{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb4ce235",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2545b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install rllib\n",
    "!pip install ray[rllib] -q\n",
    "\n",
    "# install deeplearning frameworks\n",
    "!pip install tensorflow -q\n",
    "!pip install torch -q\n",
    "\n",
    "# install openai gym environment\n",
    "!pip install gym[atari] -q\n",
    "!pip install gym[accept-rom-license] -q\n",
    "!pip install atari_py -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ceed5",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c90407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0218 15:30:24.153833104   22395 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0218 15:30:24.188022595   22395 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0218 15:30:24.219387649   22395 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0218 15:30:26.769673077   22395 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(APPOTrainer pid=22481)\u001b[0m 2022-02-18 15:30:32,058\tINFO trainer.py:2054 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(APPOTrainer pid=22481)\u001b[0m 2022-02-18 15:30:32,059\tINFO trainer.py:790 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22480)\u001b[0m 2022-02-18 15:30:37,908\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22479)\u001b[0m 2022-02-18 15:30:37,925\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(APPOTrainer pid=22481)\u001b[0m 2022-02-18 15:30:39,134\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:30:39 (running for 00:00:12.35)\n",
      "Memory usage on this node: 2.3/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+\n",
      "| Trial name                   | status   | loc              |\n",
      "|------------------------------+----------+------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |\n",
      "+------------------------------+----------+------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:30:40 (running for 00:00:13.41)\n",
      "Memory usage on this node: 2.3/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      1 |         0.996271 |  700 |  23.3684 |                   52 |                    9 |            23.3684 |\n",
      "+------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:30:45 (running for 00:00:18.41)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      1 |         0.996271 |  700 |  23.3684 |                   52 |                    9 |            23.3684 |\n",
      "+------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:30:50 (running for 00:00:23.44)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      2 |          11.0102 | 16000 |   44.434 |                  200 |                    9 |             44.434 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:30:55 (running for 00:00:28.45)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      2 |          11.0102 | 16000 |   44.434 |                  200 |                    9 |             44.434 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:31:00 (running for 00:00:33.46)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      2 |          11.0102 | 16000 |   44.434 |                  200 |                    9 |             44.434 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:31:05 (running for 00:00:38.61)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      3 |          21.1912 | 31500 |   160.87 |                  200 |                   37 |             160.87 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:31:10 (running for 00:00:43.65)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      3 |          21.1912 | 31500 |   160.87 |                  200 |                   37 |             160.87 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:31:15 (running for 00:00:48.68)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      4 |          31.2323 | 47050 |  154.951 |                  200 |                   37 |            154.951 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:31:20 (running for 00:00:53.72)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      4 |          31.2323 | 47050 |  154.951 |                  200 |                   37 |            154.951 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:31:25 (running for 00:00:58.88)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      5 |          41.4069 | 62500 |  148.689 |                  200 |                   41 |            148.689 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:31:30 (running for 00:01:03.92)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      5 |          41.4069 | 62500 |  148.689 |                  200 |                   41 |            148.689 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:31:36 (running for 00:01:09.13)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      6 |          51.6402 | 78000 |  125.008 |                  200 |                   17 |            125.008 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:31:41 (running for 00:01:14.19)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      6 |          51.6402 | 78000 |  125.008 |                  200 |                   17 |            125.008 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:31:46 (running for 00:01:19.32)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      7 |          61.8056 | 93500 |  121.693 |                  200 |                   12 |            121.693 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:31:51 (running for 00:01:24.37)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      7 |          61.8056 | 93500 |  121.693 |                  200 |                   12 |            121.693 |\n",
      "+------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:31:56 (running for 00:01:29.52)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      8 |          71.9809 | 109000 |  79.3641 |                  200 |                   11 |            79.3641 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:32:01 (running for 00:01:34.56)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      8 |          71.9809 | 109000 |  79.3641 |                  200 |                   11 |            79.3641 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:32:06 (running for 00:01:39.58)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      9 |          82.0206 | 124000 |  76.4898 |                  200 |                   12 |            76.4898 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:32:11 (running for 00:01:44.62)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |      9 |          82.0206 | 124000 |  76.4898 |                  200 |                   12 |            76.4898 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:32:16 (running for 00:01:49.82)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     10 |          92.2332 | 140050 |  76.2105 |                  200 |                   13 |            76.2105 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:32:21 (running for 00:01:54.87)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     10 |          92.2332 | 140050 |  76.2105 |                  200 |                   13 |            76.2105 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:32:26 (running for 00:02:00.10)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     11 |           102.49 | 156000 |    115.4 |                  200 |                   11 |              115.4 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:32:32 (running for 00:02:05.15)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     12 |          112.489 | 171500 |  75.5294 |                  200 |                   12 |            75.5294 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:32:37 (running for 00:02:10.16)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     12 |          112.489 | 171500 |  75.5294 |                  200 |                   12 |            75.5294 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:32:42 (running for 00:02:15.17)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     12 |          112.489 | 171500 |  75.5294 |                  200 |                   12 |            75.5294 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:32:47 (running for 00:02:20.33)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     13 |          122.668 | 187000 |  127.582 |                  200 |                   20 |            127.582 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:32:52 (running for 00:02:25.37)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     13 |          122.668 | 187000 |  127.582 |                  200 |                   20 |            127.582 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:32:57 (running for 00:02:30.43)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     14 |          132.752 | 202500 |  114.206 |                  200 |                   17 |            114.206 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:33:02 (running for 00:02:35.47)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     14 |          132.752 | 202500 |  114.206 |                  200 |                   17 |            114.206 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:33:07 (running for 00:02:40.49)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     15 |          142.776 | 218000 |  120.461 |                  200 |                   20 |            120.461 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:33:12 (running for 00:02:45.53)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     15 |          142.776 | 218000 |  120.461 |                  200 |                   20 |            120.461 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:33:17 (running for 00:02:50.70)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     16 |          152.966 | 233500 |  113.669 |                  200 |                   18 |            113.669 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:33:22 (running for 00:02:55.74)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     16 |          152.966 | 233500 |  113.669 |                  200 |                   18 |            113.669 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:33:27 (running for 00:03:00.96)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     17 |          163.204 | 249000 |  154.515 |                  200 |                   13 |            154.515 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:33:32 (running for 00:03:06.02)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     17 |          163.204 | 249000 |  154.515 |                  200 |                   13 |            154.515 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:33:38 (running for 00:03:11.13)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     18 |          173.351 | 264550 |  135.579 |                  200 |                   15 |            135.579 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:33:43 (running for 00:03:16.18)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     18 |          173.351 | 264550 |  135.579 |                  200 |                   15 |            135.579 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:33:48 (running for 00:03:21.30)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     19 |            183.5 | 280000 |     73.4 |                  200 |                   15 |               73.4 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:33:53 (running for 00:03:26.35)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     19 |            183.5 | 280000 |     73.4 |                  200 |                   15 |               73.4 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:33:58 (running for 00:03:31.61)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     20 |          193.786 | 296050 |  154.279 |                  200 |                   18 |            154.279 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:34:03 (running for 00:03:36.67)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     20 |          193.786 | 296050 |  154.279 |                  200 |                   18 |            154.279 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:34:08 (running for 00:03:41.78)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     21 |          203.935 | 312000 |   161.66 |                  200 |                   30 |             161.66 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:34:13 (running for 00:03:46.84)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     21 |          203.935 | 312000 |   161.66 |                  200 |                   30 |             161.66 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:34:18 (running for 00:03:52.02)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     22 |          214.153 | 327500 |   160.52 |                  200 |                   17 |             160.52 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:34:23 (running for 00:03:57.08)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     22 |          214.153 | 327500 |   160.52 |                  200 |                   17 |             160.52 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:34:29 (running for 00:04:02.18)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     23 |          224.288 | 343000 |   160.34 |                  200 |                   23 |             160.34 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:34:34 (running for 00:04:07.22)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     23 |          224.288 | 343000 |   160.34 |                  200 |                   23 |             160.34 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:34:39 (running for 00:04:12.44)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     24 |          234.524 | 359000 |  147.578 |                  200 |                   25 |            147.578 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:34:44 (running for 00:04:17.47)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     24 |          234.524 | 359000 |  147.578 |                  200 |                   25 |            147.578 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:34:49 (running for 00:04:22.69)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     25 |          244.757 | 375000 |  145.327 |                  200 |                   16 |            145.327 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:34:54 (running for 00:04:27.73)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     25 |          244.757 | 375000 |  145.327 |                  200 |                   16 |            145.327 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:34:59 (running for 00:04:32.82)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     26 |          254.862 | 390500 |   177.96 |                  200 |                   20 |             177.96 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:35:04 (running for 00:04:37.86)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     26 |          254.862 | 390500 |   177.96 |                  200 |                   20 |             177.96 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:35:09 (running for 00:04:43.09)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     27 |          265.117 | 406500 |   183.34 |                  200 |                   46 |             183.34 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:35:15 (running for 00:04:48.14)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     27 |          265.117 | 406500 |   183.34 |                  200 |                   46 |             183.34 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:35:20 (running for 00:04:53.26)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     28 |          275.255 | 422000 |   181.65 |                  200 |                   44 |             181.65 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:35:25 (running for 00:04:58.29)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     28 |          275.255 | 422000 |   181.65 |                  200 |                   44 |             181.65 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:35:30 (running for 00:05:03.31)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     29 |          285.261 | 437500 |   192.11 |                  200 |                   51 |             192.11 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:35:35 (running for 00:05:08.35)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     29 |          285.261 | 437500 |   192.11 |                  200 |                   51 |             192.11 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:35:40 (running for 00:05:13.44)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     30 |          295.372 | 453000 |   173.17 |                  200 |                   20 |             173.17 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:35:45 (running for 00:05:18.51)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     30 |          295.372 | 453000 |   173.17 |                  200 |                   20 |             173.17 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:35:50 (running for 00:05:23.71)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     31 |          305.615 | 469000 |   181.49 |                  200 |                   42 |             181.49 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:35:55 (running for 00:05:28.76)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     31 |          305.615 | 469000 |   181.49 |                  200 |                   42 |             181.49 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:36:00 (running for 00:05:33.82)\n",
      "Memory usage on this node: 2.4/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     32 |          315.694 | 484500 |   190.44 |                  200 |                   61 |             190.44 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:36:05 (running for 00:05:38.87)\n",
      "Memory usage on this node: 2.5/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     32 |          315.694 | 484500 |   190.44 |                  200 |                   61 |             190.44 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:36:10 (running for 00:05:44.00)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     33 |          325.854 | 499500 |   193.25 |                  200 |                   62 |             193.25 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:36:15 (running for 00:05:49.05)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     34 |          335.845 | 514500 |   186.78 |                  200 |                   29 |             186.78 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:36:20 (running for 00:05:54.05)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     34 |          335.845 | 514500 |   186.78 |                  200 |                   29 |             186.78 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:36:25 (running for 00:05:59.11)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     35 |          345.877 | 530000 |    192.6 |                  200 |                   72 |              192.6 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:36:30 (running for 00:06:04.11)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     35 |          345.877 | 530000 |    192.6 |                  200 |                   72 |              192.6 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:36:35 (running for 00:06:09.13)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     35 |          345.877 | 530000 |    192.6 |                  200 |                   72 |              192.6 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:36:41 (running for 00:06:14.20)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     36 |          355.978 | 545500 |   193.11 |                  200 |                   27 |             193.11 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:36:46 (running for 00:06:19.24)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     36 |          355.978 | 545500 |   193.11 |                  200 |                   27 |             193.11 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:36:51 (running for 00:06:24.37)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     37 |          366.121 | 561050 |    198.2 |                  200 |                   45 |              198.2 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:36:56 (running for 00:06:29.43)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     38 |           376.12 | 576500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:37:01 (running for 00:06:34.43)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     38 |           376.12 | 576500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:37:06 (running for 00:06:39.44)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     38 |           376.12 | 576500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:37:11 (running for 00:06:44.71)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     39 |          386.413 | 592500 |   196.95 |                  200 |                   41 |             196.95 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:37:16 (running for 00:06:49.76)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     39 |          386.413 | 592500 |   196.95 |                  200 |                   41 |             196.95 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:37:21 (running for 00:06:54.82)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     40 |          396.501 | 608000 |   188.49 |                  200 |                   40 |             188.49 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:37:26 (running for 00:06:59.87)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     40 |          396.501 | 608000 |   188.49 |                  200 |                   40 |             188.49 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:37:31 (running for 00:07:05.07)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     41 |          406.728 | 624000 |   179.75 |                  200 |                   24 |             179.75 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:37:36 (running for 00:07:10.11)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     41 |          406.728 | 624000 |   179.75 |                  200 |                   24 |             179.75 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:37:42 (running for 00:07:15.26)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     42 |          416.889 | 640000 |   194.84 |                  200 |                   49 |             194.84 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:37:47 (running for 00:07:20.30)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     42 |          416.889 | 640000 |   194.84 |                  200 |                   49 |             194.84 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:37:52 (running for 00:07:25.35)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     43 |          426.959 | 655550 |   188.57 |                  200 |                   15 |             188.57 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:37:57 (running for 00:07:30.40)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     43 |          426.959 | 655550 |   188.57 |                  200 |                   15 |             188.57 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:38:02 (running for 00:07:35.45)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     44 |           437.04 | 671550 |   188.69 |                  200 |                   14 |             188.69 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:38:07 (running for 00:07:40.50)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     45 |          447.023 | 687500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:38:12 (running for 00:07:45.50)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     45 |          447.023 | 687500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:38:17 (running for 00:07:50.51)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     45 |          447.023 | 687500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:38:22 (running for 00:07:55.63)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     46 |          457.173 | 703550 |   176.94 |                  200 |                   32 |             176.94 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:38:27 (running for 00:08:00.68)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     46 |          457.173 | 703550 |   176.94 |                  200 |                   32 |             176.94 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:38:32 (running for 00:08:05.84)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     47 |           467.36 | 719500 |   195.23 |                  200 |                   55 |             195.23 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:38:37 (running for 00:08:10.89)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     47 |           467.36 | 719500 |   195.23 |                  200 |                   55 |             195.23 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:38:42 (running for 00:08:16.11)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     48 |          477.603 | 735500 |   195.83 |                  200 |                   50 |             195.83 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:38:48 (running for 00:08:21.15)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     48 |          477.603 | 735500 |   195.83 |                  200 |                   50 |             195.83 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:38:53 (running for 00:08:26.20)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     49 |          487.675 | 751500 |   197.05 |                  200 |                   50 |             197.05 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:38:58 (running for 00:08:31.25)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     49 |          487.675 | 751500 |   197.05 |                  200 |                   50 |             197.05 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:39:03 (running for 00:08:36.39)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     50 |          497.838 | 767500 |   195.45 |                  200 |                   39 |             195.45 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:39:08 (running for 00:08:41.43)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     50 |          497.838 | 767500 |   195.45 |                  200 |                   39 |             195.45 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:39:13 (running for 00:08:46.50)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     51 |          507.929 | 783050 |   196.79 |                  200 |                   40 |             196.79 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:39:18 (running for 00:08:51.54)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     51 |          507.929 | 783050 |   196.79 |                  200 |                   40 |             196.79 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:39:23 (running for 00:08:56.64)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     52 |           518.04 | 799050 |   189.48 |                  200 |                   33 |             189.48 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:39:28 (running for 00:09:01.68)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     52 |           518.04 | 799050 |   189.48 |                  200 |                   33 |             189.48 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:39:33 (running for 00:09:06.87)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     53 |          528.258 | 815000 |   198.57 |                  200 |                  100 |             198.57 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:39:38 (running for 00:09:11.93)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     53 |          528.258 | 815000 |   198.57 |                  200 |                  100 |             198.57 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:39:43 (running for 00:09:17.06)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     54 |          538.417 | 830500 |   194.56 |                  200 |                   30 |             194.56 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:39:48 (running for 00:09:22.10)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     55 |          548.404 | 846000 |   197.93 |                  200 |                   47 |             197.93 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:39:53 (running for 00:09:27.10)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     55 |          548.404 | 846000 |   197.93 |                  200 |                   47 |             197.93 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:39:59 (running for 00:09:33.11)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     56 |          558.381 | 861500 |   195.12 |                  200 |                   56 |             195.12 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:40:04 (running for 00:09:38.11)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     56 |          558.381 | 861500 |   195.12 |                  200 |                   56 |             195.12 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:40:10 (running for 00:09:43.43)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     57 |          568.693 | 877550 |   188.43 |                  200 |                   24 |             188.43 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:40:15 (running for 00:09:48.44)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     57 |          568.693 | 877550 |   188.43 |                  200 |                   24 |             188.43 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:40:20 (running for 00:09:53.48)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     58 |          578.706 | 893000 |   197.41 |                  200 |                   24 |             197.41 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:40:25 (running for 00:09:58.49)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     58 |          578.706 | 893000 |   197.41 |                  200 |                   24 |             197.41 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:40:30 (running for 00:10:03.74)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     59 |          588.964 | 908500 |   191.28 |                  200 |                   17 |             191.28 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:40:35 (running for 00:10:08.75)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     59 |          588.964 | 908500 |   191.28 |                  200 |                   17 |             191.28 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:40:41 (running for 00:10:14.77)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     60 |          598.951 | 924000 |   195.63 |                  200 |                   41 |             195.63 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:40:46 (running for 00:10:19.77)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     60 |          598.951 | 924000 |   195.63 |                  200 |                   41 |             195.63 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:40:51 (running for 00:10:24.87)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     61 |           609.03 | 939550 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:40:56 (running for 00:10:29.87)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     61 |           609.03 | 939550 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:41:01 (running for 00:10:34.96)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     62 |            619.1 | 955500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:41:06 (running for 00:10:39.96)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     62 |            619.1 | 955500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:41:11 (running for 00:10:45.06)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     63 |          629.178 | 971000 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:41:16 (running for 00:10:50.06)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     63 |          629.178 | 971000 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:41:22 (running for 00:10:55.32)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     64 |          639.404 | 987000 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:41:27 (running for 00:11:00.32)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     64 |          639.404 | 987000 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:41:32 (running for 00:11:05.47)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     65 |          649.554 | 1003000 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:41:37 (running for 00:11:10.48)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     65 |          649.554 | 1003000 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:41:42 (running for 00:11:15.74)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     66 |          659.794 | 1019050 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:41:47 (running for 00:11:20.75)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     66 |          659.794 | 1019050 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:41:53 (running for 00:11:26.77)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     67 |           669.79 | 1034500 |   195.68 |                  200 |                   16 |             195.68 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:41:58 (running for 00:11:31.77)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     67 |           669.79 | 1034500 |   195.68 |                  200 |                   16 |             195.68 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:42:03 (running for 00:11:37.09)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     68 |           680.09 | 1050550 |   197.51 |                  200 |                   18 |             197.51 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:42:08 (running for 00:11:42.09)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     68 |           680.09 | 1050550 |   197.51 |                  200 |                   18 |             197.51 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:42:14 (running for 00:11:47.24)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     69 |          690.223 | 1066500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:42:19 (running for 00:11:52.24)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     69 |          690.223 | 1066500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:42:24 (running for 00:11:57.29)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     70 |          700.244 | 1082050 |   197.41 |                  200 |                   74 |             197.41 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:42:29 (running for 00:12:02.29)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     70 |          700.244 | 1082050 |   197.41 |                  200 |                   74 |             197.41 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:42:34 (running for 00:12:07.47)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     71 |          710.397 | 1098000 |   181.87 |                  200 |                   49 |             181.87 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:42:39 (running for 00:12:12.48)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     71 |          710.397 | 1098000 |   181.87 |                  200 |                   49 |             181.87 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:42:44 (running for 00:12:17.53)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     72 |          720.435 | 1113500 |   196.76 |                  200 |                   97 |             196.76 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:42:49 (running for 00:12:22.53)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     72 |          720.435 | 1113500 |   196.76 |                  200 |                   97 |             196.76 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:42:54 (running for 00:12:27.74)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     73 |          730.612 | 1129550 |   189.32 |                  200 |                   19 |             189.32 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:42:59 (running for 00:12:32.74)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     73 |          730.612 | 1129550 |   189.32 |                  200 |                   19 |             189.32 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:43:04 (running for 00:12:37.91)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     74 |          740.769 | 1145500 |   178.14 |                  200 |                   19 |             178.14 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:43:09 (running for 00:12:42.92)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     74 |          740.769 | 1145500 |   178.14 |                  200 |                   19 |             178.14 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:43:15 (running for 00:12:48.17)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     75 |          751.001 | 1161500 |   183.99 |                  200 |                   15 |             183.99 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:43:20 (running for 00:12:53.17)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     75 |          751.001 | 1161500 |   183.99 |                  200 |                   15 |             183.99 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:43:25 (running for 00:12:58.31)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     76 |          761.117 | 1177500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:43:30 (running for 00:13:03.31)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     76 |          761.117 | 1177500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:43:35 (running for 00:13:08.45)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     77 |          771.242 | 1193500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:43:40 (running for 00:13:13.45)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     77 |          771.242 | 1193500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:43:45 (running for 00:13:18.74)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     78 |          781.519 | 1209500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:43:50 (running for 00:13:23.74)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     78 |          781.519 | 1209500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:43:55 (running for 00:13:28.88)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     79 |          791.631 | 1225000 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:44:00 (running for 00:13:33.88)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     79 |          791.631 | 1225000 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:44:05 (running for 00:13:39.02)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     80 |          801.763 | 1241050 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:44:10 (running for 00:13:44.03)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     80 |          801.763 | 1241050 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:44:16 (running for 00:13:49.17)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     81 |          811.873 | 1257550 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:44:21 (running for 00:13:54.17)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     81 |          811.873 | 1257550 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:44:26 (running for 00:13:59.35)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     82 |          822.031 | 1273500 |   197.58 |                  200 |                  113 |             197.58 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:44:31 (running for 00:14:04.35)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     82 |          822.031 | 1273500 |   197.58 |                  200 |                  113 |             197.58 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:44:36 (running for 00:14:09.68)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     83 |          832.316 | 1290000 |   198.18 |                  200 |                   41 |             198.18 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:44:41 (running for 00:14:14.68)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     83 |          832.316 | 1290000 |   198.18 |                  200 |                   41 |             198.18 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:44:47 (running for 00:14:20.70)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     84 |          842.336 | 1305500 |   194.71 |                  200 |                   41 |             194.71 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:44:52 (running for 00:14:25.70)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     84 |          842.336 | 1305500 |   194.71 |                  200 |                   41 |             194.71 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:44:57 (running for 00:14:30.75)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     85 |          852.367 | 1321000 |    198.6 |                  200 |                   60 |              198.6 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:45:02 (running for 00:14:35.75)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     85 |          852.367 | 1321000 |    198.6 |                  200 |                   60 |              198.6 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:45:07 (running for 00:14:40.82)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     86 |          862.413 | 1337000 |   199.63 |                  200 |                  163 |             199.63 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:45:12 (running for 00:14:45.82)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     86 |          862.413 | 1337000 |   199.63 |                  200 |                  163 |             199.63 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:45:17 (running for 00:14:51.06)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     87 |          872.622 | 1352500 |   185.31 |                  200 |                   13 |             185.31 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:45:22 (running for 00:14:56.06)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     87 |          872.622 | 1352500 |   185.31 |                  200 |                   13 |             185.31 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:45:28 (running for 00:15:01.17)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     88 |          882.705 | 1368000 |   192.83 |                  200 |                   13 |             192.83 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:45:33 (running for 00:15:06.17)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     88 |          882.705 | 1368000 |   192.83 |                  200 |                   13 |             192.83 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:45:38 (running for 00:15:11.26)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     89 |           892.78 | 1384000 |   196.68 |                  200 |                   16 |             196.68 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:45:43 (running for 00:15:16.26)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     89 |           892.78 | 1384000 |   196.68 |                  200 |                   16 |             196.68 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:45:48 (running for 00:15:21.30)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     90 |          902.805 | 1399500 |   157.85 |                  200 |                   11 |             157.85 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:45:53 (running for 00:15:26.30)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     90 |          902.805 | 1399500 |   157.85 |                  200 |                   11 |             157.85 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:45:58 (running for 00:15:31.48)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     91 |          912.954 | 1415500 |   184.02 |                  200 |                   11 |             184.02 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:46:03 (running for 00:15:36.48)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     91 |          912.954 | 1415500 |   184.02 |                  200 |                   11 |             184.02 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:46:08 (running for 00:15:41.60)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     92 |          923.056 | 1431000 |    198.7 |                  200 |                   93 |              198.7 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:46:13 (running for 00:15:46.60)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     92 |          923.056 | 1431000 |    198.7 |                  200 |                   93 |              198.7 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:46:18 (running for 00:15:51.81)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     93 |          933.243 | 1446500 |   198.62 |                  200 |                   85 |             198.62 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:46:23 (running for 00:15:56.82)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     93 |          933.243 | 1446500 |   198.62 |                  200 |                   85 |             198.62 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:46:28 (running for 00:16:01.85)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     94 |          943.261 | 1462500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:46:33 (running for 00:16:06.85)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     94 |          943.261 | 1462500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:46:38 (running for 00:16:12.05)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     95 |          953.435 | 1478500 |   185.61 |                  200 |                   16 |             185.61 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:46:43 (running for 00:16:17.06)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     95 |          953.435 | 1478500 |   185.61 |                  200 |                   16 |             185.61 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:46:49 (running for 00:16:22.24)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     96 |          963.596 | 1494500 |   165.48 |                  200 |                   14 |             165.48 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:46:54 (running for 00:16:27.25)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     96 |          963.596 | 1494500 |   165.48 |                  200 |                   14 |             165.48 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:46:59 (running for 00:16:32.50)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     97 |          973.842 | 1510500 |   186.44 |                  200 |                   50 |             186.44 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:47:04 (running for 00:16:37.51)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     97 |          973.842 | 1510500 |   186.44 |                  200 |                   50 |             186.44 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-02-18 15:47:09 (running for 00:16:42.65)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     98 |          983.967 | 1526500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:47:14 (running for 00:16:47.66)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     98 |          983.967 | 1526500 |      200 |                  200 |                  200 |                200 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:47:19 (running for 00:16:52.76)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     99 |          994.041 | 1542550 |   199.98 |                  200 |                  198 |             199.98 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:47:24 (running for 00:16:57.76)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |     99 |          994.041 | 1542550 |   199.98 |                  200 |                  198 |             199.98 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-02-18 15:47:29 (running for 00:17:02.85)\n",
      "Memory usage on this node: 2.6/15.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/8.9 GiB heap, 0.0/4.45 GiB objects\n",
      "Result logdir: /home/dojm.ex5/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                   | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| APPO_CartPole-v0_b270f_00000 | RUNNING  | 10.182.0.2:22481 |    100 |          1004.12 | 1558500 |   199.12 |                  200 |                  112 |             199.12 |\n",
      "+------------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# test tensorflow\n",
    "!rllib train --run APPO --env CartPole-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddee745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test pytorch\n",
    "# !rllib train --run APPO --env CartPole-v0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db284d25",
   "metadata": {},
   "source": [
    "## python api ppo test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11e9be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50a06de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 16:08:30,581\tWARNING ppo.py:223 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 1333.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24503)\u001b[0m 2022-02-18 16:08:36,642\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24500)\u001b[0m 2022-02-18 16:08:37,130\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=24501)\u001b[0m 2022-02-18 16:08:37,206\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "2022-02-18 16:08:38,200\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 7998\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-08-49\n",
      "done: false\n",
      "episode_len_mean: 23.22222222222222\n",
      "episode_media: {}\n",
      "episode_reward_max: 91.0\n",
      "episode_reward_mean: 23.22222222222222\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 342\n",
      "episodes_total: 342\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6644693613052368\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029713232070207596\n",
      "        model: {}\n",
      "        policy_loss: -0.04155859351158142\n",
      "        total_loss: 198.72483825683594\n",
      "        vf_explained_var: 0.08170207589864731\n",
      "        vf_loss: 198.7604522705078\n",
      "  num_agent_steps_sampled: 7998\n",
      "  num_agent_steps_trained: 7998\n",
      "  num_steps_sampled: 7998\n",
      "  num_steps_trained: 7998\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 1\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 68.1375\n",
      "  ram_util_percent: 17.4\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09515933783958554\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09815159799473103\n",
      "  mean_inference_ms: 1.0599465356763627\n",
      "  mean_raw_obs_processing_ms: 0.15464117004764105\n",
      "time_since_restore: 10.864551544189453\n",
      "time_this_iter_s: 10.864551544189453\n",
      "time_total_s: 10.864551544189453\n",
      "timers:\n",
      "  learn_throughput: 1148.206\n",
      "  learn_time_ms: 6965.651\n",
      "  load_throughput: 21925518.557\n",
      "  load_time_ms: 0.365\n",
      "  sample_throughput: 2060.2\n",
      "  sample_time_ms: 3882.148\n",
      "  update_time_ms: 3.884\n",
      "timestamp: 1645200529\n",
      "timesteps_since_restore: 7998\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 7998\n",
      "training_iteration: 1\n",
      "trial_id: default\n",
      "\n",
      "checkpoint saved at /home/dojm.ex5/ray_results/PPOTrainer_CartPole-v0_2022-02-18_16-08-30gfueqw0q/checkpoint_000001/checkpoint-1\n",
      "agent_timesteps_total: 15996\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-08-59\n",
      "done: false\n",
      "episode_len_mean: 48.292682926829265\n",
      "episode_media: {}\n",
      "episode_reward_max: 176.0\n",
      "episode_reward_mean: 48.292682926829265\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 164\n",
      "episodes_total: 506\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.604433000087738\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01843184418976307\n",
      "        model: {}\n",
      "        policy_loss: -0.026975082233548164\n",
      "        total_loss: 354.40155029296875\n",
      "        vf_explained_var: 0.1331550031900406\n",
      "        vf_loss: 354.4229736328125\n",
      "  num_agent_steps_sampled: 15996\n",
      "  num_agent_steps_trained: 15996\n",
      "  num_steps_sampled: 15996\n",
      "  num_steps_trained: 15996\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 2\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 68.53333333333332\n",
      "  ram_util_percent: 17.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09567400085112783\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09831777200815177\n",
      "  mean_inference_ms: 1.057444581082494\n",
      "  mean_raw_obs_processing_ms: 0.14728079831022334\n",
      "time_since_restore: 21.25463557243347\n",
      "time_this_iter_s: 10.390084028244019\n",
      "time_total_s: 21.25463557243347\n",
      "timers:\n",
      "  learn_throughput: 1184.093\n",
      "  learn_time_ms: 6754.537\n",
      "  load_throughput: 20605677.759\n",
      "  load_time_ms: 0.388\n",
      "  sample_throughput: 1082.673\n",
      "  sample_time_ms: 7387.273\n",
      "  update_time_ms: 3.869\n",
      "timestamp: 1645200539\n",
      "timesteps_since_restore: 15996\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 15996\n",
      "training_iteration: 2\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 23994\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-09-09\n",
      "done: false\n",
      "episode_len_mean: 94.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 94.12\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 70\n",
      "episodes_total: 576\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5668949484825134\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009007133543491364\n",
      "        model: {}\n",
      "        policy_loss: -0.02298428677022457\n",
      "        total_loss: 841.227294921875\n",
      "        vf_explained_var: 0.15999886393547058\n",
      "        vf_loss: 841.24755859375\n",
      "  num_agent_steps_sampled: 23994\n",
      "  num_agent_steps_trained: 23994\n",
      "  num_steps_sampled: 23994\n",
      "  num_steps_trained: 23994\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 3\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 71.70666666666666\n",
      "  ram_util_percent: 17.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09533657629975881\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09810922222785198\n",
      "  mean_inference_ms: 1.0543055733642133\n",
      "  mean_raw_obs_processing_ms: 0.14272300674991836\n",
      "time_since_restore: 31.615981101989746\n",
      "time_this_iter_s: 10.361345529556274\n",
      "time_total_s: 31.615981101989746\n",
      "timers:\n",
      "  learn_throughput: 1189.598\n",
      "  learn_time_ms: 6723.279\n",
      "  load_throughput: 20900961.615\n",
      "  load_time_ms: 0.383\n",
      "  sample_throughput: 958.34\n",
      "  sample_time_ms: 8345.683\n",
      "  update_time_ms: 3.679\n",
      "timestamp: 1645200549\n",
      "timesteps_since_restore: 23994\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 23994\n",
      "training_iteration: 3\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 31992\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-09-20\n",
      "done: false\n",
      "episode_len_mean: 141.34\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 141.34\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 47\n",
      "episodes_total: 623\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5421133637428284\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0051180231384932995\n",
      "        model: {}\n",
      "        policy_loss: -0.008357550948858261\n",
      "        total_loss: 717.377685546875\n",
      "        vf_explained_var: 0.22300611436367035\n",
      "        vf_loss: 717.384521484375\n",
      "  num_agent_steps_sampled: 31992\n",
      "  num_agent_steps_trained: 31992\n",
      "  num_steps_sampled: 31992\n",
      "  num_steps_trained: 31992\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 4\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 71.56666666666666\n",
      "  ram_util_percent: 17.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09554232939908897\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09770225578002215\n",
      "  mean_inference_ms: 1.0547719991429196\n",
      "  mean_raw_obs_processing_ms: 0.13964727191605592\n",
      "time_since_restore: 42.261574268341064\n",
      "time_this_iter_s: 10.645593166351318\n",
      "time_total_s: 42.261574268341064\n",
      "timers:\n",
      "  learn_throughput: 1183.229\n",
      "  learn_time_ms: 6759.468\n",
      "  load_throughput: 21411229.227\n",
      "  load_time_ms: 0.374\n",
      "  sample_throughput: 901.303\n",
      "  sample_time_ms: 8873.821\n",
      "  update_time_ms: 3.663\n",
      "timestamp: 1645200560\n",
      "timesteps_since_restore: 31992\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 31992\n",
      "training_iteration: 4\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 39990\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-09-30\n",
      "done: false\n",
      "episode_len_mean: 171.34\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 171.34\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 41\n",
      "episodes_total: 664\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.537986695766449\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00193466164637357\n",
      "        model: {}\n",
      "        policy_loss: -0.001605973462574184\n",
      "        total_loss: 523.3052978515625\n",
      "        vf_explained_var: 0.22140496969223022\n",
      "        vf_loss: 523.3063354492188\n",
      "  num_agent_steps_sampled: 39990\n",
      "  num_agent_steps_trained: 39990\n",
      "  num_steps_sampled: 39990\n",
      "  num_steps_trained: 39990\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 5\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 71.27142857142857\n",
      "  ram_util_percent: 17.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0956308095240664\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09774686099145204\n",
      "  mean_inference_ms: 1.053459652332004\n",
      "  mean_raw_obs_processing_ms: 0.1375286531700429\n",
      "time_since_restore: 52.42321252822876\n",
      "time_this_iter_s: 10.161638259887695\n",
      "time_total_s: 52.42321252822876\n",
      "timers:\n",
      "  learn_throughput: 1194.526\n",
      "  learn_time_ms: 6695.543\n",
      "  load_throughput: 21971471.962\n",
      "  load_time_ms: 0.364\n",
      "  sample_throughput: 867.394\n",
      "  sample_time_ms: 9220.723\n",
      "  update_time_ms: 3.644\n",
      "timestamp: 1645200570\n",
      "timesteps_since_restore: 39990\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 39990\n",
      "training_iteration: 5\n",
      "trial_id: default\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 47988\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-09-41\n",
      "done: false\n",
      "episode_len_mean: 190.46\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.46\n",
      "episode_reward_min: 15.0\n",
      "episodes_this_iter: 42\n",
      "episodes_total: 706\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.15000000596046448\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5268450379371643\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0057076821103692055\n",
      "        model: {}\n",
      "        policy_loss: -0.0026327339000999928\n",
      "        total_loss: 411.5504150390625\n",
      "        vf_explained_var: 0.3908695876598358\n",
      "        vf_loss: 411.5521545410156\n",
      "  num_agent_steps_sampled: 47988\n",
      "  num_agent_steps_trained: 47988\n",
      "  num_steps_sampled: 47988\n",
      "  num_steps_trained: 47988\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 6\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 70.5\n",
      "  ram_util_percent: 17.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09561747095008437\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09766515404257464\n",
      "  mean_inference_ms: 1.0523159375985918\n",
      "  mean_raw_obs_processing_ms: 0.13557099412175588\n",
      "time_since_restore: 62.65666484832764\n",
      "time_this_iter_s: 10.233452320098877\n",
      "time_total_s: 62.65666484832764\n",
      "timers:\n",
      "  learn_throughput: 1200.002\n",
      "  learn_time_ms: 6664.988\n",
      "  load_throughput: 21828029.536\n",
      "  load_time_ms: 0.366\n",
      "  sample_throughput: 852.622\n",
      "  sample_time_ms: 9380.476\n",
      "  update_time_ms: 3.639\n",
      "timestamp: 1645200581\n",
      "timesteps_since_restore: 47988\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 47988\n",
      "training_iteration: 6\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 55986\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-09-51\n",
      "done: false\n",
      "episode_len_mean: 196.84\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.84\n",
      "episode_reward_min: 108.0\n",
      "episodes_this_iter: 39\n",
      "episodes_total: 745\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.15000000596046448\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5169378519058228\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004788364749401808\n",
      "        model: {}\n",
      "        policy_loss: 7.611019827891141e-05\n",
      "        total_loss: 372.5811767578125\n",
      "        vf_explained_var: 0.41926199197769165\n",
      "        vf_loss: 372.58038330078125\n",
      "  num_agent_steps_sampled: 55986\n",
      "  num_agent_steps_trained: 55986\n",
      "  num_steps_sampled: 55986\n",
      "  num_steps_trained: 55986\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 7\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 70.26\n",
      "  ram_util_percent: 17.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.095457944669838\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09746135254025408\n",
      "  mean_inference_ms: 1.0507158360120723\n",
      "  mean_raw_obs_processing_ms: 0.13409330552909748\n",
      "time_since_restore: 73.17795443534851\n",
      "time_this_iter_s: 10.521289587020874\n",
      "time_total_s: 73.17795443534851\n",
      "timers:\n",
      "  learn_throughput: 1197.648\n",
      "  learn_time_ms: 6678.091\n",
      "  load_throughput: 21094349.959\n",
      "  load_time_ms: 0.379\n",
      "  sample_throughput: 840.924\n",
      "  sample_time_ms: 9510.968\n",
      "  update_time_ms: 3.771\n",
      "timestamp: 1645200591\n",
      "timesteps_since_restore: 55986\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 55986\n",
      "training_iteration: 7\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 63984\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-10-01\n",
      "done: false\n",
      "episode_len_mean: 198.52\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.52\n",
      "episode_reward_min: 124.0\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 785\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.506972074508667\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004900201223790646\n",
      "        model: {}\n",
      "        policy_loss: -0.006371382158249617\n",
      "        total_loss: 337.4648742675781\n",
      "        vf_explained_var: 0.5357547998428345\n",
      "        vf_loss: 337.47088623046875\n",
      "  num_agent_steps_sampled: 63984\n",
      "  num_agent_steps_trained: 63984\n",
      "  num_steps_sampled: 63984\n",
      "  num_steps_trained: 63984\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 8\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 72.92857142857143\n",
      "  ram_util_percent: 17.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09523109626313125\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09727133533601301\n",
      "  mean_inference_ms: 1.048809246910764\n",
      "  mean_raw_obs_processing_ms: 0.13292831062556043\n",
      "time_since_restore: 82.99991869926453\n",
      "time_this_iter_s: 9.821964263916016\n",
      "time_total_s: 82.99991869926453\n",
      "timers:\n",
      "  learn_throughput: 1210.816\n",
      "  learn_time_ms: 6605.46\n",
      "  load_throughput: 21236713.392\n",
      "  load_time_ms: 0.377\n",
      "  sample_throughput: 830.132\n",
      "  sample_time_ms: 9634.616\n",
      "  update_time_ms: 3.652\n",
      "timestamp: 1645200601\n",
      "timesteps_since_restore: 63984\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 63984\n",
      "training_iteration: 8\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 71982\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-10-11\n",
      "done: false\n",
      "episode_len_mean: 199.17\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.17\n",
      "episode_reward_min: 172.0\n",
      "episodes_this_iter: 41\n",
      "episodes_total: 826\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5086461305618286\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005157826002687216\n",
      "        model: {}\n",
      "        policy_loss: -0.0037035830318927765\n",
      "        total_loss: 335.2198486328125\n",
      "        vf_explained_var: 0.5669450163841248\n",
      "        vf_loss: 335.223388671875\n",
      "  num_agent_steps_sampled: 71982\n",
      "  num_agent_steps_trained: 71982\n",
      "  num_steps_sampled: 71982\n",
      "  num_steps_trained: 71982\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 9\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 72.9142857142857\n",
      "  ram_util_percent: 17.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09488681486748024\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09693375135767657\n",
      "  mean_inference_ms: 1.0458764040421622\n",
      "  mean_raw_obs_processing_ms: 0.1316926268120595\n",
      "time_since_restore: 93.06222438812256\n",
      "time_this_iter_s: 10.062305688858032\n",
      "time_total_s: 93.06222438812256\n",
      "timers:\n",
      "  learn_throughput: 1215.28\n",
      "  learn_time_ms: 6581.201\n",
      "  load_throughput: 21508469.796\n",
      "  load_time_ms: 0.372\n",
      "  sample_throughput: 828.672\n",
      "  sample_time_ms: 9651.59\n",
      "  update_time_ms: 3.593\n",
      "timestamp: 1645200611\n",
      "timesteps_since_restore: 71982\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 71982\n",
      "training_iteration: 9\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 79980\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-10-21\n",
      "done: false\n",
      "episode_len_mean: 195.88\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.88\n",
      "episode_reward_min: 127.0\n",
      "episodes_this_iter: 41\n",
      "episodes_total: 867\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5252229571342468\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006059876177459955\n",
      "        model: {}\n",
      "        policy_loss: -0.011163152754306793\n",
      "        total_loss: 204.75042724609375\n",
      "        vf_explained_var: 0.750304639339447\n",
      "        vf_loss: 204.76133728027344\n",
      "  num_agent_steps_sampled: 79980\n",
      "  num_agent_steps_trained: 79980\n",
      "  num_steps_sampled: 79980\n",
      "  num_steps_trained: 79980\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 10\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 68.99333333333334\n",
      "  ram_util_percent: 17.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09466095964280702\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09672057216297086\n",
      "  mean_inference_ms: 1.0441682932965868\n",
      "  mean_raw_obs_processing_ms: 0.13075767728928356\n",
      "time_since_restore: 103.27599954605103\n",
      "time_this_iter_s: 10.213775157928467\n",
      "time_total_s: 103.27599954605103\n",
      "timers:\n",
      "  learn_throughput: 1217.661\n",
      "  learn_time_ms: 6568.333\n",
      "  load_throughput: 21831344.131\n",
      "  load_time_ms: 0.366\n",
      "  sample_throughput: 824.262\n",
      "  sample_time_ms: 9703.221\n",
      "  update_time_ms: 3.554\n",
      "timestamp: 1645200621\n",
      "timesteps_since_restore: 79980\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 79980\n",
      "training_iteration: 10\n",
      "trial_id: default\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 87978\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-10-32\n",
      "done: false\n",
      "episode_len_mean: 196.04\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.04\n",
      "episode_reward_min: 127.0\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 907\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.49954459071159363\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004518278408795595\n",
      "        model: {}\n",
      "        policy_loss: 0.0026209193747490644\n",
      "        total_loss: 316.4875793457031\n",
      "        vf_explained_var: 0.604655385017395\n",
      "        vf_loss: 316.4847412109375\n",
      "  num_agent_steps_sampled: 87978\n",
      "  num_agent_steps_trained: 87978\n",
      "  num_steps_sampled: 87978\n",
      "  num_steps_trained: 87978\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 11\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 67.91333333333334\n",
      "  ram_util_percent: 17.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09458875085362997\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09666223335295732\n",
      "  mean_inference_ms: 1.0432118939651223\n",
      "  mean_raw_obs_processing_ms: 0.13020170181768886\n",
      "time_since_restore: 113.70051980018616\n",
      "time_this_iter_s: 10.424520254135132\n",
      "time_total_s: 113.70051980018616\n",
      "timers:\n",
      "  learn_throughput: 1224.12\n",
      "  learn_time_ms: 6533.671\n",
      "  load_throughput: 21428325.386\n",
      "  load_time_ms: 0.373\n",
      "  sample_throughput: 773.318\n",
      "  sample_time_ms: 10342.445\n",
      "  update_time_ms: 3.515\n",
      "timestamp: 1645200632\n",
      "timesteps_since_restore: 87978\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 87978\n",
      "training_iteration: 11\n",
      "trial_id: default\n",
      "\n",
      "checkpoint saved at /home/dojm.ex5/ray_results/PPOTrainer_CartPole-v0_2022-02-18_16-08-30gfueqw0q/checkpoint_000011/checkpoint-11\n",
      "agent_timesteps_total: 95976\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-10-42\n",
      "done: false\n",
      "episode_len_mean: 198.26\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.26\n",
      "episode_reward_min: 148.0\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 947\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.01875000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5266051292419434\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003942481242120266\n",
      "        model: {}\n",
      "        policy_loss: 0.0026756972074508667\n",
      "        total_loss: 315.75189208984375\n",
      "        vf_explained_var: 0.6376459002494812\n",
      "        vf_loss: 315.7491149902344\n",
      "  num_agent_steps_sampled: 95976\n",
      "  num_agent_steps_trained: 95976\n",
      "  num_steps_sampled: 95976\n",
      "  num_steps_trained: 95976\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 12\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 70.9\n",
      "  ram_util_percent: 17.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09460049654279104\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09666395140321846\n",
      "  mean_inference_ms: 1.0431924768019398\n",
      "  mean_raw_obs_processing_ms: 0.12986376572816247\n",
      "time_since_restore: 124.02106499671936\n",
      "time_this_iter_s: 10.320545196533203\n",
      "time_total_s: 124.02106499671936\n",
      "timers:\n",
      "  learn_throughput: 1223.062\n",
      "  learn_time_ms: 6539.324\n",
      "  load_throughput: 21736566.703\n",
      "  load_time_ms: 0.368\n",
      "  sample_throughput: 777.245\n",
      "  sample_time_ms: 10290.191\n",
      "  update_time_ms: 3.493\n",
      "timestamp: 1645200642\n",
      "timesteps_since_restore: 95976\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 95976\n",
      "training_iteration: 12\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 103974\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-10-53\n",
      "done: false\n",
      "episode_len_mean: 199.55\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.55\n",
      "episode_reward_min: 166.0\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 987\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.00937500037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5361742973327637\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003890079678967595\n",
      "        model: {}\n",
      "        policy_loss: -0.010419716127216816\n",
      "        total_loss: 370.2569885253906\n",
      "        vf_explained_var: 0.5035387873649597\n",
      "        vf_loss: 370.2673645019531\n",
      "  num_agent_steps_sampled: 103974\n",
      "  num_agent_steps_trained: 103974\n",
      "  num_steps_sampled: 103974\n",
      "  num_steps_trained: 103974\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 13\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 69.36666666666666\n",
      "  ram_util_percent: 17.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09463981522523619\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09665351523689641\n",
      "  mean_inference_ms: 1.0434240681052902\n",
      "  mean_raw_obs_processing_ms: 0.12959630501586994\n",
      "time_since_restore: 134.98164296150208\n",
      "time_this_iter_s: 10.960577964782715\n",
      "time_total_s: 134.98164296150208\n",
      "timers:\n",
      "  learn_throughput: 1213.538\n",
      "  learn_time_ms: 6590.646\n",
      "  load_throughput: 21730934.373\n",
      "  load_time_ms: 0.368\n",
      "  sample_throughput: 776.196\n",
      "  sample_time_ms: 10304.092\n",
      "  update_time_ms: 3.486\n",
      "timestamp: 1645200653\n",
      "timesteps_since_restore: 103974\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 103974\n",
      "training_iteration: 13\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 111972\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-11-04\n",
      "done: false\n",
      "episode_len_mean: 199.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.99\n",
      "episode_reward_min: 199.0\n",
      "episodes_this_iter: 41\n",
      "episodes_total: 1028\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.004687500186264515\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5130336880683899\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00727189052850008\n",
      "        model: {}\n",
      "        policy_loss: -0.0020738369785249233\n",
      "        total_loss: 290.07305908203125\n",
      "        vf_explained_var: 0.622361421585083\n",
      "        vf_loss: 290.0750732421875\n",
      "  num_agent_steps_sampled: 111972\n",
      "  num_agent_steps_trained: 111972\n",
      "  num_steps_sampled: 111972\n",
      "  num_steps_trained: 111972\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 14\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 70.09333333333332\n",
      "  ram_util_percent: 15.400000000000002\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09464689630247398\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09664849095211667\n",
      "  mean_inference_ms: 1.0429972259761415\n",
      "  mean_raw_obs_processing_ms: 0.1293696209715269\n",
      "time_since_restore: 145.548437833786\n",
      "time_this_iter_s: 10.566794872283936\n",
      "time_total_s: 145.548437833786\n",
      "timers:\n",
      "  learn_throughput: 1213.237\n",
      "  learn_time_ms: 6592.282\n",
      "  load_throughput: 21532860.512\n",
      "  load_time_ms: 0.371\n",
      "  sample_throughput: 773.09\n",
      "  sample_time_ms: 10345.493\n",
      "  update_time_ms: 3.491\n",
      "timestamp: 1645200664\n",
      "timesteps_since_restore: 111972\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 111972\n",
      "training_iteration: 14\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 119970\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-11-14\n",
      "done: false\n",
      "episode_len_mean: 199.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.25\n",
      "episode_reward_min: 170.0\n",
      "episodes_this_iter: 39\n",
      "episodes_total: 1067\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.004687500186264515\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5266441106796265\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006650029681622982\n",
      "        model: {}\n",
      "        policy_loss: -0.00044774843263439834\n",
      "        total_loss: 142.77154541015625\n",
      "        vf_explained_var: 0.8264068961143494\n",
      "        vf_loss: 142.77197265625\n",
      "  num_agent_steps_sampled: 119970\n",
      "  num_agent_steps_trained: 119970\n",
      "  num_steps_sampled: 119970\n",
      "  num_steps_trained: 119970\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 15\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 70.36666666666666\n",
      "  ram_util_percent: 15.400000000000002\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09475308822338764\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09674159924848784\n",
      "  mean_inference_ms: 1.0438513073720468\n",
      "  mean_raw_obs_processing_ms: 0.1293062191244518\n",
      "time_since_restore: 156.05080914497375\n",
      "time_this_iter_s: 10.502371311187744\n",
      "time_total_s: 156.05080914497375\n",
      "timers:\n",
      "  learn_throughput: 1209.009\n",
      "  learn_time_ms: 6615.338\n",
      "  load_throughput: 21399619.413\n",
      "  load_time_ms: 0.374\n",
      "  sample_throughput: 772.146\n",
      "  sample_time_ms: 10358.15\n",
      "  update_time_ms: 3.476\n",
      "timestamp: 1645200674\n",
      "timesteps_since_restore: 119970\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 119970\n",
      "training_iteration: 15\n",
      "trial_id: default\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 127968\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-11-24\n",
      "done: false\n",
      "episode_len_mean: 198.72\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.72\n",
      "episode_reward_min: 166.0\n",
      "episodes_this_iter: 42\n",
      "episodes_total: 1109\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.004687500186264515\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5132433772087097\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0060722013004124165\n",
      "        model: {}\n",
      "        policy_loss: 0.0034667805302888155\n",
      "        total_loss: 86.35494232177734\n",
      "        vf_explained_var: 0.8856870532035828\n",
      "        vf_loss: 86.35144805908203\n",
      "  num_agent_steps_sampled: 127968\n",
      "  num_agent_steps_trained: 127968\n",
      "  num_steps_sampled: 127968\n",
      "  num_steps_trained: 127968\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 16\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 69.92000000000002\n",
      "  ram_util_percent: 15.46\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09476603282528184\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09677594412836836\n",
      "  mean_inference_ms: 1.0438467508273632\n",
      "  mean_raw_obs_processing_ms: 0.12915181846188545\n",
      "time_since_restore: 166.05282330513\n",
      "time_this_iter_s: 10.00201416015625\n",
      "time_total_s: 166.05282330513\n",
      "timers:\n",
      "  learn_throughput: 1211.699\n",
      "  learn_time_ms: 6600.649\n",
      "  load_throughput: 21055764.117\n",
      "  load_time_ms: 0.38\n",
      "  sample_throughput: 771.036\n",
      "  sample_time_ms: 10373.052\n",
      "  update_time_ms: 3.439\n",
      "timestamp: 1645200684\n",
      "timesteps_since_restore: 127968\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 127968\n",
      "training_iteration: 16\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 135966\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-11-34\n",
      "done: false\n",
      "episode_len_mean: 198.95\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.95\n",
      "episode_reward_min: 166.0\n",
      "episodes_this_iter: 39\n",
      "episodes_total: 1148\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.004687500186264515\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5167339444160461\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005206842441111803\n",
      "        model: {}\n",
      "        policy_loss: -0.0006616464233957231\n",
      "        total_loss: 205.5207977294922\n",
      "        vf_explained_var: 0.7670599222183228\n",
      "        vf_loss: 205.5214385986328\n",
      "  num_agent_steps_sampled: 135966\n",
      "  num_agent_steps_trained: 135966\n",
      "  num_steps_sampled: 135966\n",
      "  num_steps_trained: 135966\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 17\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 70.38571428571427\n",
      "  ram_util_percent: 15.492857142857144\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09468461131897447\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09668869567125522\n",
      "  mean_inference_ms: 1.042800566057337\n",
      "  mean_raw_obs_processing_ms: 0.12888722618545034\n",
      "time_since_restore: 176.08143305778503\n",
      "time_this_iter_s: 10.02860975265503\n",
      "time_total_s: 176.08143305778503\n",
      "timers:\n",
      "  learn_throughput: 1218.062\n",
      "  learn_time_ms: 6566.168\n",
      "  load_throughput: 21426956.689\n",
      "  load_time_ms: 0.373\n",
      "  sample_throughput: 773.236\n",
      "  sample_time_ms: 10343.549\n",
      "  update_time_ms: 3.332\n",
      "timestamp: 1645200694\n",
      "timesteps_since_restore: 135966\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 135966\n",
      "training_iteration: 17\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 143964\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-11-44\n",
      "done: false\n",
      "episode_len_mean: 199.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.6\n",
      "episode_reward_min: 166.0\n",
      "episodes_this_iter: 39\n",
      "episodes_total: 1187\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.004687500186264515\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5380508899688721\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028542345389723778\n",
      "        model: {}\n",
      "        policy_loss: 0.0030670221894979477\n",
      "        total_loss: 242.40220642089844\n",
      "        vf_explained_var: 0.7056396007537842\n",
      "        vf_loss: 242.3991241455078\n",
      "  num_agent_steps_sampled: 143964\n",
      "  num_agent_steps_trained: 143964\n",
      "  num_steps_sampled: 143964\n",
      "  num_steps_trained: 143964\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 18\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 70.41428571428571\n",
      "  ram_util_percent: 15.42857142857143\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09458070761165732\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09653673258740199\n",
      "  mean_inference_ms: 1.0415040108651936\n",
      "  mean_raw_obs_processing_ms: 0.1285425114076698\n",
      "time_since_restore: 185.76672053337097\n",
      "time_this_iter_s: 9.685287475585938\n",
      "time_total_s: 185.76672053337097\n",
      "timers:\n",
      "  learn_throughput: 1218.191\n",
      "  learn_time_ms: 6565.473\n",
      "  load_throughput: 21483217.03\n",
      "  load_time_ms: 0.372\n",
      "  sample_throughput: 776.799\n",
      "  sample_time_ms: 10296.093\n",
      "  update_time_ms: 3.371\n",
      "timestamp: 1645200704\n",
      "timesteps_since_restore: 143964\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 143964\n",
      "training_iteration: 18\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 151962\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-11-53\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 42\n",
      "episodes_total: 1229\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0023437500931322575\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5463025569915771\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0018493180396035314\n",
      "        model: {}\n",
      "        policy_loss: 0.000740185147151351\n",
      "        total_loss: 244.50914001464844\n",
      "        vf_explained_var: 0.6877337694168091\n",
      "        vf_loss: 244.50840759277344\n",
      "  num_agent_steps_sampled: 151962\n",
      "  num_agent_steps_trained: 151962\n",
      "  num_steps_sampled: 151962\n",
      "  num_steps_trained: 151962\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 19\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 69.71428571428571\n",
      "  ram_util_percent: 15.400000000000002\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09431657324153689\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09625721628654503\n",
      "  mean_inference_ms: 1.0387214223374275\n",
      "  mean_raw_obs_processing_ms: 0.12801926459869023\n",
      "time_since_restore: 195.40627145767212\n",
      "time_this_iter_s: 9.639550924301147\n",
      "time_total_s: 195.40627145767212\n",
      "timers:\n",
      "  learn_throughput: 1222.187\n",
      "  learn_time_ms: 6544.009\n",
      "  load_throughput: 21600800.639\n",
      "  load_time_ms: 0.37\n",
      "  sample_throughput: 778.43\n",
      "  sample_time_ms: 10274.526\n",
      "  update_time_ms: 3.356\n",
      "timestamp: 1645200713\n",
      "timesteps_since_restore: 151962\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 151962\n",
      "training_iteration: 19\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 159960\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-12-03\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 39\n",
      "episodes_total: 1268\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0011718750465661287\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5476995706558228\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032266832422465086\n",
      "        model: {}\n",
      "        policy_loss: 0.0007005110965110362\n",
      "        total_loss: 302.9565734863281\n",
      "        vf_explained_var: 0.6150109767913818\n",
      "        vf_loss: 302.95587158203125\n",
      "  num_agent_steps_sampled: 159960\n",
      "  num_agent_steps_trained: 159960\n",
      "  num_steps_sampled: 159960\n",
      "  num_steps_trained: 159960\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 20\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 70.02142857142856\n",
      "  ram_util_percent: 15.5\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0940572573588684\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09598271570560969\n",
      "  mean_inference_ms: 1.0360338026181162\n",
      "  mean_raw_obs_processing_ms: 0.12753450899013302\n",
      "time_since_restore: 205.2367067337036\n",
      "time_this_iter_s: 9.830435276031494\n",
      "time_total_s: 205.2367067337036\n",
      "timers:\n",
      "  learn_throughput: 1225.022\n",
      "  learn_time_ms: 6528.865\n",
      "  load_throughput: 21452991.873\n",
      "  load_time_ms: 0.373\n",
      "  sample_throughput: 781.852\n",
      "  sample_time_ms: 10229.552\n",
      "  update_time_ms: 3.325\n",
      "timestamp: 1645200723\n",
      "timesteps_since_restore: 159960\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 159960\n",
      "training_iteration: 20\n",
      "trial_id: default\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 167958\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-12-13\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 39\n",
      "episodes_total: 1307\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0005859375232830644\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5221631526947021\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004582822322845459\n",
      "        model: {}\n",
      "        policy_loss: 0.005140586756169796\n",
      "        total_loss: 426.9359436035156\n",
      "        vf_explained_var: 0.3953430652618408\n",
      "        vf_loss: 426.93084716796875\n",
      "  num_agent_steps_sampled: 167958\n",
      "  num_agent_steps_trained: 167958\n",
      "  num_steps_sampled: 167958\n",
      "  num_steps_trained: 167958\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 21\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 70.34285714285714\n",
      "  ram_util_percent: 15.485714285714286\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09383522926782555\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09576012005999505\n",
      "  mean_inference_ms: 1.0336668591040254\n",
      "  mean_raw_obs_processing_ms: 0.1271361244386823\n",
      "time_since_restore: 215.16119265556335\n",
      "time_this_iter_s: 9.924485921859741\n",
      "time_total_s: 215.16119265556335\n",
      "timers:\n",
      "  learn_throughput: 1230.263\n",
      "  learn_time_ms: 6501.048\n",
      "  load_throughput: 21955653.768\n",
      "  load_time_ms: 0.364\n",
      "  sample_throughput: 784.713\n",
      "  sample_time_ms: 10192.264\n",
      "  update_time_ms: 3.271\n",
      "timestamp: 1645200733\n",
      "timesteps_since_restore: 167958\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 167958\n",
      "training_iteration: 21\n",
      "trial_id: default\n",
      "\n",
      "checkpoint saved at /home/dojm.ex5/ray_results/PPOTrainer_CartPole-v0_2022-02-18_16-08-30gfueqw0q/checkpoint_000021/checkpoint-21\n",
      "agent_timesteps_total: 175956\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-12-23\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 42\n",
      "episodes_total: 1349\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0002929687616415322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5376864075660706\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005923844408243895\n",
      "        model: {}\n",
      "        policy_loss: -0.0023868302814662457\n",
      "        total_loss: 435.89483642578125\n",
      "        vf_explained_var: 0.3279728293418884\n",
      "        vf_loss: 435.8972473144531\n",
      "  num_agent_steps_sampled: 175956\n",
      "  num_agent_steps_trained: 175956\n",
      "  num_steps_sampled: 175956\n",
      "  num_steps_trained: 175956\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 22\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 69.88571428571429\n",
      "  ram_util_percent: 15.400000000000002\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0935870501280546\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09554717481861891\n",
      "  mean_inference_ms: 1.0311935982823228\n",
      "  mean_raw_obs_processing_ms: 0.1267296360262428\n",
      "time_since_restore: 224.8114881515503\n",
      "time_this_iter_s: 9.650295495986938\n",
      "time_total_s: 224.8114881515503\n",
      "timers:\n",
      "  learn_throughput: 1239.711\n",
      "  learn_time_ms: 6451.502\n",
      "  load_throughput: 21984431.085\n",
      "  load_time_ms: 0.364\n",
      "  sample_throughput: 788.178\n",
      "  sample_time_ms: 10147.452\n",
      "  update_time_ms: 3.175\n",
      "timestamp: 1645200743\n",
      "timesteps_since_restore: 175956\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 175956\n",
      "training_iteration: 22\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 183954\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-12-33\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 39\n",
      "episodes_total: 1388\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0002929687616415322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5101556777954102\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002829772187396884\n",
      "        model: {}\n",
      "        policy_loss: 0.0023312794510275126\n",
      "        total_loss: 472.3448791503906\n",
      "        vf_explained_var: 0.24742305278778076\n",
      "        vf_loss: 472.3425598144531\n",
      "  num_agent_steps_sampled: 183954\n",
      "  num_agent_steps_trained: 183954\n",
      "  num_steps_sampled: 183954\n",
      "  num_steps_trained: 183954\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 23\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 70.13571428571427\n",
      "  ram_util_percent: 15.400000000000002\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09341474500980508\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09540431447422078\n",
      "  mean_inference_ms: 1.0294834889607012\n",
      "  mean_raw_obs_processing_ms: 0.12644653832708141\n",
      "time_since_restore: 234.52120804786682\n",
      "time_this_iter_s: 9.709719896316528\n",
      "time_total_s: 234.52120804786682\n",
      "timers:\n",
      "  learn_throughput: 1259.723\n",
      "  learn_time_ms: 6349.017\n",
      "  load_throughput: 22168942.236\n",
      "  load_time_ms: 0.361\n",
      "  sample_throughput: 793.816\n",
      "  sample_time_ms: 10075.387\n",
      "  update_time_ms: 3.116\n",
      "timestamp: 1645200753\n",
      "timesteps_since_restore: 183954\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 183954\n",
      "training_iteration: 23\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 191952\n",
      "custom_metrics: {}\n",
      "date: 2022-02-18_16-12-43\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 39\n",
      "episodes_total: 1427\n",
      "experiment_id: 327d1dbbe72c4525b9d45deb77bbd6f5\n",
      "hostname: instance-1\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0001464843808207661\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4960732161998749\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006995004136115313\n",
      "        model: {}\n",
      "        policy_loss: 0.0016203013947233558\n",
      "        total_loss: 490.48101806640625\n",
      "        vf_explained_var: 0.19856062531471252\n",
      "        vf_loss: 490.4793701171875\n",
      "  num_agent_steps_sampled: 191952\n",
      "  num_agent_steps_trained: 191952\n",
      "  num_steps_sampled: 191952\n",
      "  num_steps_trained: 191952\n",
      "  num_steps_trained_this_iter: 7998\n",
      "iterations_since_restore: 24\n",
      "node_ip: 10.182.0.2\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 70.68571428571428\n",
      "  ram_util_percent: 15.450000000000001\n",
      "pid: 21861\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09326244664812229\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09523362466541521\n",
      "  mean_inference_ms: 1.0278829688994378\n",
      "  mean_raw_obs_processing_ms: 0.12617082038477048\n",
      "time_since_restore: 244.3232970237732\n",
      "time_this_iter_s: 9.802088975906372\n",
      "time_total_s: 244.3232970237732\n",
      "timers:\n",
      "  learn_throughput: 1271.336\n",
      "  learn_time_ms: 6291.02\n",
      "  load_throughput: 22548930.155\n",
      "  load_time_ms: 0.355\n",
      "  sample_throughput: 803.492\n",
      "  sample_time_ms: 9954.052\n",
      "  update_time_ms: 3.11\n",
      "timestamp: 1645200763\n",
      "timesteps_since_restore: 191952\n",
      "timesteps_this_iter: 7998\n",
      "timesteps_total: 191952\n",
      "training_iteration: 24\n",
      "trial_id: default\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# episode 1000 \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pretty_print(result))\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/tune/trainable.py:315\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m\"\"\"Runs one logical iteration of training.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03mCalls ``step()`` internally. Subclasses should override ``step()``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    A dict that describes training progress.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    314\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 315\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep() needs to return a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# We do not modify internal state nor update this result if duplicate.\u001b[39;00m\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:963\u001b[0m, in \u001b[0;36mTrainer.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m step_ctx\u001b[38;5;241m.\u001b[39mshould_stop(step_attempt_results):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Try to train one step.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 963\u001b[0m         step_attempt_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_attempt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;66;03m# @ray.remote RolloutWorker failure.\u001b[39;00m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RayError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    966\u001b[0m         \u001b[38;5;66;03m# Try to recover w/o the failed worker.\u001b[39;00m\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:1042\u001b[0m, in \u001b[0;36mTrainer.step_attempt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evaluate_this_iter:\n\u001b[0;32m-> 1042\u001b[0m     step_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_plan_or_training_iteration_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# We have to evaluate in this training iteration.\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# No parallelism.\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_parallel_to_training\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:1962\u001b[0m, in \u001b[0;36mTrainer._exec_plan_or_training_iteration_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1960\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_iteration()\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_exec_impl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/util/iter.py:756\u001b[0m, in \u001b[0;36mLocalIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_once()\n\u001b[0;32m--> 756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilt_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/util/iter.py:783\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/util/iter.py:783\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/util/iter.py:843\u001b[0m, in \u001b[0;36mLocalIterator.filter.<locals>.apply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_filter\u001b[39m(it):\n\u001b[0;32m--> 843\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    844\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics_context():\n\u001b[1;32m    845\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady) \u001b[38;5;129;01mor\u001b[39;00m fn(item):\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/util/iter.py:843\u001b[0m, in \u001b[0;36mLocalIterator.filter.<locals>.apply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_filter\u001b[39m(it):\n\u001b[0;32m--> 843\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    844\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics_context():\n\u001b[1;32m    845\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady) \u001b[38;5;129;01mor\u001b[39;00m fn(item):\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/util/iter.py:783\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/util/iter.py:783\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/util/iter.py:791\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics_context():\n\u001b[0;32m--> 791\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m result\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, _NextValueNotReady):\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/rllib/execution/train_ops.py:336\u001b[0m, in \u001b[0;36mMultiGPUTrainOneStep.__call__\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    331\u001b[0m         permutation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(num_batches)\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;66;03m# Learn on the pre-loaded data in the buffer.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m             \u001b[38;5;66;03m# Note: For minibatch SGD, the data is an offset into\u001b[39;00m\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;66;03m# the pre-loaded entire train batch.\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m             results \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_on_loaded_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\n\u001b[1;32m    338\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mper_device_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbuffer_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m             learner_info_builder\u001b[38;5;241m.\u001b[39madd_learn_on_batch_results(\n\u001b[1;32m    342\u001b[0m                 results, policy_id)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# Tower reduce and finalize results.\u001b[39;00m\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py:549\u001b[0m, in \u001b[0;36mDynamicTFPolicy.learn_on_loaded_batch\u001b[0;34m(self, offset, buffer_index)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    547\u001b[0m         sliced_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loaded_single_cpu_batch\u001b[38;5;241m.\u001b[39mslice(\n\u001b[1;32m    548\u001b[0m             start\u001b[38;5;241m=\u001b[39moffset, end\u001b[38;5;241m=\u001b[39moffset \u001b[38;5;241m+\u001b[39m batch_size)\n\u001b[0;32m--> 549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msliced_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_gpu_tower_stacks[buffer_index]\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_session(), offset)\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:420\u001b[0m, in \u001b[0;36mTFPolicy.learn_on_batch\u001b[0;34m(self, postprocessed_batch)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_learn_on_batch(\n\u001b[1;32m    417\u001b[0m     policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, train_batch\u001b[38;5;241m=\u001b[39mpostprocessed_batch, result\u001b[38;5;241m=\u001b[39mlearn_stats)\n\u001b[1;32m    419\u001b[0m fetches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_learn_on_batch(builder, postprocessed_batch)\n\u001b[0;32m--> 420\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m stats\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m: learn_stats})\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stats\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py:42\u001b[0m, in \u001b[0;36mTFRunBuilder.get\u001b[0;34m(self, to_fetch)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m \u001b[43mrun_timeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTF_TIMELINE_DIR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     46\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError fetching: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, feed_dict=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     47\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_dict))\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py:92\u001b[0m, in \u001b[0;36mrun_timeline\u001b[0;34m(sess, ops, debug_name, feed_dict, timeline_dir)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m log_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_timeline\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     89\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m     90\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuting TF run without tracing. To dump TF timeline traces \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto disk, set the TF_TIMELINE_DIR environment variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m     fetches \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fetches\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    964\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 967\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    970\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py:1190\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1190\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1193\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py:1370\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1367\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1370\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py:1377\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1376\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1379\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py:1360\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1358\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1360\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py:1453\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1452\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1453\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ppo    config   gpu, cpu \n",
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"num_gpus\"] = 0\n",
    "config[\"num_workers\"] = 3\n",
    "\n",
    "trainer = ppo.PPOTrainer(config=config, env=\"CartPole-v0\")\n",
    "\n",
    "# episode 1000 \n",
    "for i in range(100):\n",
    "    result = trainer.train()\n",
    "    print(pretty_print(result))\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        checkpoint = trainer.save()\n",
    "        print(f\"checkpoint saved at {checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a9bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   \n",
    "#     ...\n",
    "\n",
    "# trainer.import_model(\"my_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d233037",
   "metadata": {},
   "source": [
    "## Tune PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bc90db9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0218 16:13:00.752106292   21861 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0218 16:13:00.815024798   21861 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0218 16:13:00.875588150   21861 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0218 16:13:01.911335820   21861 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0218 16:13:01.949295161   21861 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0218 16:13:01.980245483   21861 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.182.0.2',\n",
       " 'raylet_ip_address': '10.182.0.2',\n",
       " 'redis_address': '10.182.0.2:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2022-02-18_16-13-00_748598_21861/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-02-18_16-13-00_748598_21861/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2022-02-18_16-13-00_748598_21861',\n",
       " 'metrics_export_port': 64624,\n",
       " 'gcs_address': '10.182.0.2:39121',\n",
       " 'node_id': '147da9084cfdcd66dbce221942465ce530a1a84cd7d0b457ee7366fd'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ray.tune           \n",
    "# tune.run   run  , config env    .\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "350c1ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0218 16:13:03.400821745   21861 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m 2022-02-18 16:13:07,732\tINFO trainer.py:2054 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m 2022-02-18 16:13:07,733\tWARNING ppo.py:223 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 1333.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m 2022-02-18 16:13:07,733\tINFO ppo.py:249 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m 2022-02-18 16:13:07,733\tINFO trainer.py:790 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m 2022-02-18 16:13:13,434\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m 2022-02-18 16:13:13,959\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m 2022-02-18 16:13:14,073\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:13:14 (running for 00:00:11.37)<br>Memory usage on this node: 2.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m 2022-02-18 16:13:14,813\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:13:15 (running for 00:00:12.39)<br>Memory usage on this node: 2.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m 2022-02-18 16:13:18,651\tWARNING deprecation.py:45 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:13:20 (running for 00:00:17.41)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 7998\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-13-25\n",
      "  done: false\n",
      "  episode_len_mean: 22.623229461756374\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 80.0\n",
      "  episode_reward_mean: 22.623229461756374\n",
      "  episode_reward_min: 8.0\n",
      "  episodes_this_iter: 353\n",
      "  episodes_total: 353\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.6563196778297424\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03812983259558678\n",
      "          model: {}\n",
      "          policy_loss: -0.049582336097955704\n",
      "          total_loss: 103.78666687011719\n",
      "          vf_explained_var: 0.3413936197757721\n",
      "          vf_loss: 103.82862854003906\n",
      "    num_agent_steps_sampled: 7998\n",
      "    num_agent_steps_trained: 7998\n",
      "    num_steps_sampled: 7998\n",
      "    num_steps_trained: 7998\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.32\n",
      "    ram_util_percent: 17.659999999999993\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09387797896211246\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09577065275640104\n",
      "    mean_inference_ms: 1.0468017956563476\n",
      "    mean_raw_obs_processing_ms: 0.14701470898105942\n",
      "  time_since_restore: 10.200247526168823\n",
      "  time_this_iter_s: 10.200247526168823\n",
      "  time_total_s: 10.200247526168823\n",
      "  timers:\n",
      "    learn_throughput: 1259.398\n",
      "    learn_time_ms: 6350.655\n",
      "    load_throughput: 26351958.674\n",
      "    load_time_ms: 0.304\n",
      "    sample_throughput: 2082.862\n",
      "    sample_time_ms: 3839.909\n",
      "    update_time_ms: 3.672\n",
      "  timestamp: 1645200805\n",
      "  timesteps_since_restore: 7998\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 7998\n",
      "  training_iteration: 1\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:13:26 (running for 00:00:22.64)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.2002</td><td style=\"text-align: right;\">7998</td><td style=\"text-align: right;\"> 22.6232</td><td style=\"text-align: right;\">                  80</td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">           22.6232</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:13:31 (running for 00:00:27.66)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.2002</td><td style=\"text-align: right;\">7998</td><td style=\"text-align: right;\"> 22.6232</td><td style=\"text-align: right;\">                  80</td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">           22.6232</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 15996\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-13-34\n",
      "  done: false\n",
      "  episode_len_mean: 55.13286713286713\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 173.0\n",
      "  episode_reward_mean: 55.13286713286713\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 496\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.5854977965354919\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023461971431970596\n",
      "          model: {}\n",
      "          policy_loss: -0.022705968469381332\n",
      "          total_loss: 394.87762451171875\n",
      "          vf_explained_var: 0.28944504261016846\n",
      "          vf_loss: 394.8932800292969\n",
      "    num_agent_steps_sampled: 15996\n",
      "    num_agent_steps_trained: 15996\n",
      "    num_steps_sampled: 15996\n",
      "    num_steps_trained: 15996\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.44285714285715\n",
      "    ram_util_percent: 17.699999999999996\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0917301617112963\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09317882987465649\n",
      "    mean_inference_ms: 1.0208070215875933\n",
      "    mean_raw_obs_processing_ms: 0.13622421623379116\n",
      "  time_since_restore: 19.951399564743042\n",
      "  time_this_iter_s: 9.751152038574219\n",
      "  time_total_s: 19.951399564743042\n",
      "  timers:\n",
      "    learn_throughput: 1275.989\n",
      "    learn_time_ms: 6268.08\n",
      "    load_throughput: 26331274.248\n",
      "    load_time_ms: 0.304\n",
      "    sample_throughput: 1159.385\n",
      "    sample_time_ms: 6898.487\n",
      "    update_time_ms: 3.732\n",
      "  timestamp: 1645200814\n",
      "  timesteps_since_restore: 15996\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 15996\n",
      "  training_iteration: 2\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:13:36 (running for 00:00:33.42)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         19.9514</td><td style=\"text-align: right;\">15996</td><td style=\"text-align: right;\"> 55.1329</td><td style=\"text-align: right;\">                 173</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">           55.1329</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:13:41 (running for 00:00:38.44)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         19.9514</td><td style=\"text-align: right;\">15996</td><td style=\"text-align: right;\"> 55.1329</td><td style=\"text-align: right;\">                 173</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">           55.1329</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 23994\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-13-44\n",
      "  done: false\n",
      "  episode_len_mean: 99.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 99.29\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 551\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.5482329726219177\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029056033119559288\n",
      "          model: {}\n",
      "          policy_loss: 0.0015300814993679523\n",
      "          total_loss: 785.9194946289062\n",
      "          vf_explained_var: 0.3188325762748718\n",
      "          vf_loss: 785.9048461914062\n",
      "    num_agent_steps_sampled: 23994\n",
      "    num_agent_steps_trained: 23994\n",
      "    num_steps_sampled: 23994\n",
      "    num_steps_trained: 23994\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.56428571428572\n",
      "    ram_util_percent: 17.699999999999996\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09106593762445524\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09267046039536064\n",
      "    mean_inference_ms: 1.0171563245147839\n",
      "    mean_raw_obs_processing_ms: 0.13244748416408497\n",
      "  time_since_restore: 29.452428579330444\n",
      "  time_this_iter_s: 9.501029014587402\n",
      "  time_total_s: 29.452428579330444\n",
      "  timers:\n",
      "    learn_throughput: 1297.788\n",
      "    learn_time_ms: 6162.795\n",
      "    load_throughput: 26786832.626\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 1018.52\n",
      "    sample_time_ms: 7852.572\n",
      "    update_time_ms: 3.414\n",
      "  timestamp: 1645200824\n",
      "  timesteps_since_restore: 23994\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 23994\n",
      "  training_iteration: 3\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:13:47 (running for 00:00:43.96)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         29.4524</td><td style=\"text-align: right;\">23994</td><td style=\"text-align: right;\">   99.29</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">             99.29</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:13:52 (running for 00:00:48.98)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         29.4524</td><td style=\"text-align: right;\">23994</td><td style=\"text-align: right;\">   99.29</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">             99.29</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 31992\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-13-53\n",
      "  done: false\n",
      "  episode_len_mean: 140.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 140.24\n",
      "  episode_reward_min: 14.0\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 609\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.5461025238037109\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010036826133728027\n",
      "          model: {}\n",
      "          policy_loss: -0.009099910967051983\n",
      "          total_loss: 317.2502136230469\n",
      "          vf_explained_var: 0.5953806042671204\n",
      "          vf_loss: 317.2525634765625\n",
      "    num_agent_steps_sampled: 31992\n",
      "    num_agent_steps_trained: 31992\n",
      "    num_steps_sampled: 31992\n",
      "    num_steps_trained: 31992\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.03076923076922\n",
      "    ram_util_percent: 17.699999999999996\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09078699490387145\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09235899961721303\n",
      "    mean_inference_ms: 1.0104917669167535\n",
      "    mean_raw_obs_processing_ms: 0.12848549225824013\n",
      "  time_since_restore: 39.02156710624695\n",
      "  time_this_iter_s: 9.569138526916504\n",
      "  time_total_s: 39.02156710624695\n",
      "  timers:\n",
      "    learn_throughput: 1303.343\n",
      "    learn_time_ms: 6136.527\n",
      "    load_throughput: 25904280.612\n",
      "    load_time_ms: 0.309\n",
      "    sample_throughput: 968.072\n",
      "    sample_time_ms: 8261.781\n",
      "    update_time_ms: 3.153\n",
      "  timestamp: 1645200833\n",
      "  timesteps_since_restore: 31992\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 31992\n",
      "  training_iteration: 4\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:13:58 (running for 00:00:54.54)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         39.0216</td><td style=\"text-align: right;\">31992</td><td style=\"text-align: right;\">  140.24</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  14</td><td style=\"text-align: right;\">            140.24</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:14:03 (running for 00:00:59.56)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         39.0216</td><td style=\"text-align: right;\">31992</td><td style=\"text-align: right;\">  140.24</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  14</td><td style=\"text-align: right;\">            140.24</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 39990\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-14-03\n",
      "  done: false\n",
      "  episode_len_mean: 145.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 145.89\n",
      "  episode_reward_min: 14.0\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 661\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.5112403035163879\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010761898942291737\n",
      "          model: {}\n",
      "          policy_loss: -0.003086635610088706\n",
      "          total_loss: 125.67259979248047\n",
      "          vf_explained_var: 0.8515458106994629\n",
      "          vf_loss: 125.66841125488281\n",
      "    num_agent_steps_sampled: 39990\n",
      "    num_agent_steps_trained: 39990\n",
      "    num_steps_sampled: 39990\n",
      "    num_steps_trained: 39990\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.69999999999999\n",
      "    ram_util_percent: 17.699999999999996\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09020259631532773\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09175685240003617\n",
      "    mean_inference_ms: 1.004248830840176\n",
      "    mean_raw_obs_processing_ms: 0.12571028872399176\n",
      "  time_since_restore: 48.60979151725769\n",
      "  time_this_iter_s: 9.588224411010742\n",
      "  time_total_s: 48.60979151725769\n",
      "  timers:\n",
      "    learn_throughput: 1304.491\n",
      "    learn_time_ms: 6131.128\n",
      "    load_throughput: 26244753.084\n",
      "    load_time_ms: 0.305\n",
      "    sample_throughput: 938.608\n",
      "    sample_time_ms: 8521.128\n",
      "    update_time_ms: 3.06\n",
      "  timestamp: 1645200843\n",
      "  timesteps_since_restore: 39990\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 39990\n",
      "  training_iteration: 5\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:14:08 (running for 00:01:05.18)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         48.6098</td><td style=\"text-align: right;\">39990</td><td style=\"text-align: right;\">  145.89</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  14</td><td style=\"text-align: right;\">            145.89</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:14:13 (running for 00:01:10.20)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         48.6098</td><td style=\"text-align: right;\">39990</td><td style=\"text-align: right;\">  145.89</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  14</td><td style=\"text-align: right;\">            145.89</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 47988\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-14-13\n",
      "  done: false\n",
      "  episode_len_mean: 150.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 150.42\n",
      "  episode_reward_min: 79.0\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 715\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.5024617910385132\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012433185242116451\n",
      "          model: {}\n",
      "          policy_loss: -0.006217490416020155\n",
      "          total_loss: 100.6497802734375\n",
      "          vf_explained_var: 0.8781093955039978\n",
      "          vf_loss: 100.6476058959961\n",
      "    num_agent_steps_sampled: 47988\n",
      "    num_agent_steps_trained: 47988\n",
      "    num_steps_sampled: 47988\n",
      "    num_steps_trained: 47988\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.09999999999998\n",
      "    ram_util_percent: 17.699999999999996\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08978877753189267\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09119114191257514\n",
      "    mean_inference_ms: 0.9982817435907996\n",
      "    mean_raw_obs_processing_ms: 0.12368392881628196\n",
      "  time_since_restore: 58.95866632461548\n",
      "  time_this_iter_s: 10.348874807357788\n",
      "  time_total_s: 58.95866632461548\n",
      "  timers:\n",
      "    learn_throughput: 1280.781\n",
      "    learn_time_ms: 6244.626\n",
      "    load_throughput: 25150101.256\n",
      "    load_time_ms: 0.318\n",
      "    sample_throughput: 917.994\n",
      "    sample_time_ms: 8712.475\n",
      "    update_time_ms: 3.195\n",
      "  timestamp: 1645200853\n",
      "  timesteps_since_restore: 47988\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 47988\n",
      "  training_iteration: 6\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:14:18 (running for 00:01:15.53)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         58.9587</td><td style=\"text-align: right;\">47988</td><td style=\"text-align: right;\">  150.42</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  79</td><td style=\"text-align: right;\">            150.42</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 55986\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-14-23\n",
      "  done: false\n",
      "  episode_len_mean: 158.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 158.36\n",
      "  episode_reward_min: 79.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 762\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.5008154511451721\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006025450769811869\n",
      "          model: {}\n",
      "          policy_loss: -0.004031640477478504\n",
      "          total_loss: 133.00575256347656\n",
      "          vf_explained_var: 0.8178073167800903\n",
      "          vf_loss: 133.00570678710938\n",
      "    num_agent_steps_sampled: 55986\n",
      "    num_agent_steps_trained: 55986\n",
      "    num_steps_sampled: 55986\n",
      "    num_steps_trained: 55986\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.81428571428572\n",
      "    ram_util_percent: 17.699999999999996\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08993147834286205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09131707489315836\n",
      "    mean_inference_ms: 0.9983177264439204\n",
      "    mean_raw_obs_processing_ms: 0.12303417596001433\n",
      "  time_since_restore: 68.80204105377197\n",
      "  time_this_iter_s: 9.843374729156494\n",
      "  time_total_s: 68.80204105377197\n",
      "  timers:\n",
      "    learn_throughput: 1282.468\n",
      "    learn_time_ms: 6236.413\n",
      "    load_throughput: 24694742.217\n",
      "    load_time_ms: 0.324\n",
      "    sample_throughput: 891.929\n",
      "    sample_time_ms: 8967.078\n",
      "    update_time_ms: 3.116\n",
      "  timestamp: 1645200863\n",
      "  timesteps_since_restore: 55986\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 55986\n",
      "  training_iteration: 7\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:14:24 (running for 00:01:21.35)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">          68.802</td><td style=\"text-align: right;\">55986</td><td style=\"text-align: right;\">  158.36</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  79</td><td style=\"text-align: right;\">            158.36</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:14:29 (running for 00:01:26.42)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">          68.802</td><td style=\"text-align: right;\">55986</td><td style=\"text-align: right;\">  158.36</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  79</td><td style=\"text-align: right;\">            158.36</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 63984\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-14-33\n",
      "  done: false\n",
      "  episode_len_mean: 170.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 170.93\n",
      "  episode_reward_min: 97.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 807\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.4798318147659302\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03719320893287659\n",
      "          model: {}\n",
      "          policy_loss: 0.005044438876211643\n",
      "          total_loss: 169.7579345703125\n",
      "          vf_explained_var: 0.7574735879898071\n",
      "          vf_loss: 169.727783203125\n",
      "    num_agent_steps_sampled: 63984\n",
      "    num_agent_steps_trained: 63984\n",
      "    num_steps_sampled: 63984\n",
      "    num_steps_trained: 63984\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.70714285714287\n",
      "    ram_util_percent: 17.699999999999996\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09004473082343627\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0914945089945169\n",
      "    mean_inference_ms: 1.0005860808211486\n",
      "    mean_raw_obs_processing_ms: 0.12271514629858851\n",
      "  time_since_restore: 78.45338559150696\n",
      "  time_this_iter_s: 9.651344537734985\n",
      "  time_total_s: 78.45338559150696\n",
      "  timers:\n",
      "    learn_throughput: 1286.194\n",
      "    learn_time_ms: 6218.345\n",
      "    load_throughput: 24773225.066\n",
      "    load_time_ms: 0.323\n",
      "    sample_throughput: 882.055\n",
      "    sample_time_ms: 9067.461\n",
      "    update_time_ms: 3.097\n",
      "  timestamp: 1645200873\n",
      "  timesteps_since_restore: 63984\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 63984\n",
      "  training_iteration: 8\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:14:35 (running for 00:01:32.03)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         78.4534</td><td style=\"text-align: right;\">63984</td><td style=\"text-align: right;\">  170.93</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            170.93</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:14:40 (running for 00:01:37.09)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         78.4534</td><td style=\"text-align: right;\">63984</td><td style=\"text-align: right;\">  170.93</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            170.93</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 71982\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-14-43\n",
      "  done: false\n",
      "  episode_len_mean: 144.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 144.09\n",
      "  episode_reward_min: 63.0\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 871\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.3428010940551758\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02739672176539898\n",
      "          model: {}\n",
      "          policy_loss: 0.01685418002307415\n",
      "          total_loss: 110.41184997558594\n",
      "          vf_explained_var: 0.8334566354751587\n",
      "          vf_loss: 110.36726379394531\n",
      "    num_agent_steps_sampled: 71982\n",
      "    num_agent_steps_trained: 71982\n",
      "    num_steps_sampled: 71982\n",
      "    num_steps_trained: 71982\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.12142857142857\n",
      "    ram_util_percent: 17.707142857142852\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09016147889767467\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09157854676581169\n",
      "    mean_inference_ms: 1.0014589083563659\n",
      "    mean_raw_obs_processing_ms: 0.12247239956368056\n",
      "  time_since_restore: 88.3340060710907\n",
      "  time_this_iter_s: 9.88062047958374\n",
      "  time_total_s: 88.3340060710907\n",
      "  timers:\n",
      "    learn_throughput: 1285.901\n",
      "    learn_time_ms: 6219.765\n",
      "    load_throughput: 24916595.736\n",
      "    load_time_ms: 0.321\n",
      "    sample_throughput: 874.587\n",
      "    sample_time_ms: 9144.886\n",
      "    update_time_ms: 3.084\n",
      "  timestamp: 1645200883\n",
      "  timesteps_since_restore: 71982\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 71982\n",
      "  training_iteration: 9\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:14:46 (running for 00:01:42.94)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">          88.334</td><td style=\"text-align: right;\">71982</td><td style=\"text-align: right;\">  144.09</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">            144.09</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:14:51 (running for 00:01:48.01)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">          88.334</td><td style=\"text-align: right;\">71982</td><td style=\"text-align: right;\">  144.09</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">            144.09</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 79980\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-14-53\n",
      "  done: false\n",
      "  episode_len_mean: 128.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 128.68\n",
      "  episode_reward_min: 63.0\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 933\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187499523162842\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.35199832916259766\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00377882132306695\n",
      "          model: {}\n",
      "          policy_loss: 0.0015623868675902486\n",
      "          total_loss: 75.85494232177734\n",
      "          vf_explained_var: 0.8908015489578247\n",
      "          vf_loss: 75.84764099121094\n",
      "    num_agent_steps_sampled: 79980\n",
      "    num_agent_steps_trained: 79980\n",
      "    num_steps_sampled: 79980\n",
      "    num_steps_trained: 79980\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.88571428571429\n",
      "    ram_util_percent: 17.78571428571429\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09033298133985372\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09164629864112277\n",
      "    mean_inference_ms: 1.0037298122684595\n",
      "    mean_raw_obs_processing_ms: 0.12258593116168398\n",
      "  time_since_restore: 98.02247381210327\n",
      "  time_this_iter_s: 9.688467741012573\n",
      "  time_total_s: 98.02247381210327\n",
      "  timers:\n",
      "    learn_throughput: 1289.29\n",
      "    learn_time_ms: 6203.415\n",
      "    load_throughput: 24980298.899\n",
      "    load_time_ms: 0.32\n",
      "    sample_throughput: 867.477\n",
      "    sample_time_ms: 9219.841\n",
      "    update_time_ms: 3.051\n",
      "  timestamp: 1645200893\n",
      "  timesteps_since_restore: 79980\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 79980\n",
      "  training_iteration: 10\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:14:57 (running for 00:01:53.66)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         98.0225</td><td style=\"text-align: right;\">79980</td><td style=\"text-align: right;\">  128.68</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">            128.68</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:15:02 (running for 00:01:58.72)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         98.0225</td><td style=\"text-align: right;\">79980</td><td style=\"text-align: right;\">  128.68</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">            128.68</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 87978\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-15-02\n",
      "  done: false\n",
      "  episode_len_mean: 127.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 127.25\n",
      "  episode_reward_min: 62.0\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 997\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.36956101655960083\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009445090778172016\n",
      "          model: {}\n",
      "          policy_loss: 0.0019622149411588907\n",
      "          total_loss: 74.072509765625\n",
      "          vf_explained_var: 0.8932039141654968\n",
      "          vf_loss: 74.0633773803711\n",
      "    num_agent_steps_sampled: 87978\n",
      "    num_agent_steps_trained: 87978\n",
      "    num_steps_sampled: 87978\n",
      "    num_steps_trained: 87978\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.58571428571429\n",
      "    ram_util_percent: 17.699999999999996\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09037775503285886\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09167987925140421\n",
      "    mean_inference_ms: 1.0039860616977947\n",
      "    mean_raw_obs_processing_ms: 0.1224052175523823\n",
      "  time_since_restore: 107.87538647651672\n",
      "  time_this_iter_s: 9.852912664413452\n",
      "  time_total_s: 107.87538647651672\n",
      "  timers:\n",
      "    learn_throughput: 1292.165\n",
      "    learn_time_ms: 6189.613\n",
      "    load_throughput: 24757227.596\n",
      "    load_time_ms: 0.323\n",
      "    sample_throughput: 815.472\n",
      "    sample_time_ms: 9807.819\n",
      "    update_time_ms: 3.195\n",
      "  timestamp: 1645200902\n",
      "  timesteps_since_restore: 87978\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 87978\n",
      "  training_iteration: 11\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:15:07 (running for 00:02:04.54)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         107.875</td><td style=\"text-align: right;\">87978</td><td style=\"text-align: right;\">  127.25</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  62</td><td style=\"text-align: right;\">            127.25</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 95976\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-15-12\n",
      "  done: false\n",
      "  episode_len_mean: 131.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 131.98\n",
      "  episode_reward_min: 62.0\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 1055\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.3719309866428375\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005352893378585577\n",
      "          model: {}\n",
      "          policy_loss: -0.0021865018643438816\n",
      "          total_loss: 80.34904479980469\n",
      "          vf_explained_var: 0.8334817290306091\n",
      "          vf_loss: 80.34716033935547\n",
      "    num_agent_steps_sampled: 95976\n",
      "    num_agent_steps_trained: 95976\n",
      "    num_steps_sampled: 95976\n",
      "    num_steps_trained: 95976\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.40714285714287\n",
      "    ram_util_percent: 17.699999999999996\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09040902168320496\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09166711125397463\n",
      "    mean_inference_ms: 1.0042298442653457\n",
      "    mean_raw_obs_processing_ms: 0.12225407418802098\n",
      "  time_since_restore: 117.72173023223877\n",
      "  time_this_iter_s: 9.846343755722046\n",
      "  time_total_s: 117.72173023223877\n",
      "  timers:\n",
      "    learn_throughput: 1290.762\n",
      "    learn_time_ms: 6196.34\n",
      "    load_throughput: 24328119.075\n",
      "    load_time_ms: 0.329\n",
      "    sample_throughput: 816.509\n",
      "    sample_time_ms: 9795.357\n",
      "    update_time_ms: 3.111\n",
      "  timestamp: 1645200912\n",
      "  timesteps_since_restore: 95976\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 95976\n",
      "  training_iteration: 12\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:15:13 (running for 00:02:10.45)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         117.722</td><td style=\"text-align: right;\">95976</td><td style=\"text-align: right;\">  131.98</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  62</td><td style=\"text-align: right;\">            131.98</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:15:18 (running for 00:02:15.49)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         117.722</td><td style=\"text-align: right;\">95976</td><td style=\"text-align: right;\">  131.98</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  62</td><td style=\"text-align: right;\">            131.98</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 103974\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-15-22\n",
      "  done: false\n",
      "  episode_len_mean: 140.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 140.89\n",
      "  episode_reward_min: 71.0\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 1109\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.3657454252243042\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011945944279432297\n",
      "          model: {}\n",
      "          policy_loss: 0.0044080461375415325\n",
      "          total_loss: 53.856300354003906\n",
      "          vf_explained_var: 0.9327297210693359\n",
      "          vf_loss: 53.84282684326172\n",
      "    num_agent_steps_sampled: 103974\n",
      "    num_agent_steps_trained: 103974\n",
      "    num_steps_sampled: 103974\n",
      "    num_steps_trained: 103974\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.10714285714286\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09068082808273069\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09196814392735891\n",
      "    mean_inference_ms: 1.0061347176357294\n",
      "    mean_raw_obs_processing_ms: 0.12241095042288754\n",
      "  time_since_restore: 127.70458555221558\n",
      "  time_this_iter_s: 9.982855319976807\n",
      "  time_total_s: 127.70458555221558\n",
      "  timers:\n",
      "    learn_throughput: 1285.195\n",
      "    learn_time_ms: 6223.179\n",
      "    load_throughput: 23354249.089\n",
      "    load_time_ms: 0.342\n",
      "    sample_throughput: 814.154\n",
      "    sample_time_ms: 9823.689\n",
      "    update_time_ms: 3.149\n",
      "  timestamp: 1645200922\n",
      "  timesteps_since_restore: 103974\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 103974\n",
      "  training_iteration: 13\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:15:24 (running for 00:02:21.47)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         127.705</td><td style=\"text-align: right;\">103974</td><td style=\"text-align: right;\">  140.89</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  71</td><td style=\"text-align: right;\">            140.89</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:15:29 (running for 00:02:26.49)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         127.705</td><td style=\"text-align: right;\">103974</td><td style=\"text-align: right;\">  140.89</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  71</td><td style=\"text-align: right;\">            140.89</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 111972\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-15-32\n",
      "  done: false\n",
      "  episode_len_mean: 151.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 151.74\n",
      "  episode_reward_min: 71.0\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 1162\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.3523932993412018\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005930595099925995\n",
      "          model: {}\n",
      "          policy_loss: -0.004008808173239231\n",
      "          total_loss: 83.49282836914062\n",
      "          vf_explained_var: 0.8696354627609253\n",
      "          vf_loss: 83.4923324584961\n",
      "    num_agent_steps_sampled: 111972\n",
      "    num_agent_steps_trained: 111972\n",
      "    num_steps_sampled: 111972\n",
      "    num_steps_trained: 111972\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.35000000000001\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09080264839291338\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09212859157351705\n",
      "    mean_inference_ms: 1.006710874373026\n",
      "    mean_raw_obs_processing_ms: 0.12232376547973299\n",
      "  time_since_restore: 137.26771545410156\n",
      "  time_this_iter_s: 9.563129901885986\n",
      "  time_total_s: 137.26771545410156\n",
      "  timers:\n",
      "    learn_throughput: 1286.561\n",
      "    learn_time_ms: 6216.572\n",
      "    load_throughput: 23411294.153\n",
      "    load_time_ms: 0.342\n",
      "    sample_throughput: 811.46\n",
      "    sample_time_ms: 9856.306\n",
      "    update_time_ms: 3.345\n",
      "  timestamp: 1645200932\n",
      "  timesteps_since_restore: 111972\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 111972\n",
      "  training_iteration: 14\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:15:35 (running for 00:02:32.04)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         137.268</td><td style=\"text-align: right;\">111972</td><td style=\"text-align: right;\">  151.74</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  71</td><td style=\"text-align: right;\">            151.74</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:15:40 (running for 00:02:37.07)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         137.268</td><td style=\"text-align: right;\">111972</td><td style=\"text-align: right;\">  151.74</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  71</td><td style=\"text-align: right;\">            151.74</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 119970\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-15-42\n",
      "  done: false\n",
      "  episode_len_mean: 156.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 156.33\n",
      "  episode_reward_min: 71.0\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 1213\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.3420014977455139\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018145715817809105\n",
      "          model: {}\n",
      "          policy_loss: 0.002927095629274845\n",
      "          total_loss: 172.57073974609375\n",
      "          vf_explained_var: 0.7238893508911133\n",
      "          vf_loss: 172.5540313720703\n",
      "    num_agent_steps_sampled: 119970\n",
      "    num_agent_steps_trained: 119970\n",
      "    num_steps_sampled: 119970\n",
      "    num_steps_trained: 119970\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.6\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09069360759352472\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09204337046477788\n",
      "    mean_inference_ms: 1.0044967471552269\n",
      "    mean_raw_obs_processing_ms: 0.12184581469258308\n",
      "  time_since_restore: 146.9747076034546\n",
      "  time_this_iter_s: 9.706992149353027\n",
      "  time_total_s: 146.9747076034546\n",
      "  timers:\n",
      "    learn_throughput: 1285.385\n",
      "    learn_time_ms: 6222.26\n",
      "    load_throughput: 23278081.599\n",
      "    load_time_ms: 0.344\n",
      "    sample_throughput: 811.431\n",
      "    sample_time_ms: 9856.664\n",
      "    update_time_ms: 3.345\n",
      "  timestamp: 1645200942\n",
      "  timesteps_since_restore: 119970\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 119970\n",
      "  training_iteration: 15\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:15:46 (running for 00:02:42.78)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         146.975</td><td style=\"text-align: right;\">119970</td><td style=\"text-align: right;\">  156.33</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  71</td><td style=\"text-align: right;\">            156.33</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:15:51 (running for 00:02:47.80)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         146.975</td><td style=\"text-align: right;\">119970</td><td style=\"text-align: right;\">  156.33</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  71</td><td style=\"text-align: right;\">            156.33</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 127968\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-15-52\n",
      "  done: false\n",
      "  episode_len_mean: 159.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 159.01\n",
      "  episode_reward_min: 84.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 1262\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.3597950339317322\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006443389225751162\n",
      "          model: {}\n",
      "          policy_loss: -0.00261673703789711\n",
      "          total_loss: 170.62339782714844\n",
      "          vf_explained_var: 0.756334125995636\n",
      "          vf_loss: 170.6211395263672\n",
      "    num_agent_steps_sampled: 127968\n",
      "    num_agent_steps_trained: 127968\n",
      "    num_steps_sampled: 127968\n",
      "    num_steps_trained: 127968\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.17857142857143\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0907073876574498\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09207783671709306\n",
      "    mean_inference_ms: 1.0039745903941024\n",
      "    mean_raw_obs_processing_ms: 0.12160543472349562\n",
      "  time_since_restore: 157.0123987197876\n",
      "  time_this_iter_s: 10.037691116333008\n",
      "  time_total_s: 157.0123987197876\n",
      "  timers:\n",
      "    learn_throughput: 1294.359\n",
      "    learn_time_ms: 6179.118\n",
      "    load_throughput: 23368891.252\n",
      "    load_time_ms: 0.342\n",
      "    sample_throughput: 809.959\n",
      "    sample_time_ms: 9874.577\n",
      "    update_time_ms: 3.221\n",
      "  timestamp: 1645200952\n",
      "  timesteps_since_restore: 127968\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 127968\n",
      "  training_iteration: 16\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:15:56 (running for 00:02:52.86)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         157.012</td><td style=\"text-align: right;\">127968</td><td style=\"text-align: right;\">  159.01</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  84</td><td style=\"text-align: right;\">            159.01</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:16:01 (running for 00:02:57.88)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         157.012</td><td style=\"text-align: right;\">127968</td><td style=\"text-align: right;\">  159.01</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  84</td><td style=\"text-align: right;\">            159.01</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 135966\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-16-01\n",
      "  done: false\n",
      "  episode_len_mean: 160.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 160.91\n",
      "  episode_reward_min: 83.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 1311\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.35914650559425354\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01860162243247032\n",
      "          model: {}\n",
      "          policy_loss: 0.003199506551027298\n",
      "          total_loss: 167.50439453125\n",
      "          vf_explained_var: 0.7177789211273193\n",
      "          vf_loss: 167.48707580566406\n",
      "    num_agent_steps_sampled: 135966\n",
      "    num_agent_steps_trained: 135966\n",
      "    num_steps_sampled: 135966\n",
      "    num_steps_trained: 135966\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.58571428571427\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09069745613695143\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0920592939567269\n",
      "    mean_inference_ms: 1.004047992661985\n",
      "    mean_raw_obs_processing_ms: 0.12145658169371072\n",
      "  time_since_restore: 166.7614073753357\n",
      "  time_this_iter_s: 9.749008655548096\n",
      "  time_total_s: 166.7614073753357\n",
      "  timers:\n",
      "    learn_throughput: 1293.044\n",
      "    learn_time_ms: 6185.402\n",
      "    load_throughput: 23562578.768\n",
      "    load_time_ms: 0.339\n",
      "    sample_throughput: 814.83\n",
      "    sample_time_ms: 9815.545\n",
      "    update_time_ms: 3.228\n",
      "  timestamp: 1645200961\n",
      "  timesteps_since_restore: 135966\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 135966\n",
      "  training_iteration: 17\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:16:07 (running for 00:03:03.62)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         166.761</td><td style=\"text-align: right;\">135966</td><td style=\"text-align: right;\">  160.91</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            160.91</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 143964\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-16-11\n",
      "  done: false\n",
      "  episode_len_mean: 160.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 160.67\n",
      "  episode_reward_min: 83.0\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 1362\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.3580566346645355\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0038129156455397606\n",
      "          model: {}\n",
      "          policy_loss: -0.030072098597884178\n",
      "          total_loss: 108.02054595947266\n",
      "          vf_explained_var: 0.845535397529602\n",
      "          vf_loss: 108.04771423339844\n",
      "    num_agent_steps_sampled: 143964\n",
      "    num_agent_steps_trained: 143964\n",
      "    num_steps_sampled: 143964\n",
      "    num_steps_trained: 143964\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.40000000000002\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09059655697835688\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09194873757676564\n",
      "    mean_inference_ms: 1.0031131259464636\n",
      "    mean_raw_obs_processing_ms: 0.1211800842726825\n",
      "  time_since_restore: 176.27163767814636\n",
      "  time_this_iter_s: 9.510230302810669\n",
      "  time_total_s: 176.27163767814636\n",
      "  timers:\n",
      "    learn_throughput: 1295.132\n",
      "    learn_time_ms: 6175.431\n",
      "    load_throughput: 23643955.027\n",
      "    load_time_ms: 0.338\n",
      "    sample_throughput: 814.591\n",
      "    sample_time_ms: 9818.422\n",
      "    update_time_ms: 3.241\n",
      "  timestamp: 1645200971\n",
      "  timesteps_since_restore: 143964\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 143964\n",
      "  training_iteration: 18\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:16:12 (running for 00:03:09.11)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         176.272</td><td style=\"text-align: right;\">143964</td><td style=\"text-align: right;\">  160.67</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            160.67</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:16:17 (running for 00:03:14.17)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         176.272</td><td style=\"text-align: right;\">143964</td><td style=\"text-align: right;\">  160.67</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            160.67</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 151962\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-16-21\n",
      "  done: false\n",
      "  episode_len_mean: 162.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 162.1\n",
      "  episode_reward_min: 81.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 1410\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.37968748807907104\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.3424537181854248\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011622203513979912\n",
      "          model: {}\n",
      "          policy_loss: -0.0006588486139662564\n",
      "          total_loss: 125.1579818725586\n",
      "          vf_explained_var: 0.837342381477356\n",
      "          vf_loss: 125.15422821044922\n",
      "    num_agent_steps_sampled: 151962\n",
      "    num_agent_steps_trained: 151962\n",
      "    num_steps_sampled: 151962\n",
      "    num_steps_trained: 151962\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.61538461538461\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09048209314798612\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09181628950618542\n",
      "    mean_inference_ms: 1.0022221658322934\n",
      "    mean_raw_obs_processing_ms: 0.12094433140419568\n",
      "  time_since_restore: 185.84161734580994\n",
      "  time_this_iter_s: 9.569979667663574\n",
      "  time_total_s: 185.84161734580994\n",
      "  timers:\n",
      "    learn_throughput: 1298.79\n",
      "    learn_time_ms: 6158.038\n",
      "    load_throughput: 23310432.487\n",
      "    load_time_ms: 0.343\n",
      "    sample_throughput: 816.546\n",
      "    sample_time_ms: 9794.921\n",
      "    update_time_ms: 3.215\n",
      "  timestamp: 1645200981\n",
      "  timesteps_since_restore: 151962\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 151962\n",
      "  training_iteration: 19\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:16:23 (running for 00:03:19.71)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         185.842</td><td style=\"text-align: right;\">151962</td><td style=\"text-align: right;\">   162.1</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  81</td><td style=\"text-align: right;\">             162.1</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:16:28 (running for 00:03:24.77)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         185.842</td><td style=\"text-align: right;\">151962</td><td style=\"text-align: right;\">   162.1</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  81</td><td style=\"text-align: right;\">             162.1</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 159960\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-16-30\n",
      "  done: false\n",
      "  episode_len_mean: 164.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 164.84\n",
      "  episode_reward_min: 81.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 1459\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.37968748807907104\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.29633060097694397\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03462636098265648\n",
      "          model: {}\n",
      "          policy_loss: 0.004040401428937912\n",
      "          total_loss: 140.65243530273438\n",
      "          vf_explained_var: 0.8076243996620178\n",
      "          vf_loss: 140.63525390625\n",
      "    num_agent_steps_sampled: 159960\n",
      "    num_agent_steps_trained: 159960\n",
      "    num_steps_sampled: 159960\n",
      "    num_steps_trained: 159960\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.31428571428572\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09041015594770974\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09172862237918095\n",
      "    mean_inference_ms: 1.0010437809457673\n",
      "    mean_raw_obs_processing_ms: 0.12072979746576624\n",
      "  time_since_restore: 195.35640835762024\n",
      "  time_this_iter_s: 9.514791011810303\n",
      "  time_total_s: 195.35640835762024\n",
      "  timers:\n",
      "    learn_throughput: 1300.751\n",
      "    learn_time_ms: 6148.757\n",
      "    load_throughput: 23499855.266\n",
      "    load_time_ms: 0.34\n",
      "    sample_throughput: 818.735\n",
      "    sample_time_ms: 9768.725\n",
      "    update_time_ms: 3.209\n",
      "  timestamp: 1645200990\n",
      "  timesteps_since_restore: 159960\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 159960\n",
      "  training_iteration: 20\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:16:33 (running for 00:03:30.25)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         195.356</td><td style=\"text-align: right;\">159960</td><td style=\"text-align: right;\">  164.84</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  81</td><td style=\"text-align: right;\">            164.84</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:16:38 (running for 00:03:35.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         195.356</td><td style=\"text-align: right;\">159960</td><td style=\"text-align: right;\">  164.84</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  81</td><td style=\"text-align: right;\">            164.84</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 167958\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-16-40\n",
      "  done: false\n",
      "  episode_len_mean: 168.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 168.79\n",
      "  episode_reward_min: 81.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 1506\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.569531261920929\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.20050247013568878\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.05889700725674629\n",
      "          model: {}\n",
      "          policy_loss: 0.013813000172376633\n",
      "          total_loss: 194.38246154785156\n",
      "          vf_explained_var: 0.7130165100097656\n",
      "          vf_loss: 194.33509826660156\n",
      "    num_agent_steps_sampled: 167958\n",
      "    num_agent_steps_trained: 167958\n",
      "    num_steps_sampled: 167958\n",
      "    num_steps_trained: 167958\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.22307692307692\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0903687177595312\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09170772140367671\n",
      "    mean_inference_ms: 1.001039661426629\n",
      "    mean_raw_obs_processing_ms: 0.12063576675091618\n",
      "  time_since_restore: 204.88550806045532\n",
      "  time_this_iter_s: 9.529099702835083\n",
      "  time_total_s: 204.88550806045532\n",
      "  timers:\n",
      "    learn_throughput: 1305.552\n",
      "    learn_time_ms: 6126.144\n",
      "    load_throughput: 23832085.388\n",
      "    load_time_ms: 0.336\n",
      "    sample_throughput: 820.312\n",
      "    sample_time_ms: 9749.946\n",
      "    update_time_ms: 2.945\n",
      "  timestamp: 1645201000\n",
      "  timesteps_since_restore: 167958\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 167958\n",
      "  training_iteration: 21\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:16:44 (running for 00:03:40.81)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         204.886</td><td style=\"text-align: right;\">167958</td><td style=\"text-align: right;\">  168.79</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  81</td><td style=\"text-align: right;\">            168.79</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:16:49 (running for 00:03:45.88)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         204.886</td><td style=\"text-align: right;\">167958</td><td style=\"text-align: right;\">  168.79</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  81</td><td style=\"text-align: right;\">            168.79</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 175956\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-16-50\n",
      "  done: false\n",
      "  episode_len_mean: 165.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 165.44\n",
      "  episode_reward_min: 87.0\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1556\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.854296863079071\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.2295999675989151\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009467183612287045\n",
      "          model: {}\n",
      "          policy_loss: -0.01945370063185692\n",
      "          total_loss: 149.9912109375\n",
      "          vf_explained_var: 0.7862793207168579\n",
      "          vf_loss: 150.00259399414062\n",
      "    num_agent_steps_sampled: 175956\n",
      "    num_agent_steps_trained: 175956\n",
      "    num_steps_sampled: 175956\n",
      "    num_steps_trained: 175956\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.0\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09034749686372429\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09166437120087784\n",
      "    mean_inference_ms: 1.0006609007572693\n",
      "    mean_raw_obs_processing_ms: 0.12050229939183903\n",
      "  time_since_restore: 214.6490135192871\n",
      "  time_this_iter_s: 9.763505458831787\n",
      "  time_total_s: 214.6490135192871\n",
      "  timers:\n",
      "    learn_throughput: 1305.494\n",
      "    learn_time_ms: 6126.414\n",
      "    load_throughput: 23799959.838\n",
      "    load_time_ms: 0.336\n",
      "    sample_throughput: 822.948\n",
      "    sample_time_ms: 9718.719\n",
      "    update_time_ms: 2.946\n",
      "  timestamp: 1645201010\n",
      "  timesteps_since_restore: 175956\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 175956\n",
      "  training_iteration: 22\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:16:55 (running for 00:03:51.60)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         214.649</td><td style=\"text-align: right;\">175956</td><td style=\"text-align: right;\">  165.44</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            165.44</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 183954\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-16-59\n",
      "  done: false\n",
      "  episode_len_mean: 163.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 163.53\n",
      "  episode_reward_min: 84.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 1602\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.854296863079071\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.21595020592212677\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006258292123675346\n",
      "          model: {}\n",
      "          policy_loss: 0.001434431760571897\n",
      "          total_loss: 133.78785705566406\n",
      "          vf_explained_var: 0.8327243328094482\n",
      "          vf_loss: 133.7810821533203\n",
      "    num_agent_steps_sampled: 183954\n",
      "    num_agent_steps_trained: 183954\n",
      "    num_steps_sampled: 183954\n",
      "    num_steps_trained: 183954\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.77857142857142\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09035216402869452\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09164160338720378\n",
      "    mean_inference_ms: 1.0007293134863313\n",
      "    mean_raw_obs_processing_ms: 0.12044303056086492\n",
      "  time_since_restore: 224.220787525177\n",
      "  time_this_iter_s: 9.571774005889893\n",
      "  time_total_s: 224.220787525177\n",
      "  timers:\n",
      "    learn_throughput: 1309.224\n",
      "    learn_time_ms: 6108.964\n",
      "    load_throughput: 24377620.371\n",
      "    load_time_ms: 0.328\n",
      "    sample_throughput: 824.941\n",
      "    sample_time_ms: 9695.243\n",
      "    update_time_ms: 2.896\n",
      "  timestamp: 1645201019\n",
      "  timesteps_since_restore: 183954\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 183954\n",
      "  training_iteration: 23\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:17:00 (running for 00:03:57.19)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         224.221</td><td style=\"text-align: right;\">183954</td><td style=\"text-align: right;\">  163.53</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  84</td><td style=\"text-align: right;\">            163.53</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:17:05 (running for 00:04:02.21)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         224.221</td><td style=\"text-align: right;\">183954</td><td style=\"text-align: right;\">  163.53</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  84</td><td style=\"text-align: right;\">            163.53</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 191952\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-17-09\n",
      "  done: false\n",
      "  episode_len_mean: 167.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 167.36\n",
      "  episode_reward_min: 84.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 1650\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.854296863079071\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.20105081796646118\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04611339420080185\n",
      "          model: {}\n",
      "          policy_loss: 0.008530955761671066\n",
      "          total_loss: 179.1567840576172\n",
      "          vf_explained_var: 0.7870320677757263\n",
      "          vf_loss: 179.10885620117188\n",
      "    num_agent_steps_sampled: 191952\n",
      "    num_agent_steps_trained: 191952\n",
      "    num_steps_sampled: 191952\n",
      "    num_steps_trained: 191952\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.59285714285714\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09037611707542417\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09165097044400351\n",
      "    mean_inference_ms: 1.0013162228814385\n",
      "    mean_raw_obs_processing_ms: 0.12046566985500705\n",
      "  time_since_restore: 234.07176876068115\n",
      "  time_this_iter_s: 9.85098123550415\n",
      "  time_total_s: 234.07176876068115\n",
      "  timers:\n",
      "    learn_throughput: 1303.931\n",
      "    learn_time_ms: 6133.76\n",
      "    load_throughput: 24224468.076\n",
      "    load_time_ms: 0.33\n",
      "    sample_throughput: 826.091\n",
      "    sample_time_ms: 9681.743\n",
      "    update_time_ms: 2.757\n",
      "  timestamp: 1645201029\n",
      "  timesteps_since_restore: 191952\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 191952\n",
      "  training_iteration: 24\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:17:11 (running for 00:04:08.10)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         234.072</td><td style=\"text-align: right;\">191952</td><td style=\"text-align: right;\">  167.36</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  84</td><td style=\"text-align: right;\">            167.36</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:17:16 (running for 00:04:13.13)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         234.072</td><td style=\"text-align: right;\">191952</td><td style=\"text-align: right;\">  167.36</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  84</td><td style=\"text-align: right;\">            167.36</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 199950\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-17-19\n",
      "  done: false\n",
      "  episode_len_mean: 169.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 169.93\n",
      "  episode_reward_min: 85.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 1698\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2814452648162842\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.21947671473026276\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01032229419797659\n",
      "          model: {}\n",
      "          policy_loss: -0.011534541845321655\n",
      "          total_loss: 247.7323760986328\n",
      "          vf_explained_var: 0.6601625680923462\n",
      "          vf_loss: 247.73068237304688\n",
      "    num_agent_steps_sampled: 199950\n",
      "    num_agent_steps_trained: 199950\n",
      "    num_steps_sampled: 199950\n",
      "    num_steps_trained: 199950\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.67857142857142\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09043658909307688\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09168905173944783\n",
      "    mean_inference_ms: 1.0005188207226872\n",
      "    mean_raw_obs_processing_ms: 0.12038750407182022\n",
      "  time_since_restore: 243.79242396354675\n",
      "  time_this_iter_s: 9.7206552028656\n",
      "  time_total_s: 243.79242396354675\n",
      "  timers:\n",
      "    learn_throughput: 1304.429\n",
      "    learn_time_ms: 6131.419\n",
      "    load_throughput: 23961459.566\n",
      "    load_time_ms: 0.334\n",
      "    sample_throughput: 823.697\n",
      "    sample_time_ms: 9709.886\n",
      "    update_time_ms: 2.739\n",
      "  timestamp: 1645201039\n",
      "  timesteps_since_restore: 199950\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 199950\n",
      "  training_iteration: 25\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:17:22 (running for 00:04:18.86)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         243.792</td><td style=\"text-align: right;\">199950</td><td style=\"text-align: right;\">  169.93</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  85</td><td style=\"text-align: right;\">            169.93</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:17:27 (running for 00:04:23.88)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         243.792</td><td style=\"text-align: right;\">199950</td><td style=\"text-align: right;\">  169.93</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  85</td><td style=\"text-align: right;\">            169.93</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 207948\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-17-28\n",
      "  done: false\n",
      "  episode_len_mean: 165.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 165.06\n",
      "  episode_reward_min: 85.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 1746\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2814452648162842\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.2053244411945343\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0036731993313878775\n",
      "          model: {}\n",
      "          policy_loss: 0.0020685559138655663\n",
      "          total_loss: 112.39591217041016\n",
      "          vf_explained_var: 0.8783342242240906\n",
      "          vf_loss: 112.38912963867188\n",
      "    num_agent_steps_sampled: 207948\n",
      "    num_agent_steps_trained: 207948\n",
      "    num_steps_sampled: 207948\n",
      "    num_steps_trained: 207948\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.49285714285715\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09042089025531885\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09164954937318219\n",
      "    mean_inference_ms: 0.9994787422320621\n",
      "    mean_raw_obs_processing_ms: 0.12027554169229962\n",
      "  time_since_restore: 253.25040745735168\n",
      "  time_this_iter_s: 9.457983493804932\n",
      "  time_total_s: 253.25040745735168\n",
      "  timers:\n",
      "    learn_throughput: 1313.209\n",
      "    learn_time_ms: 6090.423\n",
      "    load_throughput: 24083597.812\n",
      "    load_time_ms: 0.332\n",
      "    sample_throughput: 825.311\n",
      "    sample_time_ms: 9690.887\n",
      "    update_time_ms: 2.722\n",
      "  timestamp: 1645201048\n",
      "  timesteps_since_restore: 207948\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 207948\n",
      "  training_iteration: 26\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:17:32 (running for 00:04:29.35)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">          253.25</td><td style=\"text-align: right;\">207948</td><td style=\"text-align: right;\">  165.06</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  85</td><td style=\"text-align: right;\">            165.06</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:17:37 (running for 00:04:34.37)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">          253.25</td><td style=\"text-align: right;\">207948</td><td style=\"text-align: right;\">  165.06</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  85</td><td style=\"text-align: right;\">            165.06</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 215946\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-17-38\n",
      "  done: false\n",
      "  episode_len_mean: 161.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 161.81\n",
      "  episode_reward_min: 91.0\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1796\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226324081421\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.18346665799617767\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009501822292804718\n",
      "          model: {}\n",
      "          policy_loss: -0.00021397638192865998\n",
      "          total_loss: 128.60946655273438\n",
      "          vf_explained_var: 0.8021526336669922\n",
      "          vf_loss: 128.6035919189453\n",
      "    num_agent_steps_sampled: 215946\n",
      "    num_agent_steps_trained: 215946\n",
      "    num_steps_sampled: 215946\n",
      "    num_steps_trained: 215946\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.48461538461538\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09040265098268374\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09159152845706832\n",
      "    mean_inference_ms: 0.9989215032213156\n",
      "    mean_raw_obs_processing_ms: 0.12014545775963432\n",
      "  time_since_restore: 262.8668751716614\n",
      "  time_this_iter_s: 9.616467714309692\n",
      "  time_total_s: 262.8668751716614\n",
      "  timers:\n",
      "    learn_throughput: 1318.545\n",
      "    learn_time_ms: 6065.776\n",
      "    load_throughput: 24224468.076\n",
      "    load_time_ms: 0.33\n",
      "    sample_throughput: 827.845\n",
      "    sample_time_ms: 9661.233\n",
      "    update_time_ms: 2.707\n",
      "  timestamp: 1645201058\n",
      "  timesteps_since_restore: 215946\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 215946\n",
      "  training_iteration: 27\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:17:43 (running for 00:04:39.99)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         262.867</td><td style=\"text-align: right;\">215946</td><td style=\"text-align: right;\">  161.81</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            161.81</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 223944\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-17-48\n",
      "  done: false\n",
      "  episode_len_mean: 165.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 165.21\n",
      "  episode_reward_min: 91.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 1843\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226324081421\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.15844379365444183\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007773605640977621\n",
      "          model: {}\n",
      "          policy_loss: 0.0009647337137721479\n",
      "          total_loss: 172.06475830078125\n",
      "          vf_explained_var: 0.8003438711166382\n",
      "          vf_loss: 172.05880737304688\n",
      "    num_agent_steps_sampled: 223944\n",
      "    num_agent_steps_trained: 223944\n",
      "    num_steps_sampled: 223944\n",
      "    num_steps_trained: 223944\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.72142857142856\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09041224750716145\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09157103029265645\n",
      "    mean_inference_ms: 0.999478635156427\n",
      "    mean_raw_obs_processing_ms: 0.12013436026092558\n",
      "  time_since_restore: 272.6164152622223\n",
      "  time_this_iter_s: 9.749540090560913\n",
      "  time_total_s: 272.6164152622223\n",
      "  timers:\n",
      "    learn_throughput: 1313.652\n",
      "    learn_time_ms: 6088.37\n",
      "    load_throughput: 24213976.752\n",
      "    load_time_ms: 0.33\n",
      "    sample_throughput: 829.896\n",
      "    sample_time_ms: 9637.352\n",
      "    update_time_ms: 2.636\n",
      "  timestamp: 1645201068\n",
      "  timesteps_since_restore: 223944\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 223944\n",
      "  training_iteration: 28\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:17:49 (running for 00:04:45.71)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         272.616</td><td style=\"text-align: right;\">223944</td><td style=\"text-align: right;\">  165.21</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            165.21</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:17:54 (running for 00:04:50.78)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         272.616</td><td style=\"text-align: right;\">223944</td><td style=\"text-align: right;\">  165.21</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            165.21</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 231942\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-17-57\n",
      "  done: false\n",
      "  episode_len_mean: 167.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 167.72\n",
      "  episode_reward_min: 99.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 1892\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226324081421\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.1505027711391449\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013176508247852325\n",
      "          model: {}\n",
      "          policy_loss: 0.004753949586302042\n",
      "          total_loss: 151.5006866455078\n",
      "          vf_explained_var: 0.8214354515075684\n",
      "          vf_loss: 151.4875030517578\n",
      "    num_agent_steps_sampled: 231942\n",
      "    num_agent_steps_trained: 231942\n",
      "    num_steps_sampled: 231942\n",
      "    num_steps_trained: 231942\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.4357142857143\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09034656443455814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09150913870202189\n",
      "    mean_inference_ms: 0.9989988312609509\n",
      "    mean_raw_obs_processing_ms: 0.12004237466348819\n",
      "  time_since_restore: 282.1267695426941\n",
      "  time_this_iter_s: 9.510354280471802\n",
      "  time_total_s: 282.1267695426941\n",
      "  timers:\n",
      "    learn_throughput: 1314.397\n",
      "    learn_time_ms: 6084.92\n",
      "    load_throughput: 24338709.564\n",
      "    load_time_ms: 0.329\n",
      "    sample_throughput: 828.178\n",
      "    sample_time_ms: 9657.342\n",
      "    update_time_ms: 2.618\n",
      "  timestamp: 1645201077\n",
      "  timesteps_since_restore: 231942\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 231942\n",
      "  training_iteration: 29\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:17:59 (running for 00:04:56.24)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         282.127</td><td style=\"text-align: right;\">231942</td><td style=\"text-align: right;\">  167.72</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            167.72</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:18:04 (running for 00:05:01.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         282.127</td><td style=\"text-align: right;\">231942</td><td style=\"text-align: right;\">  167.72</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            167.72</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 239940\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-18-07\n",
      "  done: false\n",
      "  episode_len_mean: 161.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 161.0\n",
      "  episode_reward_min: 86.0\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 1943\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226324081421\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.16593220829963684\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.004615537356585264\n",
      "          model: {}\n",
      "          policy_loss: -0.0019219513051211834\n",
      "          total_loss: 169.56626892089844\n",
      "          vf_explained_var: 0.7769481539726257\n",
      "          vf_loss: 169.56521606445312\n",
      "    num_agent_steps_sampled: 239940\n",
      "    num_agent_steps_trained: 239940\n",
      "    num_steps_sampled: 239940\n",
      "    num_steps_trained: 239940\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.86428571428571\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09024261140926154\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09143233039048092\n",
      "    mean_inference_ms: 0.9974240220073257\n",
      "    mean_raw_obs_processing_ms: 0.11982129500830092\n",
      "  time_since_restore: 291.74794006347656\n",
      "  time_this_iter_s: 9.62117052078247\n",
      "  time_total_s: 291.74794006347656\n",
      "  timers:\n",
      "    learn_throughput: 1311.719\n",
      "    learn_time_ms: 6097.341\n",
      "    load_throughput: 23584113.746\n",
      "    load_time_ms: 0.339\n",
      "    sample_throughput: 828.658\n",
      "    sample_time_ms: 9651.755\n",
      "    update_time_ms: 2.636\n",
      "  timestamp: 1645201087\n",
      "  timesteps_since_restore: 239940\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 239940\n",
      "  training_iteration: 30\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:18:10 (running for 00:05:06.89)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         291.748</td><td style=\"text-align: right;\">239940</td><td style=\"text-align: right;\">     161</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">               161</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:18:15 (running for 00:05:11.95)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         291.748</td><td style=\"text-align: right;\">239940</td><td style=\"text-align: right;\">     161</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">               161</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 247938\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-18-16\n",
      "  done: false\n",
      "  episode_len_mean: 161.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 161.77\n",
      "  episode_reward_min: 86.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 1992\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.32036131620407104\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.14191965758800507\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03699013590812683\n",
      "          model: {}\n",
      "          policy_loss: 0.005330064333975315\n",
      "          total_loss: 146.8995361328125\n",
      "          vf_explained_var: 0.8179624676704407\n",
      "          vf_loss: 146.88235473632812\n",
      "    num_agent_steps_sampled: 247938\n",
      "    num_agent_steps_trained: 247938\n",
      "    num_steps_sampled: 247938\n",
      "    num_steps_trained: 247938\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.36153846153846\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09016797900393655\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09135964333371949\n",
      "    mean_inference_ms: 0.9968040659128943\n",
      "    mean_raw_obs_processing_ms: 0.11974309679946905\n",
      "  time_since_restore: 301.3713698387146\n",
      "  time_this_iter_s: 9.623429775238037\n",
      "  time_total_s: 301.3713698387146\n",
      "  timers:\n",
      "    learn_throughput: 1309.0\n",
      "    learn_time_ms: 6110.009\n",
      "    load_throughput: 23310432.487\n",
      "    load_time_ms: 0.343\n",
      "    sample_throughput: 827.88\n",
      "    sample_time_ms: 9660.823\n",
      "    update_time_ms: 2.7\n",
      "  timestamp: 1645201096\n",
      "  timesteps_since_restore: 247938\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 247938\n",
      "  training_iteration: 31\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:18:21 (running for 00:05:17.54)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         301.371</td><td style=\"text-align: right;\">247938</td><td style=\"text-align: right;\">  161.77</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            161.77</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:18:26 (running for 00:05:22.62)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         301.371</td><td style=\"text-align: right;\">247938</td><td style=\"text-align: right;\">  161.77</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            161.77</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 255936\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-18-26\n",
      "  done: false\n",
      "  episode_len_mean: 170.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 170.13\n",
      "  episode_reward_min: 107.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 2037\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.48054200410842896\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.15264147520065308\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008605041541159153\n",
      "          model: {}\n",
      "          policy_loss: 0.005270441994071007\n",
      "          total_loss: 224.1078338623047\n",
      "          vf_explained_var: 0.7148579359054565\n",
      "          vf_loss: 224.09841918945312\n",
      "    num_agent_steps_sampled: 255936\n",
      "    num_agent_steps_trained: 255936\n",
      "    num_steps_sampled: 255936\n",
      "    num_steps_trained: 255936\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.98571428571428\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09013986244351813\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09134026766424957\n",
      "    mean_inference_ms: 0.9971341756067958\n",
      "    mean_raw_obs_processing_ms: 0.11974737943910338\n",
      "  time_since_restore: 311.16689896583557\n",
      "  time_this_iter_s: 9.795529127120972\n",
      "  time_total_s: 311.16689896583557\n",
      "  timers:\n",
      "    learn_throughput: 1310.268\n",
      "    learn_time_ms: 6104.097\n",
      "    load_throughput: 23642288.669\n",
      "    load_time_ms: 0.338\n",
      "    sample_throughput: 825.997\n",
      "    sample_time_ms: 9682.842\n",
      "    update_time_ms: 2.782\n",
      "  timestamp: 1645201106\n",
      "  timesteps_since_restore: 255936\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 255936\n",
      "  training_iteration: 32\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:18:31 (running for 00:05:28.37)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         311.167</td><td style=\"text-align: right;\">255936</td><td style=\"text-align: right;\">  170.13</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 107</td><td style=\"text-align: right;\">            170.13</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 263934\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-18-36\n",
      "  done: false\n",
      "  episode_len_mean: 169.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 169.03\n",
      "  episode_reward_min: 87.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 2084\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.48054200410842896\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.1436041295528412\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0414595827460289\n",
      "          model: {}\n",
      "          policy_loss: 0.015884047374129295\n",
      "          total_loss: 228.87060546875\n",
      "          vf_explained_var: 0.7325608134269714\n",
      "          vf_loss: 228.83480834960938\n",
      "    num_agent_steps_sampled: 263934\n",
      "    num_agent_steps_trained: 263934\n",
      "    num_steps_sampled: 263934\n",
      "    num_steps_trained: 263934\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.60714285714286\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09015207368029894\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0913572981799079\n",
      "    mean_inference_ms: 0.9977045105085486\n",
      "    mean_raw_obs_processing_ms: 0.1197252488480549\n",
      "  time_since_restore: 320.9316964149475\n",
      "  time_this_iter_s: 9.764797449111938\n",
      "  time_total_s: 320.9316964149475\n",
      "  timers:\n",
      "    learn_throughput: 1308.72\n",
      "    learn_time_ms: 6111.316\n",
      "    load_throughput: 23842248.324\n",
      "    load_time_ms: 0.335\n",
      "    sample_throughput: 825.488\n",
      "    sample_time_ms: 9688.815\n",
      "    update_time_ms: 2.788\n",
      "  timestamp: 1645201116\n",
      "  timesteps_since_restore: 263934\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 263934\n",
      "  training_iteration: 33\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:18:37 (running for 00:05:34.15)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         320.932</td><td style=\"text-align: right;\">263934</td><td style=\"text-align: right;\">  169.03</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            169.03</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:18:42 (running for 00:05:39.17)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         320.932</td><td style=\"text-align: right;\">263934</td><td style=\"text-align: right;\">  169.03</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            169.03</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 271932\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-18-46\n",
      "  done: false\n",
      "  episode_len_mean: 169.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 169.3\n",
      "  episode_reward_min: 87.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 2132\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.720812976360321\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.15924397110939026\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00485978415235877\n",
      "          model: {}\n",
      "          policy_loss: -0.0006422773003578186\n",
      "          total_loss: 147.7464141845703\n",
      "          vf_explained_var: 0.806395947933197\n",
      "          vf_loss: 147.7435760498047\n",
      "    num_agent_steps_sampled: 271932\n",
      "    num_agent_steps_trained: 271932\n",
      "    num_steps_sampled: 271932\n",
      "    num_steps_trained: 271932\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.97142857142858\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09013143136445652\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0913320174673056\n",
      "    mean_inference_ms: 0.9975217406014472\n",
      "    mean_raw_obs_processing_ms: 0.11961426601593807\n",
      "  time_since_restore: 330.43427300453186\n",
      "  time_this_iter_s: 9.50257658958435\n",
      "  time_total_s: 330.43427300453186\n",
      "  timers:\n",
      "    learn_throughput: 1313.324\n",
      "    learn_time_ms: 6089.89\n",
      "    load_throughput: 23470260.542\n",
      "    load_time_ms: 0.341\n",
      "    sample_throughput: 826.004\n",
      "    sample_time_ms: 9682.762\n",
      "    update_time_ms: 2.81\n",
      "  timestamp: 1645201126\n",
      "  timesteps_since_restore: 271932\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 271932\n",
      "  training_iteration: 34\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:18:48 (running for 00:05:44.68)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         330.434</td><td style=\"text-align: right;\">271932</td><td style=\"text-align: right;\">   169.3</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">             169.3</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:18:53 (running for 00:05:49.70)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         330.434</td><td style=\"text-align: right;\">271932</td><td style=\"text-align: right;\">   169.3</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">             169.3</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 279930\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-18-55\n",
      "  done: false\n",
      "  episode_len_mean: 171.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 171.31\n",
      "  episode_reward_min: 89.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 2179\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3604064881801605\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.11531173437833786\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.09544724971055984\n",
      "          model: {}\n",
      "          policy_loss: 0.01772780530154705\n",
      "          total_loss: 194.99630737304688\n",
      "          vf_explained_var: 0.7515812516212463\n",
      "          vf_loss: 194.94418334960938\n",
      "    num_agent_steps_sampled: 279930\n",
      "    num_agent_steps_trained: 279930\n",
      "    num_steps_sampled: 279930\n",
      "    num_steps_trained: 279930\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.3\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09006388770099766\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09125916303613309\n",
      "    mean_inference_ms: 0.996803742303932\n",
      "    mean_raw_obs_processing_ms: 0.11947037557975676\n",
      "  time_since_restore: 339.88051676750183\n",
      "  time_this_iter_s: 9.44624376296997\n",
      "  time_total_s: 339.88051676750183\n",
      "  timers:\n",
      "    learn_throughput: 1317.043\n",
      "    learn_time_ms: 6072.693\n",
      "    load_throughput: 23767920.782\n",
      "    load_time_ms: 0.337\n",
      "    sample_throughput: 828.692\n",
      "    sample_time_ms: 9651.349\n",
      "    update_time_ms: 2.819\n",
      "  timestamp: 1645201135\n",
      "  timesteps_since_restore: 279930\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 279930\n",
      "  training_iteration: 35\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:18:58 (running for 00:05:55.20)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         339.881</td><td style=\"text-align: right;\">279930</td><td style=\"text-align: right;\">  171.31</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            171.31</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:19:03 (running for 00:06:00.22)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         339.881</td><td style=\"text-align: right;\">279930</td><td style=\"text-align: right;\">  171.31</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            171.31</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 287928\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-19-05\n",
      "  done: false\n",
      "  episode_len_mean: 166.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 166.91\n",
      "  episode_reward_min: 98.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 2227\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5406097173690796\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.13450466096401215\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010651600547134876\n",
      "          model: {}\n",
      "          policy_loss: 0.0016233389033004642\n",
      "          total_loss: 170.8343048095703\n",
      "          vf_explained_var: 0.7834724187850952\n",
      "          vf_loss: 170.82691955566406\n",
      "    num_agent_steps_sampled: 287928\n",
      "    num_agent_steps_trained: 287928\n",
      "    num_steps_sampled: 287928\n",
      "    num_steps_trained: 287928\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.61538461538463\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09002658228076481\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09120829187473296\n",
      "    mean_inference_ms: 0.9964250065957867\n",
      "    mean_raw_obs_processing_ms: 0.11940269186570088\n",
      "  time_since_restore: 349.60973358154297\n",
      "  time_this_iter_s: 9.729216814041138\n",
      "  time_total_s: 349.60973358154297\n",
      "  timers:\n",
      "    learn_throughput: 1313.015\n",
      "    learn_time_ms: 6091.323\n",
      "    load_throughput: 23803337.396\n",
      "    load_time_ms: 0.336\n",
      "    sample_throughput: 829.468\n",
      "    sample_time_ms: 9642.327\n",
      "    update_time_ms: 2.839\n",
      "  timestamp: 1645201145\n",
      "  timesteps_since_restore: 287928\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 287928\n",
      "  training_iteration: 36\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:19:09 (running for 00:06:05.95)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">          349.61</td><td style=\"text-align: right;\">287928</td><td style=\"text-align: right;\">  166.91</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  98</td><td style=\"text-align: right;\">            166.91</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:19:14 (running for 00:06:10.97)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">          349.61</td><td style=\"text-align: right;\">287928</td><td style=\"text-align: right;\">  166.91</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  98</td><td style=\"text-align: right;\">            166.91</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 295926\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-19-15\n",
      "  done: false\n",
      "  episode_len_mean: 159.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 159.45\n",
      "  episode_reward_min: 96.0\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 2279\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5406097173690796\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.14586390554904938\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011688628233969212\n",
      "          model: {}\n",
      "          policy_loss: 0.001218721503391862\n",
      "          total_loss: 158.58465576171875\n",
      "          vf_explained_var: 0.7931883335113525\n",
      "          vf_loss: 158.57711791992188\n",
      "    num_agent_steps_sampled: 295926\n",
      "    num_agent_steps_trained: 295926\n",
      "    num_steps_sampled: 295926\n",
      "    num_steps_trained: 295926\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.67142857142856\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09000511308145563\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09119070721002986\n",
      "    mean_inference_ms: 0.995834655828105\n",
      "    mean_raw_obs_processing_ms: 0.1193383275552676\n",
      "  time_since_restore: 359.29692244529724\n",
      "  time_this_iter_s: 9.687188863754272\n",
      "  time_total_s: 359.29692244529724\n",
      "  timers:\n",
      "    learn_throughput: 1308.224\n",
      "    learn_time_ms: 6113.634\n",
      "    load_throughput: 23509736.766\n",
      "    load_time_ms: 0.34\n",
      "    sample_throughput: 829.183\n",
      "    sample_time_ms: 9645.638\n",
      "    update_time_ms: 2.921\n",
      "  timestamp: 1645201155\n",
      "  timesteps_since_restore: 295926\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 295926\n",
      "  training_iteration: 37\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:19:20 (running for 00:06:16.68)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         359.297</td><td style=\"text-align: right;\">295926</td><td style=\"text-align: right;\">  159.45</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  96</td><td style=\"text-align: right;\">            159.45</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 303924\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-19-24\n",
      "  done: false\n",
      "  episode_len_mean: 158.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 158.53\n",
      "  episode_reward_min: 96.0\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 2329\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5406097173690796\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.11226444691419601\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.07095829397439957\n",
      "          model: {}\n",
      "          policy_loss: 0.01674896851181984\n",
      "          total_loss: 149.63623046875\n",
      "          vf_explained_var: 0.810158371925354\n",
      "          vf_loss: 149.5811309814453\n",
      "    num_agent_steps_sampled: 303924\n",
      "    num_agent_steps_trained: 303924\n",
      "    num_steps_sampled: 303924\n",
      "    num_steps_trained: 303924\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.69285714285714\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08998707884265605\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09118661458421506\n",
      "    mean_inference_ms: 0.9953639583595235\n",
      "    mean_raw_obs_processing_ms: 0.11929509249463983\n",
      "  time_since_restore: 368.96298146247864\n",
      "  time_this_iter_s: 9.666059017181396\n",
      "  time_total_s: 368.96298146247864\n",
      "  timers:\n",
      "    learn_throughput: 1311.652\n",
      "    learn_time_ms: 6097.656\n",
      "    load_throughput: 23282928.506\n",
      "    load_time_ms: 0.344\n",
      "    sample_throughput: 826.626\n",
      "    sample_time_ms: 9675.472\n",
      "    update_time_ms: 2.943\n",
      "  timestamp: 1645201164\n",
      "  timesteps_since_restore: 303924\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 303924\n",
      "  training_iteration: 38\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:19:25 (running for 00:06:22.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         368.963</td><td style=\"text-align: right;\">303924</td><td style=\"text-align: right;\">  158.53</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  96</td><td style=\"text-align: right;\">            158.53</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:19:30 (running for 00:06:27.37)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         368.963</td><td style=\"text-align: right;\">303924</td><td style=\"text-align: right;\">  158.53</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  96</td><td style=\"text-align: right;\">            158.53</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 311922\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-19-34\n",
      "  done: false\n",
      "  episode_len_mean: 167.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 167.7\n",
      "  episode_reward_min: 100.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 2374\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8109146356582642\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.15437287092208862\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03479505702853203\n",
      "          model: {}\n",
      "          policy_loss: 0.009532065130770206\n",
      "          total_loss: 219.4230194091797\n",
      "          vf_explained_var: 0.7199543118476868\n",
      "          vf_loss: 219.38528442382812\n",
      "    num_agent_steps_sampled: 311922\n",
      "    num_agent_steps_trained: 311922\n",
      "    num_steps_sampled: 311922\n",
      "    num_steps_trained: 311922\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.32857142857142\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0899847780613306\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0912095212481368\n",
      "    mean_inference_ms: 0.9954435246230804\n",
      "    mean_raw_obs_processing_ms: 0.11921332030135404\n",
      "  time_since_restore: 378.51458263397217\n",
      "  time_this_iter_s: 9.55160117149353\n",
      "  time_total_s: 378.51458263397217\n",
      "  timers:\n",
      "    learn_throughput: 1311.597\n",
      "    learn_time_ms: 6097.908\n",
      "    load_throughput: 23589088.947\n",
      "    load_time_ms: 0.339\n",
      "    sample_throughput: 827.614\n",
      "    sample_time_ms: 9663.92\n",
      "    update_time_ms: 2.974\n",
      "  timestamp: 1645201174\n",
      "  timesteps_since_restore: 311922\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 311922\n",
      "  training_iteration: 39\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:19:36 (running for 00:06:32.89)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         378.515</td><td style=\"text-align: right;\">311922</td><td style=\"text-align: right;\">   167.7</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 100</td><td style=\"text-align: right;\">             167.7</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:19:41 (running for 00:06:37.95)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         378.515</td><td style=\"text-align: right;\">311922</td><td style=\"text-align: right;\">   167.7</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 100</td><td style=\"text-align: right;\">             167.7</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 319920\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-19-43\n",
      "  done: false\n",
      "  episode_len_mean: 167.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 167.65\n",
      "  episode_reward_min: 95.0\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 2424\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163718938827515\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.13824135065078735\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017884301021695137\n",
      "          model: {}\n",
      "          policy_loss: 0.0026512728072702885\n",
      "          total_loss: 157.70510864257812\n",
      "          vf_explained_var: 0.7581000328063965\n",
      "          vf_loss: 157.68069458007812\n",
      "    num_agent_steps_sampled: 319920\n",
      "    num_agent_steps_trained: 319920\n",
      "    num_steps_sampled: 319920\n",
      "    num_steps_trained: 319920\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.22142857142858\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08995901713251707\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09116702984307153\n",
      "    mean_inference_ms: 0.9951028352536233\n",
      "    mean_raw_obs_processing_ms: 0.11912485204824297\n",
      "  time_since_restore: 388.1038031578064\n",
      "  time_this_iter_s: 9.589220523834229\n",
      "  time_total_s: 388.1038031578064\n",
      "  timers:\n",
      "    learn_throughput: 1312.804\n",
      "    learn_time_ms: 6092.302\n",
      "    load_throughput: 24329883.516\n",
      "    load_time_ms: 0.329\n",
      "    sample_throughput: 827.314\n",
      "    sample_time_ms: 9667.431\n",
      "    update_time_ms: 2.941\n",
      "  timestamp: 1645201183\n",
      "  timesteps_since_restore: 319920\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 319920\n",
      "  training_iteration: 40\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:19:46 (running for 00:06:43.51)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         388.104</td><td style=\"text-align: right;\">319920</td><td style=\"text-align: right;\">  167.65</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  95</td><td style=\"text-align: right;\">            167.65</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:19:52 (running for 00:06:48.58)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         388.104</td><td style=\"text-align: right;\">319920</td><td style=\"text-align: right;\">  167.65</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  95</td><td style=\"text-align: right;\">            167.65</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 327918\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-19-53\n",
      "  done: false\n",
      "  episode_len_mean: 164.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 164.68\n",
      "  episode_reward_min: 95.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 2470\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163718938827515\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.15788410604000092\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008086251094937325\n",
      "          model: {}\n",
      "          policy_loss: 0.007653933018445969\n",
      "          total_loss: 202.3778533935547\n",
      "          vf_explained_var: 0.7000349164009094\n",
      "          vf_loss: 202.3603515625\n",
      "    num_agent_steps_sampled: 327918\n",
      "    num_agent_steps_trained: 327918\n",
      "    num_steps_sampled: 327918\n",
      "    num_steps_trained: 327918\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.62142857142858\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08994692919292475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09113398455117885\n",
      "    mean_inference_ms: 0.99500807016466\n",
      "    mean_raw_obs_processing_ms: 0.11909397185522831\n",
      "  time_since_restore: 397.9139335155487\n",
      "  time_this_iter_s: 9.81013035774231\n",
      "  time_total_s: 397.9139335155487\n",
      "  timers:\n",
      "    learn_throughput: 1310.372\n",
      "    learn_time_ms: 6103.609\n",
      "    load_throughput: 24657143.25\n",
      "    load_time_ms: 0.324\n",
      "    sample_throughput: 827.174\n",
      "    sample_time_ms: 9669.067\n",
      "    update_time_ms: 2.913\n",
      "  timestamp: 1645201193\n",
      "  timesteps_since_restore: 327918\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 327918\n",
      "  training_iteration: 41\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:19:57 (running for 00:06:54.35)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         397.914</td><td style=\"text-align: right;\">327918</td><td style=\"text-align: right;\">  164.68</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  95</td><td style=\"text-align: right;\">            164.68</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:20:02 (running for 00:06:59.40)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         397.914</td><td style=\"text-align: right;\">327918</td><td style=\"text-align: right;\">  164.68</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  95</td><td style=\"text-align: right;\">            164.68</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 335916\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-20-03\n",
      "  done: false\n",
      "  episode_len_mean: 166.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 166.76\n",
      "  episode_reward_min: 86.0\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 2520\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163718938827515\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.13372057676315308\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013376995921134949\n",
      "          model: {}\n",
      "          policy_loss: 0.0035725405905395746\n",
      "          total_loss: 162.95729064941406\n",
      "          vf_explained_var: 0.7600688338279724\n",
      "          vf_loss: 162.9374542236328\n",
      "    num_agent_steps_sampled: 335916\n",
      "    num_agent_steps_trained: 335916\n",
      "    num_steps_sampled: 335916\n",
      "    num_steps_trained: 335916\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.8\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08994616387805955\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09112826578852808\n",
      "    mean_inference_ms: 0.9950787572979617\n",
      "    mean_raw_obs_processing_ms: 0.11908821305552113\n",
      "  time_since_restore: 407.70901465415955\n",
      "  time_this_iter_s: 9.79508113861084\n",
      "  time_total_s: 407.70901465415955\n",
      "  timers:\n",
      "    learn_throughput: 1309.469\n",
      "    learn_time_ms: 6107.819\n",
      "    load_throughput: 24664394.818\n",
      "    load_time_ms: 0.324\n",
      "    sample_throughput: 826.583\n",
      "    sample_time_ms: 9675.981\n",
      "    update_time_ms: 2.811\n",
      "  timestamp: 1645201203\n",
      "  timesteps_since_restore: 335916\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 335916\n",
      "  training_iteration: 42\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:20:08 (running for 00:07:05.17)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         407.709</td><td style=\"text-align: right;\">335916</td><td style=\"text-align: right;\">  166.76</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            166.76</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 343914\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-20-13\n",
      "  done: false\n",
      "  episode_len_mean: 165.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 165.34\n",
      "  episode_reward_min: 86.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 2567\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163718938827515\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.17361395061016083\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007341816555708647\n",
      "          model: {}\n",
      "          policy_loss: -0.0002927586028818041\n",
      "          total_loss: 193.49359130859375\n",
      "          vf_explained_var: 0.7451034188270569\n",
      "          vf_loss: 193.48497009277344\n",
      "    num_agent_steps_sampled: 343914\n",
      "    num_agent_steps_trained: 343914\n",
      "    num_steps_sampled: 343914\n",
      "    num_steps_trained: 343914\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.57857142857144\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08996450253245775\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09115195097585596\n",
      "    mean_inference_ms: 0.9950543777094869\n",
      "    mean_raw_obs_processing_ms: 0.119066768562628\n",
      "  time_since_restore: 417.4967432022095\n",
      "  time_this_iter_s: 9.787728548049927\n",
      "  time_total_s: 417.4967432022095\n",
      "  timers:\n",
      "    learn_throughput: 1307.851\n",
      "    learn_time_ms: 6115.377\n",
      "    load_throughput: 24175586.186\n",
      "    load_time_ms: 0.331\n",
      "    sample_throughput: 826.689\n",
      "    sample_time_ms: 9674.744\n",
      "    update_time_ms: 2.86\n",
      "  timestamp: 1645201213\n",
      "  timesteps_since_restore: 343914\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 343914\n",
      "  training_iteration: 43\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:20:14 (running for 00:07:10.98)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         417.497</td><td style=\"text-align: right;\">343914</td><td style=\"text-align: right;\">  165.34</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            165.34</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:20:19 (running for 00:07:16.00)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         417.497</td><td style=\"text-align: right;\">343914</td><td style=\"text-align: right;\">  165.34</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            165.34</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 351912\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-20-23\n",
      "  done: false\n",
      "  episode_len_mean: 166.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 166.75\n",
      "  episode_reward_min: 81.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 2615\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163718938827515\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.14918580651283264\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0051583475433290005\n",
      "          model: {}\n",
      "          policy_loss: 0.004171659704297781\n",
      "          total_loss: 132.55307006835938\n",
      "          vf_explained_var: 0.8243038654327393\n",
      "          vf_loss: 132.54261779785156\n",
      "    num_agent_steps_sampled: 351912\n",
      "    num_agent_steps_trained: 351912\n",
      "    num_steps_sampled: 351912\n",
      "    num_steps_trained: 351912\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.7923076923077\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09001987719333279\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09123262878407377\n",
      "    mean_inference_ms: 0.9960399512007859\n",
      "    mean_raw_obs_processing_ms: 0.11913811827703544\n",
      "  time_since_restore: 427.238760471344\n",
      "  time_this_iter_s: 9.742017269134521\n",
      "  time_total_s: 427.238760471344\n",
      "  timers:\n",
      "    learn_throughput: 1307.498\n",
      "    learn_time_ms: 6117.029\n",
      "    load_throughput: 24906112.846\n",
      "    load_time_ms: 0.321\n",
      "    sample_throughput: 824.1\n",
      "    sample_time_ms: 9705.131\n",
      "    update_time_ms: 2.849\n",
      "  timestamp: 1645201223\n",
      "  timesteps_since_restore: 351912\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 351912\n",
      "  training_iteration: 44\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:20:25 (running for 00:07:21.75)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         427.239</td><td style=\"text-align: right;\">351912</td><td style=\"text-align: right;\">  166.75</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  81</td><td style=\"text-align: right;\">            166.75</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:20:30 (running for 00:07:26.77)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         427.239</td><td style=\"text-align: right;\">351912</td><td style=\"text-align: right;\">  166.75</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  81</td><td style=\"text-align: right;\">            166.75</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 359910\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-20-33\n",
      "  done: false\n",
      "  episode_len_mean: 163.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 163.72\n",
      "  episode_reward_min: 81.0\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 2665\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163718938827515\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.1487347036600113\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008665917441248894\n",
      "          model: {}\n",
      "          policy_loss: 0.007335761096328497\n",
      "          total_loss: 219.7231903076172\n",
      "          vf_explained_var: 0.6720133423805237\n",
      "          vf_loss: 219.70530700683594\n",
      "    num_agent_steps_sampled: 359910\n",
      "    num_agent_steps_trained: 359910\n",
      "    num_steps_sampled: 359910\n",
      "    num_steps_trained: 359910\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.44000000000001\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09007871173267298\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09128642824078753\n",
      "    mean_inference_ms: 0.9965006951117746\n",
      "    mean_raw_obs_processing_ms: 0.1191988717404406\n",
      "  time_since_restore: 437.0723626613617\n",
      "  time_this_iter_s: 9.8336021900177\n",
      "  time_total_s: 437.0723626613617\n",
      "  timers:\n",
      "    learn_throughput: 1302.783\n",
      "    learn_time_ms: 6139.163\n",
      "    load_throughput: 24347542.018\n",
      "    load_time_ms: 0.328\n",
      "    sample_throughput: 822.554\n",
      "    sample_time_ms: 9723.379\n",
      "    update_time_ms: 2.869\n",
      "  timestamp: 1645201233\n",
      "  timesteps_since_restore: 359910\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 359910\n",
      "  training_iteration: 45\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:20:36 (running for 00:07:32.66)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         437.072</td><td style=\"text-align: right;\">359910</td><td style=\"text-align: right;\">  163.72</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  81</td><td style=\"text-align: right;\">            163.72</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:20:41 (running for 00:07:37.68)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         437.072</td><td style=\"text-align: right;\">359910</td><td style=\"text-align: right;\">  163.72</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  81</td><td style=\"text-align: right;\">            163.72</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 367908\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-20-42\n",
      "  done: false\n",
      "  episode_len_mean: 164.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 164.71\n",
      "  episode_reward_min: 35.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 2713\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163718938827515\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.08907436579465866\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.10774877667427063\n",
      "          model: {}\n",
      "          policy_loss: 0.01622171327471733\n",
      "          total_loss: 210.79824829101562\n",
      "          vf_explained_var: 0.7104708552360535\n",
      "          vf_loss: 210.65097045898438\n",
      "    num_agent_steps_sampled: 367908\n",
      "    num_agent_steps_trained: 367908\n",
      "    num_steps_sampled: 367908\n",
      "    num_steps_trained: 367908\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.11538461538461\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09011807345432324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09131237232916685\n",
      "    mean_inference_ms: 0.9971169607981766\n",
      "    mean_raw_obs_processing_ms: 0.11927499133316762\n",
      "  time_since_restore: 446.8376853466034\n",
      "  time_this_iter_s: 9.7653226852417\n",
      "  time_total_s: 446.8376853466034\n",
      "  timers:\n",
      "    learn_throughput: 1303.106\n",
      "    learn_time_ms: 6137.644\n",
      "    load_throughput: 24872872.686\n",
      "    load_time_ms: 0.322\n",
      "    sample_throughput: 820.271\n",
      "    sample_time_ms: 9750.437\n",
      "    update_time_ms: 2.927\n",
      "  timestamp: 1645201242\n",
      "  timesteps_since_restore: 367908\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 367908\n",
      "  training_iteration: 46\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:20:46 (running for 00:07:43.44)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         446.838</td><td style=\"text-align: right;\">367908</td><td style=\"text-align: right;\">  164.71</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  35</td><td style=\"text-align: right;\">            164.71</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:20:51 (running for 00:07:48.46)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         446.838</td><td style=\"text-align: right;\">367908</td><td style=\"text-align: right;\">  164.71</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  35</td><td style=\"text-align: right;\">            164.71</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 375906\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-20-52\n",
      "  done: false\n",
      "  episode_len_mean: 167.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 167.4\n",
      "  episode_reward_min: 35.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 2761\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.824557900428772\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.059612758457660675\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.033711422234773636\n",
      "          model: {}\n",
      "          policy_loss: 0.008847398683428764\n",
      "          total_loss: 123.73078155517578\n",
      "          vf_explained_var: 0.8098240494728088\n",
      "          vf_loss: 123.6604232788086\n",
      "    num_agent_steps_sampled: 375906\n",
      "    num_agent_steps_trained: 375906\n",
      "    num_steps_sampled: 375906\n",
      "    num_steps_trained: 375906\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.2357142857143\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09011183935100457\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09130514591116523\n",
      "    mean_inference_ms: 0.9972969621608513\n",
      "    mean_raw_obs_processing_ms: 0.11930583198386073\n",
      "  time_since_restore: 456.34651041030884\n",
      "  time_this_iter_s: 9.508825063705444\n",
      "  time_total_s: 456.34651041030884\n",
      "  timers:\n",
      "    learn_throughput: 1307.023\n",
      "    learn_time_ms: 6119.248\n",
      "    load_throughput: 24874717.034\n",
      "    load_time_ms: 0.322\n",
      "    sample_throughput: 820.335\n",
      "    sample_time_ms: 9749.676\n",
      "    update_time_ms: 2.922\n",
      "  timestamp: 1645201252\n",
      "  timesteps_since_restore: 375906\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 375906\n",
      "  training_iteration: 47\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:20:57 (running for 00:07:54.02)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         456.347</td><td style=\"text-align: right;\">375906</td><td style=\"text-align: right;\">   167.4</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  35</td><td style=\"text-align: right;\">             167.4</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 383904\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-21-02\n",
      "  done: false\n",
      "  episode_len_mean: 166.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 166.37\n",
      "  episode_reward_min: 97.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 2808\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.7368369102478027\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.06708469986915588\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019707277417182922\n",
      "          model: {}\n",
      "          policy_loss: 0.007900294847786427\n",
      "          total_loss: 231.5553436279297\n",
      "          vf_explained_var: 0.6910389065742493\n",
      "          vf_loss: 231.49351501464844\n",
      "    num_agent_steps_sampled: 383904\n",
      "    num_agent_steps_trained: 383904\n",
      "    num_steps_sampled: 383904\n",
      "    num_steps_trained: 383904\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.67857142857142\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09010933850632337\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09131361698060539\n",
      "    mean_inference_ms: 0.9969378859960146\n",
      "    mean_raw_obs_processing_ms: 0.11920253817183157\n",
      "  time_since_restore: 466.0419542789459\n",
      "  time_this_iter_s: 9.695443868637085\n",
      "  time_total_s: 466.0419542789459\n",
      "  timers:\n",
      "    learn_throughput: 1306.185\n",
      "    learn_time_ms: 6123.177\n",
      "    load_throughput: 25277705.819\n",
      "    load_time_ms: 0.316\n",
      "    sample_throughput: 821.945\n",
      "    sample_time_ms: 9730.573\n",
      "    update_time_ms: 2.966\n",
      "  timestamp: 1645201262\n",
      "  timesteps_since_restore: 383904\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 383904\n",
      "  training_iteration: 48\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:21:03 (running for 00:07:59.65)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         466.042</td><td style=\"text-align: right;\">383904</td><td style=\"text-align: right;\">  166.37</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            166.37</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:21:08 (running for 00:08:04.72)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         466.042</td><td style=\"text-align: right;\">383904</td><td style=\"text-align: right;\">  166.37</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            166.37</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 391902\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-21-11\n",
      "  done: false\n",
      "  episode_len_mean: 166.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 166.28\n",
      "  episode_reward_min: 101.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 2857\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.7368369102478027\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.08315809816122055\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04207519069314003\n",
      "          model: {}\n",
      "          policy_loss: 0.009804085828363895\n",
      "          total_loss: 169.92396545410156\n",
      "          vf_explained_var: 0.7569190859794617\n",
      "          vf_loss: 169.79901123046875\n",
      "    num_agent_steps_sampled: 391902\n",
      "    num_agent_steps_trained: 391902\n",
      "    num_steps_sampled: 391902\n",
      "    num_steps_trained: 391902\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.85\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09013135335540082\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09134632280777645\n",
      "    mean_inference_ms: 0.9970271589031547\n",
      "    mean_raw_obs_processing_ms: 0.11914501168784807\n",
      "  time_since_restore: 475.6946611404419\n",
      "  time_this_iter_s: 9.652706861495972\n",
      "  time_total_s: 475.6946611404419\n",
      "  timers:\n",
      "    learn_throughput: 1305.993\n",
      "    learn_time_ms: 6124.074\n",
      "    load_throughput: 24711634.175\n",
      "    load_time_ms: 0.324\n",
      "    sample_throughput: 820.845\n",
      "    sample_time_ms: 9743.614\n",
      "    update_time_ms: 2.933\n",
      "  timestamp: 1645201271\n",
      "  timesteps_since_restore: 391902\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 391902\n",
      "  training_iteration: 49\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:21:13 (running for 00:08:10.33)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         475.695</td><td style=\"text-align: right;\">391902</td><td style=\"text-align: right;\">  166.28</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 101</td><td style=\"text-align: right;\">            166.28</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:21:18 (running for 00:08:15.39)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         475.695</td><td style=\"text-align: right;\">391902</td><td style=\"text-align: right;\">  166.28</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 101</td><td style=\"text-align: right;\">            166.28</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 399900\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-21-21\n",
      "  done: false\n",
      "  episode_len_mean: 168.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 168.0\n",
      "  episode_reward_min: 101.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 2904\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.105255126953125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.13149717450141907\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03970426693558693\n",
      "          model: {}\n",
      "          policy_loss: 0.012997059151530266\n",
      "          total_loss: 177.91693115234375\n",
      "          vf_explained_var: 0.7500792741775513\n",
      "          vf_loss: 177.740966796875\n",
      "    num_agent_steps_sampled: 399900\n",
      "    num_agent_steps_trained: 399900\n",
      "    num_steps_sampled: 399900\n",
      "    num_steps_trained: 399900\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.79230769230767\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09010836561008989\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0912997216444954\n",
      "    mean_inference_ms: 0.9971887238347668\n",
      "    mean_raw_obs_processing_ms: 0.11920094992796047\n",
      "  time_since_restore: 485.2819526195526\n",
      "  time_this_iter_s: 9.587291479110718\n",
      "  time_total_s: 485.2819526195526\n",
      "  timers:\n",
      "    learn_throughput: 1304.629\n",
      "    learn_time_ms: 6130.476\n",
      "    load_throughput: 24764538.16\n",
      "    load_time_ms: 0.323\n",
      "    sample_throughput: 821.359\n",
      "    sample_time_ms: 9737.521\n",
      "    update_time_ms: 2.95\n",
      "  timestamp: 1645201281\n",
      "  timesteps_since_restore: 399900\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 399900\n",
      "  training_iteration: 50\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:21:24 (running for 00:08:20.95)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         485.282</td><td style=\"text-align: right;\">399900</td><td style=\"text-align: right;\">     168</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 101</td><td style=\"text-align: right;\">               168</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:21:29 (running for 00:08:26.02)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         485.282</td><td style=\"text-align: right;\">399900</td><td style=\"text-align: right;\">     168</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 101</td><td style=\"text-align: right;\">               168</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 407898\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-21-30\n",
      "  done: false\n",
      "  episode_len_mean: 176.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 176.33\n",
      "  episode_reward_min: 103.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 2948\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 6.1578826904296875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.1290682703256607\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.05857124924659729\n",
      "          model: {}\n",
      "          policy_loss: 0.01868523471057415\n",
      "          total_loss: 224.25137329101562\n",
      "          vf_explained_var: 0.7505896687507629\n",
      "          vf_loss: 223.87200927734375\n",
      "    num_agent_steps_sampled: 407898\n",
      "    num_agent_steps_trained: 407898\n",
      "    num_steps_sampled: 407898\n",
      "    num_steps_trained: 407898\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.22857142857144\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09008673770993575\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09126294492447298\n",
      "    mean_inference_ms: 0.997428500214945\n",
      "    mean_raw_obs_processing_ms: 0.11923943340698002\n",
      "  time_since_restore: 494.8649275302887\n",
      "  time_this_iter_s: 9.582974910736084\n",
      "  time_total_s: 494.8649275302887\n",
      "  timers:\n",
      "    learn_throughput: 1308.716\n",
      "    learn_time_ms: 6111.334\n",
      "    load_throughput: 24425544.919\n",
      "    load_time_ms: 0.327\n",
      "    sample_throughput: 821.104\n",
      "    sample_time_ms: 9740.54\n",
      "    update_time_ms: 2.917\n",
      "  timestamp: 1645201290\n",
      "  timesteps_since_restore: 407898\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 407898\n",
      "  training_iteration: 51\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:21:35 (running for 00:08:31.56)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         494.865</td><td style=\"text-align: right;\">407898</td><td style=\"text-align: right;\">  176.33</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 103</td><td style=\"text-align: right;\">            176.33</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:21:40 (running for 00:08:36.61)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         494.865</td><td style=\"text-align: right;\">407898</td><td style=\"text-align: right;\">  176.33</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 103</td><td style=\"text-align: right;\">            176.33</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 415896\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-21-40\n",
      "  done: false\n",
      "  episode_len_mean: 180.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 180.34\n",
      "  episode_reward_min: 104.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 2992\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 9.236824035644531\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.10130976140499115\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0556359738111496\n",
      "          model: {}\n",
      "          policy_loss: 0.025534752756357193\n",
      "          total_loss: 200.3425750732422\n",
      "          vf_explained_var: 0.7423725724220276\n",
      "          vf_loss: 199.80316162109375\n",
      "    num_agent_steps_sampled: 415896\n",
      "    num_agent_steps_trained: 415896\n",
      "    num_steps_sampled: 415896\n",
      "    num_steps_trained: 415896\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.44285714285715\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09006685763816492\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09123237602003087\n",
      "    mean_inference_ms: 0.9973990079488693\n",
      "    mean_raw_obs_processing_ms: 0.11922786193505877\n",
      "  time_since_restore: 504.4572184085846\n",
      "  time_this_iter_s: 9.592290878295898\n",
      "  time_total_s: 504.4572184085846\n",
      "  timers:\n",
      "    learn_throughput: 1311.488\n",
      "    learn_time_ms: 6098.416\n",
      "    load_throughput: 24470087.82\n",
      "    load_time_ms: 0.327\n",
      "    sample_throughput: 823.355\n",
      "    sample_time_ms: 9713.919\n",
      "    update_time_ms: 2.919\n",
      "  timestamp: 1645201300\n",
      "  timesteps_since_restore: 415896\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 415896\n",
      "  training_iteration: 52\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:21:45 (running for 00:08:42.18)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         504.457</td><td style=\"text-align: right;\">415896</td><td style=\"text-align: right;\">  180.34</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 104</td><td style=\"text-align: right;\">            180.34</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:21:50 (running for 00:08:47.24)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         504.457</td><td style=\"text-align: right;\">415896</td><td style=\"text-align: right;\">  180.34</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 104</td><td style=\"text-align: right;\">            180.34</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 423894\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-21-50\n",
      "  done: false\n",
      "  episode_len_mean: 175.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.88\n",
      "  episode_reward_min: 103.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 3039\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 13.855236053466797\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.0665767639875412\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021180929616093636\n",
      "          model: {}\n",
      "          policy_loss: -0.008550412021577358\n",
      "          total_loss: 223.6392822265625\n",
      "          vf_explained_var: 0.6716112494468689\n",
      "          vf_loss: 223.35435485839844\n",
      "    num_agent_steps_sampled: 423894\n",
      "    num_agent_steps_trained: 423894\n",
      "    num_steps_sampled: 423894\n",
      "    num_steps_trained: 423894\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.79285714285714\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09007739539329761\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09124111070318414\n",
      "    mean_inference_ms: 0.9971688017716906\n",
      "    mean_raw_obs_processing_ms: 0.1192101278609018\n",
      "  time_since_restore: 514.5877051353455\n",
      "  time_this_iter_s: 10.130486726760864\n",
      "  time_total_s: 514.5877051353455\n",
      "  timers:\n",
      "    learn_throughput: 1306.228\n",
      "    learn_time_ms: 6122.974\n",
      "    load_throughput: 24450468.945\n",
      "    load_time_ms: 0.327\n",
      "    sample_throughput: 823.624\n",
      "    sample_time_ms: 9710.742\n",
      "    update_time_ms: 2.908\n",
      "  timestamp: 1645201310\n",
      "  timesteps_since_restore: 423894\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 423894\n",
      "  training_iteration: 53\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:21:55 (running for 00:08:52.34)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         514.588</td><td style=\"text-align: right;\">423894</td><td style=\"text-align: right;\">  175.88</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 103</td><td style=\"text-align: right;\">            175.88</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 431892\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-22-00\n",
      "  done: false\n",
      "  episode_len_mean: 171.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 171.62\n",
      "  episode_reward_min: 99.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 3085\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 20.782854080200195\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.06797761470079422\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03218122944235802\n",
      "          model: {}\n",
      "          policy_loss: 0.014422597363591194\n",
      "          total_loss: 220.71868896484375\n",
      "          vf_explained_var: 0.7061865925788879\n",
      "          vf_loss: 220.0354461669922\n",
      "    num_agent_steps_sampled: 431892\n",
      "    num_agent_steps_trained: 431892\n",
      "    num_steps_sampled: 431892\n",
      "    num_steps_trained: 431892\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.29333333333334\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09012478062882988\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09129857692703769\n",
      "    mean_inference_ms: 0.9971659769424075\n",
      "    mean_raw_obs_processing_ms: 0.11918394968982868\n",
      "  time_since_restore: 524.5162787437439\n",
      "  time_this_iter_s: 9.928573608398438\n",
      "  time_total_s: 524.5162787437439\n",
      "  timers:\n",
      "    learn_throughput: 1300.828\n",
      "    learn_time_ms: 6148.391\n",
      "    load_throughput: 24227967.205\n",
      "    load_time_ms: 0.33\n",
      "    sample_throughput: 822.14\n",
      "    sample_time_ms: 9728.271\n",
      "    update_time_ms: 2.854\n",
      "  timestamp: 1645201320\n",
      "  timesteps_since_restore: 431892\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 431892\n",
      "  training_iteration: 54\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:22:01 (running for 00:08:58.28)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         524.516</td><td style=\"text-align: right;\">431892</td><td style=\"text-align: right;\">  171.62</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            171.62</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:22:06 (running for 00:09:03.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         524.516</td><td style=\"text-align: right;\">431892</td><td style=\"text-align: right;\">  171.62</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            171.62</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 439890\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-22-10\n",
      "  done: false\n",
      "  episode_len_mean: 172.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 172.59\n",
      "  episode_reward_min: 99.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 3132\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 31.17428207397461\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.06318257749080658\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02002718858420849\n",
      "          model: {}\n",
      "          policy_loss: 0.009286674670875072\n",
      "          total_loss: 224.47573852539062\n",
      "          vf_explained_var: 0.6881179213523865\n",
      "          vf_loss: 223.8421173095703\n",
      "    num_agent_steps_sampled: 439890\n",
      "    num_agent_steps_trained: 439890\n",
      "    num_steps_sampled: 439890\n",
      "    num_steps_trained: 439890\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.75714285714285\n",
      "    ram_util_percent: 17.80714285714286\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09017686353814489\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09135115203393691\n",
      "    mean_inference_ms: 0.9978301036676342\n",
      "    mean_raw_obs_processing_ms: 0.11925326973518605\n",
      "  time_since_restore: 534.2663633823395\n",
      "  time_this_iter_s: 9.750084638595581\n",
      "  time_total_s: 534.2663633823395\n",
      "  timers:\n",
      "    learn_throughput: 1303.975\n",
      "    learn_time_ms: 6133.552\n",
      "    load_throughput: 24874717.034\n",
      "    load_time_ms: 0.322\n",
      "    sample_throughput: 819.481\n",
      "    sample_time_ms: 9759.838\n",
      "    update_time_ms: 2.88\n",
      "  timestamp: 1645201330\n",
      "  timesteps_since_restore: 439890\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 439890\n",
      "  training_iteration: 55\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:22:12 (running for 00:09:09.06)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         534.266</td><td style=\"text-align: right;\">439890</td><td style=\"text-align: right;\">  172.59</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            172.59</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:22:17 (running for 00:09:14.08)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         534.266</td><td style=\"text-align: right;\">439890</td><td style=\"text-align: right;\">  172.59</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            172.59</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 447888\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-22-20\n",
      "  done: false\n",
      "  episode_len_mean: 171.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 171.76\n",
      "  episode_reward_min: 101.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 3179\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 46.76142120361328\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.04889371991157532\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021515261381864548\n",
      "          model: {}\n",
      "          policy_loss: 0.008056008256971836\n",
      "          total_loss: 210.4112548828125\n",
      "          vf_explained_var: 0.7377381920814514\n",
      "          vf_loss: 209.39710998535156\n",
      "    num_agent_steps_sampled: 447888\n",
      "    num_agent_steps_trained: 447888\n",
      "    num_steps_sampled: 447888\n",
      "    num_steps_trained: 447888\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.00769230769232\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09018809252872045\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09136177481808723\n",
      "    mean_inference_ms: 0.9983369792183214\n",
      "    mean_raw_obs_processing_ms: 0.11931296717069553\n",
      "  time_since_restore: 543.8268458843231\n",
      "  time_this_iter_s: 9.560482501983643\n",
      "  time_total_s: 543.8268458843231\n",
      "  timers:\n",
      "    learn_throughput: 1304.698\n",
      "    learn_time_ms: 6130.155\n",
      "    load_throughput: 24847080.507\n",
      "    load_time_ms: 0.322\n",
      "    sample_throughput: 822.16\n",
      "    sample_time_ms: 9728.028\n",
      "    update_time_ms: 2.875\n",
      "  timestamp: 1645201340\n",
      "  timesteps_since_restore: 447888\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 447888\n",
      "  training_iteration: 56\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:22:23 (running for 00:09:19.64)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         543.827</td><td style=\"text-align: right;\">447888</td><td style=\"text-align: right;\">  171.76</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 101</td><td style=\"text-align: right;\">            171.76</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:22:28 (running for 00:09:24.66)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         543.827</td><td style=\"text-align: right;\">447888</td><td style=\"text-align: right;\">  171.76</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 101</td><td style=\"text-align: right;\">            171.76</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 455886\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-22-29\n",
      "  done: false\n",
      "  episode_len_mean: 166.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 166.64\n",
      "  episode_reward_min: 101.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 3226\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 70.14213562011719\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.04425426945090294\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03444501385092735\n",
      "          model: {}\n",
      "          policy_loss: 0.010467512533068657\n",
      "          total_loss: 168.5272216796875\n",
      "          vf_explained_var: 0.796676754951477\n",
      "          vf_loss: 166.1007080078125\n",
      "    num_agent_steps_sampled: 455886\n",
      "    num_agent_steps_trained: 455886\n",
      "    num_steps_sampled: 455886\n",
      "    num_steps_trained: 455886\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.52142857142859\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09017738935461087\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09135125528857153\n",
      "    mean_inference_ms: 0.9978918854078573\n",
      "    mean_raw_obs_processing_ms: 0.11923691027582127\n",
      "  time_since_restore: 553.4561111927032\n",
      "  time_this_iter_s: 9.629265308380127\n",
      "  time_total_s: 553.4561111927032\n",
      "  timers:\n",
      "    learn_throughput: 1302.608\n",
      "    learn_time_ms: 6139.988\n",
      "    load_throughput: 25306309.137\n",
      "    load_time_ms: 0.316\n",
      "    sample_throughput: 822.252\n",
      "    sample_time_ms: 9726.949\n",
      "    update_time_ms: 2.795\n",
      "  timestamp: 1645201349\n",
      "  timesteps_since_restore: 455886\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 455886\n",
      "  training_iteration: 57\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:22:33 (running for 00:09:30.34)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         553.456</td><td style=\"text-align: right;\">455886</td><td style=\"text-align: right;\">  166.64</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 101</td><td style=\"text-align: right;\">            166.64</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:22:38 (running for 00:09:35.36)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         553.456</td><td style=\"text-align: right;\">455886</td><td style=\"text-align: right;\">  166.64</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 101</td><td style=\"text-align: right;\">            166.64</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 463884\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-22-39\n",
      "  done: false\n",
      "  episode_len_mean: 169.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 169.9\n",
      "  episode_reward_min: 105.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 3271\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 105.21320343017578\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.042654771357774734\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025131607428193092\n",
      "          model: {}\n",
      "          policy_loss: 0.012841414660215378\n",
      "          total_loss: 258.32830810546875\n",
      "          vf_explained_var: 0.6625987887382507\n",
      "          vf_loss: 255.6712646484375\n",
      "    num_agent_steps_sampled: 463884\n",
      "    num_agent_steps_trained: 463884\n",
      "    num_steps_sampled: 463884\n",
      "    num_steps_trained: 463884\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.80714285714285\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09019234011748478\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09136254192433946\n",
      "    mean_inference_ms: 0.9981255293771647\n",
      "    mean_raw_obs_processing_ms: 0.11922965995750871\n",
      "  time_since_restore: 563.45334815979\n",
      "  time_this_iter_s: 9.997236967086792\n",
      "  time_total_s: 563.45334815979\n",
      "  timers:\n",
      "    learn_throughput: 1296.722\n",
      "    learn_time_ms: 6167.859\n",
      "    load_throughput: 24677095.33\n",
      "    load_time_ms: 0.324\n",
      "    sample_throughput: 821.261\n",
      "    sample_time_ms: 9738.677\n",
      "    update_time_ms: 2.805\n",
      "  timestamp: 1645201359\n",
      "  timesteps_since_restore: 463884\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 463884\n",
      "  training_iteration: 58\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:22:43 (running for 00:09:40.37)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         563.453</td><td style=\"text-align: right;\">463884</td><td style=\"text-align: right;\">   169.9</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 105</td><td style=\"text-align: right;\">             169.9</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:22:48 (running for 00:09:45.39)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         563.453</td><td style=\"text-align: right;\">463884</td><td style=\"text-align: right;\">   169.9</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 105</td><td style=\"text-align: right;\">             169.9</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 471882\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-22-49\n",
      "  done: false\n",
      "  episode_len_mean: 178.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 178.44\n",
      "  episode_reward_min: 105.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 3316\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 157.81980895996094\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.0539686493575573\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025772344321012497\n",
      "          model: {}\n",
      "          policy_loss: 0.01000082679092884\n",
      "          total_loss: 224.36322021484375\n",
      "          vf_explained_var: 0.7157287001609802\n",
      "          vf_loss: 220.2858123779297\n",
      "    num_agent_steps_sampled: 471882\n",
      "    num_agent_steps_trained: 471882\n",
      "    num_steps_sampled: 471882\n",
      "    num_steps_trained: 471882\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.20714285714284\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09020998103281226\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09137852047617095\n",
      "    mean_inference_ms: 0.9986656662156423\n",
      "    mean_raw_obs_processing_ms: 0.11927933295489947\n",
      "  time_since_restore: 573.2777442932129\n",
      "  time_this_iter_s: 9.824396133422852\n",
      "  time_total_s: 573.2777442932129\n",
      "  timers:\n",
      "    learn_throughput: 1291.503\n",
      "    learn_time_ms: 6192.783\n",
      "    load_throughput: 25015692.313\n",
      "    load_time_ms: 0.32\n",
      "    sample_throughput: 819.583\n",
      "    sample_time_ms: 9758.62\n",
      "    update_time_ms: 2.882\n",
      "  timestamp: 1645201369\n",
      "  timesteps_since_restore: 471882\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 471882\n",
      "  training_iteration: 59\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:22:54 (running for 00:09:51.24)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         573.278</td><td style=\"text-align: right;\">471882</td><td style=\"text-align: right;\">  178.44</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 105</td><td style=\"text-align: right;\">            178.44</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 479880\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-22-59\n",
      "  done: false\n",
      "  episode_len_mean: 173.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 173.19\n",
      "  episode_reward_min: 99.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 3364\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 236.72970581054688\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.05242650955915451\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04405077546834946\n",
      "          model: {}\n",
      "          policy_loss: 0.011281711980700493\n",
      "          total_loss: 251.88864135742188\n",
      "          vf_explained_var: 0.7112007141113281\n",
      "          vf_loss: 241.44923400878906\n",
      "    num_agent_steps_sampled: 479880\n",
      "    num_agent_steps_trained: 479880\n",
      "    num_steps_sampled: 479880\n",
      "    num_steps_trained: 479880\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.54\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09024793007892745\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09143920649976653\n",
      "    mean_inference_ms: 0.9984668247902481\n",
      "    mean_raw_obs_processing_ms: 0.11922252458380637\n",
      "  time_since_restore: 583.3371651172638\n",
      "  time_this_iter_s: 10.059420824050903\n",
      "  time_total_s: 583.3371651172638\n",
      "  timers:\n",
      "    learn_throughput: 1284.604\n",
      "    learn_time_ms: 6226.045\n",
      "    load_throughput: 24784664.494\n",
      "    load_time_ms: 0.323\n",
      "    sample_throughput: 816.296\n",
      "    sample_time_ms: 9797.913\n",
      "    update_time_ms: 2.851\n",
      "  timestamp: 1645201379\n",
      "  timesteps_since_restore: 479880\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 479880\n",
      "  training_iteration: 60\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:22:59 (running for 00:09:56.25)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         583.337</td><td style=\"text-align: right;\">479880</td><td style=\"text-align: right;\">  173.19</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            173.19</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:23:04 (running for 00:10:01.33)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         583.337</td><td style=\"text-align: right;\">479880</td><td style=\"text-align: right;\">  173.19</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            173.19</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:23:09 (running for 00:10:06.36)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         583.337</td><td style=\"text-align: right;\">479880</td><td style=\"text-align: right;\">  173.19</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            173.19</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 487878\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-23-09\n",
      "  done: false\n",
      "  episode_len_mean: 170.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 170.41\n",
      "  episode_reward_min: 99.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 3409\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 355.09454345703125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.07278791069984436\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.056107595562934875\n",
      "          model: {}\n",
      "          policy_loss: 0.010839208029210567\n",
      "          total_loss: 215.64744567871094\n",
      "          vf_explained_var: 0.7630528807640076\n",
      "          vf_loss: 195.71310424804688\n",
      "    num_agent_steps_sampled: 487878\n",
      "    num_agent_steps_trained: 487878\n",
      "    num_steps_sampled: 487878\n",
      "    num_steps_trained: 487878\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.2642857142857\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09026217777191035\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09145802021913786\n",
      "    mean_inference_ms: 0.9997255081441526\n",
      "    mean_raw_obs_processing_ms: 0.11923068247144603\n",
      "  time_since_restore: 593.6138834953308\n",
      "  time_this_iter_s: 10.276718378067017\n",
      "  time_total_s: 593.6138834953308\n",
      "  timers:\n",
      "    learn_throughput: 1278.115\n",
      "    learn_time_ms: 6257.651\n",
      "    load_throughput: 23901705.302\n",
      "    load_time_ms: 0.335\n",
      "    sample_throughput: 810.44\n",
      "    sample_time_ms: 9868.71\n",
      "    update_time_ms: 3.023\n",
      "  timestamp: 1645201389\n",
      "  timesteps_since_restore: 487878\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 487878\n",
      "  training_iteration: 61\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:23:15 (running for 00:10:11.61)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         593.614</td><td style=\"text-align: right;\">487878</td><td style=\"text-align: right;\">  170.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            170.41</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 495876\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-23-19\n",
      "  done: false\n",
      "  episode_len_mean: 175.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.21\n",
      "  episode_reward_min: 107.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 3455\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 532.641845703125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.06273797899484634\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04616609960794449\n",
      "          model: {}\n",
      "          policy_loss: 0.011953593231737614\n",
      "          total_loss: 182.7661590576172\n",
      "          vf_explained_var: 0.828907310962677\n",
      "          vf_loss: 158.16421508789062\n",
      "    num_agent_steps_sampled: 495876\n",
      "    num_agent_steps_trained: 495876\n",
      "    num_steps_sampled: 495876\n",
      "    num_steps_trained: 495876\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.7\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09025786090369006\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09142429587201951\n",
      "    mean_inference_ms: 1.0008852340642411\n",
      "    mean_raw_obs_processing_ms: 0.11928315535957236\n",
      "  time_since_restore: 603.4627678394318\n",
      "  time_this_iter_s: 9.848884344100952\n",
      "  time_total_s: 603.4627678394318\n",
      "  timers:\n",
      "    learn_throughput: 1276.159\n",
      "    learn_time_ms: 6267.245\n",
      "    load_throughput: 24088786.006\n",
      "    load_time_ms: 0.332\n",
      "    sample_throughput: 806.527\n",
      "    sample_time_ms: 9916.591\n",
      "    update_time_ms: 3.019\n",
      "  timestamp: 1645201399\n",
      "  timesteps_since_restore: 495876\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 495876\n",
      "  training_iteration: 62\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:23:20 (running for 00:10:17.43)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         603.463</td><td style=\"text-align: right;\">495876</td><td style=\"text-align: right;\">  175.21</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 107</td><td style=\"text-align: right;\">            175.21</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:23:25 (running for 00:10:22.49)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         603.463</td><td style=\"text-align: right;\">495876</td><td style=\"text-align: right;\">  175.21</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 107</td><td style=\"text-align: right;\">            175.21</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 503874\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-23-29\n",
      "  done: false\n",
      "  episode_len_mean: 176.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 176.89\n",
      "  episode_reward_min: 107.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 3500\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 798.9627685546875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.06729288399219513\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.075484998524189\n",
      "          model: {}\n",
      "          policy_loss: 0.019685495644807816\n",
      "          total_loss: 268.9708557128906\n",
      "          vf_explained_var: 0.7785211801528931\n",
      "          vf_loss: 208.64146423339844\n",
      "    num_agent_steps_sampled: 503874\n",
      "    num_agent_steps_trained: 503874\n",
      "    num_steps_sampled: 503874\n",
      "    num_steps_trained: 503874\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.37142857142855\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09026338082622681\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09143640888826861\n",
      "    mean_inference_ms: 1.0011884436397618\n",
      "    mean_raw_obs_processing_ms: 0.11929433710346143\n",
      "  time_since_restore: 613.2313663959503\n",
      "  time_this_iter_s: 9.768598556518555\n",
      "  time_total_s: 613.2313663959503\n",
      "  timers:\n",
      "    learn_throughput: 1281.315\n",
      "    learn_time_ms: 6242.026\n",
      "    load_throughput: 24713454.687\n",
      "    load_time_ms: 0.324\n",
      "    sample_throughput: 806.648\n",
      "    sample_time_ms: 9915.107\n",
      "    update_time_ms: 2.953\n",
      "  timestamp: 1645201409\n",
      "  timesteps_since_restore: 503874\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 503874\n",
      "  training_iteration: 63\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:23:31 (running for 00:10:28.23)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         613.231</td><td style=\"text-align: right;\">503874</td><td style=\"text-align: right;\">  176.89</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 107</td><td style=\"text-align: right;\">            176.89</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:23:36 (running for 00:10:33.29)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         613.231</td><td style=\"text-align: right;\">503874</td><td style=\"text-align: right;\">  176.89</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 107</td><td style=\"text-align: right;\">            176.89</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 511872\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-23-39\n",
      "  done: false\n",
      "  episode_len_mean: 179.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 179.85\n",
      "  episode_reward_min: 106.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 3545\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1198.444091796875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.09038178622722626\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.049379922449588776\n",
      "          model: {}\n",
      "          policy_loss: 0.014875239692628384\n",
      "          total_loss: 280.5402526855469\n",
      "          vf_explained_var: 0.6930385828018188\n",
      "          vf_loss: 221.34629821777344\n",
      "    num_agent_steps_sampled: 511872\n",
      "    num_agent_steps_trained: 511872\n",
      "    num_steps_sampled: 511872\n",
      "    num_steps_trained: 511872\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.99285714285713\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09027425569015765\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09146222564061265\n",
      "    mean_inference_ms: 1.0016102143376435\n",
      "    mean_raw_obs_processing_ms: 0.1193303596197244\n",
      "  time_since_restore: 623.033096075058\n",
      "  time_this_iter_s: 9.801729679107666\n",
      "  time_total_s: 623.033096075058\n",
      "  timers:\n",
      "    learn_throughput: 1282.726\n",
      "    learn_time_ms: 6235.16\n",
      "    load_throughput: 25146959.064\n",
      "    load_time_ms: 0.318\n",
      "    sample_throughput: 809.184\n",
      "    sample_time_ms: 9884.035\n",
      "    update_time_ms: 2.932\n",
      "  timestamp: 1645201419\n",
      "  timesteps_since_restore: 511872\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 511872\n",
      "  training_iteration: 64\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:23:42 (running for 00:10:39.06)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         623.033</td><td style=\"text-align: right;\">511872</td><td style=\"text-align: right;\">  179.85</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 106</td><td style=\"text-align: right;\">            179.85</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:23:47 (running for 00:10:44.12)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         623.033</td><td style=\"text-align: right;\">511872</td><td style=\"text-align: right;\">  179.85</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 106</td><td style=\"text-align: right;\">            179.85</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 519870\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-23-49\n",
      "  done: false\n",
      "  episode_len_mean: 182.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 182.41\n",
      "  episode_reward_min: 101.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 3589\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1797.6661376953125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.09609381854534149\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.058910153806209564\n",
      "          model: {}\n",
      "          policy_loss: 0.02336357720196247\n",
      "          total_loss: 384.6606750488281\n",
      "          vf_explained_var: 0.6140781044960022\n",
      "          vf_loss: 278.7365417480469\n",
      "    num_agent_steps_sampled: 519870\n",
      "    num_agent_steps_trained: 519870\n",
      "    num_steps_sampled: 519870\n",
      "    num_steps_trained: 519870\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.34285714285714\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09027970125294996\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09148137699773691\n",
      "    mean_inference_ms: 1.001728804855438\n",
      "    mean_raw_obs_processing_ms: 0.11930608675495666\n",
      "  time_since_restore: 632.7496817111969\n",
      "  time_this_iter_s: 9.716585636138916\n",
      "  time_total_s: 632.7496817111969\n",
      "  timers:\n",
      "    learn_throughput: 1280.117\n",
      "    learn_time_ms: 6247.869\n",
      "    load_throughput: 25099920.233\n",
      "    load_time_ms: 0.319\n",
      "    sample_throughput: 811.059\n",
      "    sample_time_ms: 9861.181\n",
      "    update_time_ms: 2.944\n",
      "  timestamp: 1645201429\n",
      "  timesteps_since_restore: 519870\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 519870\n",
      "  training_iteration: 65\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:23:53 (running for 00:10:49.80)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">          632.75</td><td style=\"text-align: right;\">519870</td><td style=\"text-align: right;\">  182.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 101</td><td style=\"text-align: right;\">            182.41</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:23:58 (running for 00:10:54.88)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">          632.75</td><td style=\"text-align: right;\">519870</td><td style=\"text-align: right;\">  182.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 101</td><td style=\"text-align: right;\">            182.41</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 527868\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-23-59\n",
      "  done: false\n",
      "  episode_len_mean: 181.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 181.31\n",
      "  episode_reward_min: 99.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 3631\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2696.499267578125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.11226452142000198\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.05230628326535225\n",
      "          model: {}\n",
      "          policy_loss: 0.02587195485830307\n",
      "          total_loss: 368.7185363769531\n",
      "          vf_explained_var: 0.7480672597885132\n",
      "          vf_loss: 227.6488037109375\n",
      "    num_agent_steps_sampled: 527868\n",
      "    num_agent_steps_trained: 527868\n",
      "    num_steps_sampled: 527868\n",
      "    num_steps_trained: 527868\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.14999999999999\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09028894362511992\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09147494747746547\n",
      "    mean_inference_ms: 1.0021533038304862\n",
      "    mean_raw_obs_processing_ms: 0.11934455574946307\n",
      "  time_since_restore: 642.7641868591309\n",
      "  time_this_iter_s: 10.01450514793396\n",
      "  time_total_s: 642.7641868591309\n",
      "  timers:\n",
      "    learn_throughput: 1275.03\n",
      "    learn_time_ms: 6272.792\n",
      "    load_throughput: 24937588.011\n",
      "    load_time_ms: 0.321\n",
      "    sample_throughput: 808.316\n",
      "    sample_time_ms: 9894.649\n",
      "    update_time_ms: 2.917\n",
      "  timestamp: 1645201439\n",
      "  timesteps_since_restore: 527868\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 527868\n",
      "  training_iteration: 66\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:24:04 (running for 00:11:00.85)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         642.764</td><td style=\"text-align: right;\">527868</td><td style=\"text-align: right;\">  181.31</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            181.31</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 535866\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-24-09\n",
      "  done: false\n",
      "  episode_len_mean: 184.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 184.75\n",
      "  episode_reward_min: 99.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 3675\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4044.7490234375\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.09823477268218994\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.044182587414979935\n",
      "          model: {}\n",
      "          policy_loss: 0.013477074913680553\n",
      "          total_loss: 465.8087463378906\n",
      "          vf_explained_var: 0.6733625531196594\n",
      "          vf_loss: 287.0877990722656\n",
      "    num_agent_steps_sampled: 535866\n",
      "    num_agent_steps_trained: 535866\n",
      "    num_steps_sampled: 535866\n",
      "    num_steps_trained: 535866\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.66\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09031072248197511\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09147558342095437\n",
      "    mean_inference_ms: 1.002158532269778\n",
      "    mean_raw_obs_processing_ms: 0.11936737845296447\n",
      "  time_since_restore: 652.6281704902649\n",
      "  time_this_iter_s: 9.863983631134033\n",
      "  time_total_s: 652.6281704902649\n",
      "  timers:\n",
      "    learn_throughput: 1272.344\n",
      "    learn_time_ms: 6286.036\n",
      "    load_throughput: 24644463.262\n",
      "    load_time_ms: 0.325\n",
      "    sample_throughput: 805.468\n",
      "    sample_time_ms: 9929.625\n",
      "    update_time_ms: 2.976\n",
      "  timestamp: 1645201449\n",
      "  timesteps_since_restore: 535866\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 535866\n",
      "  training_iteration: 67\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:24:10 (running for 00:11:06.72)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         652.628</td><td style=\"text-align: right;\">535866</td><td style=\"text-align: right;\">  184.75</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            184.75</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:24:15 (running for 00:11:11.75)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         652.628</td><td style=\"text-align: right;\">535866</td><td style=\"text-align: right;\">  184.75</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  99</td><td style=\"text-align: right;\">            184.75</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 543864\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-24-18\n",
      "  done: false\n",
      "  episode_len_mean: 189.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 189.97\n",
      "  episode_reward_min: 107.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 3716\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 6067.12353515625\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.09458549320697784\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04621560871601105\n",
      "          model: {}\n",
      "          policy_loss: 0.01467897742986679\n",
      "          total_loss: 527.0311889648438\n",
      "          vf_explained_var: 0.6963675022125244\n",
      "          vf_loss: 246.62071228027344\n",
      "    num_agent_steps_sampled: 543864\n",
      "    num_agent_steps_trained: 543864\n",
      "    num_steps_sampled: 543864\n",
      "    num_steps_trained: 543864\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.01538461538463\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0903179038058617\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09146649519103939\n",
      "    mean_inference_ms: 1.0020219987960894\n",
      "    mean_raw_obs_processing_ms: 0.11937173576954024\n",
      "  time_since_restore: 662.1933686733246\n",
      "  time_this_iter_s: 9.565198183059692\n",
      "  time_total_s: 662.1933686733246\n",
      "  timers:\n",
      "    learn_throughput: 1278.886\n",
      "    learn_time_ms: 6253.88\n",
      "    load_throughput: 24902415.108\n",
      "    load_time_ms: 0.321\n",
      "    sample_throughput: 805.256\n",
      "    sample_time_ms: 9932.245\n",
      "    update_time_ms: 2.957\n",
      "  timestamp: 1645201458\n",
      "  timesteps_since_restore: 543864\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 543864\n",
      "  training_iteration: 68\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:24:20 (running for 00:11:17.32)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         662.193</td><td style=\"text-align: right;\">543864</td><td style=\"text-align: right;\">  189.97</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 107</td><td style=\"text-align: right;\">            189.97</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:24:25 (running for 00:11:22.34)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         662.193</td><td style=\"text-align: right;\">543864</td><td style=\"text-align: right;\">  189.97</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 107</td><td style=\"text-align: right;\">            189.97</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 551862\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-24-28\n",
      "  done: false\n",
      "  episode_len_mean: 190.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 190.16\n",
      "  episode_reward_min: 107.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 3759\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 9100.6845703125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.08885835856199265\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.044808633625507355\n",
      "          model: {}\n",
      "          policy_loss: 0.01176194753497839\n",
      "          total_loss: 635.5819702148438\n",
      "          vf_explained_var: 0.7220821380615234\n",
      "          vf_loss: 227.78099060058594\n",
      "    num_agent_steps_sampled: 551862\n",
      "    num_agent_steps_trained: 551862\n",
      "    num_steps_sampled: 551862\n",
      "    num_steps_trained: 551862\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.51428571428572\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09030932268158186\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0914387357158325\n",
      "    mean_inference_ms: 1.0017172512844805\n",
      "    mean_raw_obs_processing_ms: 0.11934182717625964\n",
      "  time_since_restore: 671.980465888977\n",
      "  time_this_iter_s: 9.787097215652466\n",
      "  time_total_s: 671.980465888977\n",
      "  timers:\n",
      "    learn_throughput: 1279.691\n",
      "    learn_time_ms: 6249.945\n",
      "    load_throughput: 25194174.534\n",
      "    load_time_ms: 0.317\n",
      "    sample_throughput: 807.847\n",
      "    sample_time_ms: 9900.392\n",
      "    update_time_ms: 2.906\n",
      "  timestamp: 1645201468\n",
      "  timesteps_since_restore: 551862\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 551862\n",
      "  training_iteration: 69\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:24:31 (running for 00:11:28.14)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">          671.98</td><td style=\"text-align: right;\">551862</td><td style=\"text-align: right;\">  190.16</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 107</td><td style=\"text-align: right;\">            190.16</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:24:36 (running for 00:11:33.16)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">          671.98</td><td style=\"text-align: right;\">551862</td><td style=\"text-align: right;\">  190.16</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 107</td><td style=\"text-align: right;\">            190.16</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 559860\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-24-38\n",
      "  done: false\n",
      "  episode_len_mean: 185.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 185.07\n",
      "  episode_reward_min: 106.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 3804\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 13651.02734375\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.07829993963241577\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03625166788697243\n",
      "          model: {}\n",
      "          policy_loss: 0.009748688898980618\n",
      "          total_loss: 796.2630615234375\n",
      "          vf_explained_var: 0.6693958044052124\n",
      "          vf_loss: 301.3807678222656\n",
      "    num_agent_steps_sampled: 559860\n",
      "    num_agent_steps_trained: 559860\n",
      "    num_steps_sampled: 559860\n",
      "    num_steps_trained: 559860\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.07142857142858\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0903201885205528\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09147332047216712\n",
      "    mean_inference_ms: 1.0017222169416125\n",
      "    mean_raw_obs_processing_ms: 0.11928424295345641\n",
      "  time_since_restore: 681.9399991035461\n",
      "  time_this_iter_s: 9.959533214569092\n",
      "  time_total_s: 681.9399991035461\n",
      "  timers:\n",
      "    learn_throughput: 1282.612\n",
      "    learn_time_ms: 6235.711\n",
      "    load_throughput: 25051186.164\n",
      "    load_time_ms: 0.319\n",
      "    sample_throughput: 807.864\n",
      "    sample_time_ms: 9900.185\n",
      "    update_time_ms: 2.929\n",
      "  timestamp: 1645201478\n",
      "  timesteps_since_restore: 559860\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 559860\n",
      "  training_iteration: 70\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:24:42 (running for 00:11:39.16)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">          681.94</td><td style=\"text-align: right;\">559860</td><td style=\"text-align: right;\">  185.07</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 106</td><td style=\"text-align: right;\">            185.07</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:24:47 (running for 00:11:44.18)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">          681.94</td><td style=\"text-align: right;\">559860</td><td style=\"text-align: right;\">  185.07</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 106</td><td style=\"text-align: right;\">            185.07</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 567858\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-24-48\n",
      "  done: false\n",
      "  episode_len_mean: 183.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 183.16\n",
      "  episode_reward_min: 106.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 3847\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 20476.541015625\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.07793374359607697\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04186750575900078\n",
      "          model: {}\n",
      "          policy_loss: 0.014838268049061298\n",
      "          total_loss: 1119.9896240234375\n",
      "          vf_explained_var: 0.6503315567970276\n",
      "          vf_loss: 262.6730651855469\n",
      "    num_agent_steps_sampled: 567858\n",
      "    num_agent_steps_trained: 567858\n",
      "    num_steps_sampled: 567858\n",
      "    num_steps_trained: 567858\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.95714285714286\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.090341039085186\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09149556771400748\n",
      "    mean_inference_ms: 1.0020708912120369\n",
      "    mean_raw_obs_processing_ms: 0.11930465976518011\n",
      "  time_since_restore: 691.6238849163055\n",
      "  time_this_iter_s: 9.6838858127594\n",
      "  time_total_s: 691.6238849163055\n",
      "  timers:\n",
      "    learn_throughput: 1287.726\n",
      "    learn_time_ms: 6210.946\n",
      "    load_throughput: 26226286.758\n",
      "    load_time_ms: 0.305\n",
      "    sample_throughput: 811.847\n",
      "    sample_time_ms: 9851.612\n",
      "    update_time_ms: 2.788\n",
      "  timestamp: 1645201488\n",
      "  timesteps_since_restore: 567858\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 567858\n",
      "  training_iteration: 71\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:24:53 (running for 00:11:49.88)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         691.624</td><td style=\"text-align: right;\">567858</td><td style=\"text-align: right;\">  183.16</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 106</td><td style=\"text-align: right;\">            183.16</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 575856\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-24-58\n",
      "  done: false\n",
      "  episode_len_mean: 180.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 180.18\n",
      "  episode_reward_min: 103.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 3892\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 30714.8125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.0742148831486702\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.034302208572626114\n",
      "          model: {}\n",
      "          policy_loss: 0.0029575650114566088\n",
      "          total_loss: 1347.92578125\n",
      "          vf_explained_var: 0.6333418488502502\n",
      "          vf_loss: 294.3370056152344\n",
      "    num_agent_steps_sampled: 575856\n",
      "    num_agent_steps_trained: 575856\n",
      "    num_steps_sampled: 575856\n",
      "    num_steps_trained: 575856\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.63571428571429\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09035646187239423\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09150501976048897\n",
      "    mean_inference_ms: 1.0023253744700398\n",
      "    mean_raw_obs_processing_ms: 0.11932045420418316\n",
      "  time_since_restore: 701.347279548645\n",
      "  time_this_iter_s: 9.723394632339478\n",
      "  time_total_s: 701.347279548645\n",
      "  timers:\n",
      "    learn_throughput: 1289.279\n",
      "    learn_time_ms: 6203.465\n",
      "    load_throughput: 25415594.66\n",
      "    load_time_ms: 0.315\n",
      "    sample_throughput: 814.322\n",
      "    sample_time_ms: 9821.67\n",
      "    update_time_ms: 2.744\n",
      "  timestamp: 1645201498\n",
      "  timesteps_since_restore: 575856\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 575856\n",
      "  training_iteration: 72\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:24:59 (running for 00:11:55.57)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         701.347</td><td style=\"text-align: right;\">575856</td><td style=\"text-align: right;\">  180.18</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 103</td><td style=\"text-align: right;\">            180.18</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:25:04 (running for 00:12:00.63)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         701.347</td><td style=\"text-align: right;\">575856</td><td style=\"text-align: right;\">  180.18</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 103</td><td style=\"text-align: right;\">            180.18</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 583854\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-25-07\n",
      "  done: false\n",
      "  episode_len_mean: 177.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 177.57\n",
      "  episode_reward_min: 103.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 3936\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 46072.21875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.07232031971216202\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04250494763255119\n",
      "          model: {}\n",
      "          policy_loss: 0.011422532610595226\n",
      "          total_loss: 2218.33154296875\n",
      "          vf_explained_var: 0.6702271699905396\n",
      "          vf_loss: 260.0224609375\n",
      "    num_agent_steps_sampled: 583854\n",
      "    num_agent_steps_trained: 583854\n",
      "    num_steps_sampled: 583854\n",
      "    num_steps_trained: 583854\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.72142857142858\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09036614350588776\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09151192245630231\n",
      "    mean_inference_ms: 1.0021531207329135\n",
      "    mean_raw_obs_processing_ms: 0.11927826406618067\n",
      "  time_since_restore: 711.2010769844055\n",
      "  time_this_iter_s: 9.853797435760498\n",
      "  time_total_s: 711.2010769844055\n",
      "  timers:\n",
      "    learn_throughput: 1286.018\n",
      "    learn_time_ms: 6219.197\n",
      "    load_throughput: 24836043.083\n",
      "    load_time_ms: 0.322\n",
      "    sample_throughput: 815.511\n",
      "    sample_time_ms: 9807.348\n",
      "    update_time_ms: 2.769\n",
      "  timestamp: 1645201507\n",
      "  timesteps_since_restore: 583854\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 583854\n",
      "  training_iteration: 73\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:25:09 (running for 00:12:06.45)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         711.201</td><td style=\"text-align: right;\">583854</td><td style=\"text-align: right;\">  177.57</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 103</td><td style=\"text-align: right;\">            177.57</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:25:14 (running for 00:12:11.52)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         711.201</td><td style=\"text-align: right;\">583854</td><td style=\"text-align: right;\">  177.57</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 103</td><td style=\"text-align: right;\">            177.57</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 591852\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-25-17\n",
      "  done: false\n",
      "  episode_len_mean: 180.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 180.86\n",
      "  episode_reward_min: 97.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 3979\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 69108.328125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.06449325382709503\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02399345301091671\n",
      "          model: {}\n",
      "          policy_loss: 0.005901125725358725\n",
      "          total_loss: 1894.916748046875\n",
      "          vf_explained_var: 0.6755633354187012\n",
      "          vf_loss: 236.76353454589844\n",
      "    num_agent_steps_sampled: 591852\n",
      "    num_agent_steps_trained: 591852\n",
      "    num_steps_sampled: 591852\n",
      "    num_steps_trained: 591852\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.37857142857142\n",
      "    ram_util_percent: 17.81428571428572\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09035928825060215\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09148440878949861\n",
      "    mean_inference_ms: 1.001958701197324\n",
      "    mean_raw_obs_processing_ms: 0.11926210101060337\n",
      "  time_since_restore: 721.1003668308258\n",
      "  time_this_iter_s: 9.899289846420288\n",
      "  time_total_s: 721.1003668308258\n",
      "  timers:\n",
      "    learn_throughput: 1284.216\n",
      "    learn_time_ms: 6227.922\n",
      "    load_throughput: 24200002.447\n",
      "    load_time_ms: 0.33\n",
      "    sample_throughput: 814.147\n",
      "    sample_time_ms: 9823.78\n",
      "    update_time_ms: 2.844\n",
      "  timestamp: 1645201517\n",
      "  timesteps_since_restore: 591852\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 591852\n",
      "  training_iteration: 74\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:25:20 (running for 00:12:17.38)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">           721.1</td><td style=\"text-align: right;\">591852</td><td style=\"text-align: right;\">  180.86</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            180.86</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:25:25 (running for 00:12:22.45)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">           721.1</td><td style=\"text-align: right;\">591852</td><td style=\"text-align: right;\">  180.86</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            180.86</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 599850\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-25-27\n",
      "  done: false\n",
      "  episode_len_mean: 182.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 182.29\n",
      "  episode_reward_min: 93.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 4023\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 103662.4921875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.04869302734732628\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03032515197992325\n",
      "          model: {}\n",
      "          policy_loss: 0.010228361934423447\n",
      "          total_loss: 3448.0419921875\n",
      "          vf_explained_var: 0.6412744522094727\n",
      "          vf_loss: 304.4510192871094\n",
      "    num_agent_steps_sampled: 599850\n",
      "    num_agent_steps_trained: 599850\n",
      "    num_steps_sampled: 599850\n",
      "    num_steps_trained: 599850\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.50666666666666\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09034981714347518\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09147939082446549\n",
      "    mean_inference_ms: 1.0020713204464102\n",
      "    mean_raw_obs_processing_ms: 0.11924771277966643\n",
      "  time_since_restore: 731.127771615982\n",
      "  time_this_iter_s: 10.02740478515625\n",
      "  time_total_s: 731.127771615982\n",
      "  timers:\n",
      "    learn_throughput: 1278.443\n",
      "    learn_time_ms: 6256.047\n",
      "    load_throughput: 23590747.814\n",
      "    load_time_ms: 0.339\n",
      "    sample_throughput: 813.212\n",
      "    sample_time_ms: 9835.078\n",
      "    update_time_ms: 2.844\n",
      "  timestamp: 1645201527\n",
      "  timesteps_since_restore: 599850\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 599850\n",
      "  training_iteration: 75\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:25:31 (running for 00:12:28.49)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         731.128</td><td style=\"text-align: right;\">599850</td><td style=\"text-align: right;\">  182.29</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  93</td><td style=\"text-align: right;\">            182.29</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:25:36 (running for 00:12:33.52)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         731.128</td><td style=\"text-align: right;\">599850</td><td style=\"text-align: right;\">  182.29</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  93</td><td style=\"text-align: right;\">            182.29</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 607848\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-25-37\n",
      "  done: false\n",
      "  episode_len_mean: 184.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 184.35\n",
      "  episode_reward_min: 88.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 4066\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 155493.734375\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.04176419973373413\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028988294303417206\n",
      "          model: {}\n",
      "          policy_loss: 0.007723824121057987\n",
      "          total_loss: 4785.05810546875\n",
      "          vf_explained_var: 0.6563820242881775\n",
      "          vf_loss: 277.5525207519531\n",
      "    num_agent_steps_sampled: 607848\n",
      "    num_agent_steps_trained: 607848\n",
      "    num_steps_sampled: 607848\n",
      "    num_steps_trained: 607848\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.72857142857143\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09035407272479017\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09148616917581588\n",
      "    mean_inference_ms: 1.0020464487559024\n",
      "    mean_raw_obs_processing_ms: 0.11924249366745521\n",
      "  time_since_restore: 740.9463646411896\n",
      "  time_this_iter_s: 9.81859302520752\n",
      "  time_total_s: 740.9463646411896\n",
      "  timers:\n",
      "    learn_throughput: 1280.487\n",
      "    learn_time_ms: 6246.061\n",
      "    load_throughput: 23494917.63\n",
      "    load_time_ms: 0.34\n",
      "    sample_throughput: 811.675\n",
      "    sample_time_ms: 9853.703\n",
      "    update_time_ms: 2.834\n",
      "  timestamp: 1645201537\n",
      "  timesteps_since_restore: 607848\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 607848\n",
      "  training_iteration: 76\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:25:42 (running for 00:12:39.32)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         740.946</td><td style=\"text-align: right;\">607848</td><td style=\"text-align: right;\">  184.35</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  88</td><td style=\"text-align: right;\">            184.35</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 615846\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-25-47\n",
      "  done: false\n",
      "  episode_len_mean: 181.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 181.1\n",
      "  episode_reward_min: 88.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 4110\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 233240.609375\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.03289351239800453\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026309622451663017\n",
      "          model: {}\n",
      "          policy_loss: 0.018500838428735733\n",
      "          total_loss: 6463.7939453125\n",
      "          vf_explained_var: 0.5319949388504028\n",
      "          vf_loss: 327.3034362792969\n",
      "    num_agent_steps_sampled: 615846\n",
      "    num_agent_steps_trained: 615846\n",
      "    num_steps_sampled: 615846\n",
      "    num_steps_trained: 615846\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.33571428571429\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09036125652826615\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09149272234268004\n",
      "    mean_inference_ms: 1.0016759326825442\n",
      "    mean_raw_obs_processing_ms: 0.11918270311854126\n",
      "  time_since_restore: 750.6604614257812\n",
      "  time_this_iter_s: 9.714096784591675\n",
      "  time_total_s: 750.6604614257812\n",
      "  timers:\n",
      "    learn_throughput: 1282.385\n",
      "    learn_time_ms: 6236.819\n",
      "    load_throughput: 23610672.432\n",
      "    load_time_ms: 0.339\n",
      "    sample_throughput: 812.976\n",
      "    sample_time_ms: 9837.924\n",
      "    update_time_ms: 2.819\n",
      "  timestamp: 1645201547\n",
      "  timesteps_since_restore: 615846\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 615846\n",
      "  training_iteration: 77\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:25:48 (running for 00:12:45.01)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">          750.66</td><td style=\"text-align: right;\">615846</td><td style=\"text-align: right;\">   181.1</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  88</td><td style=\"text-align: right;\">             181.1</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:25:53 (running for 00:12:50.08)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">          750.66</td><td style=\"text-align: right;\">615846</td><td style=\"text-align: right;\">   181.1</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  88</td><td style=\"text-align: right;\">             181.1</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 623844\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-25-57\n",
      "  done: false\n",
      "  episode_len_mean: 183.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 183.61\n",
      "  episode_reward_min: 82.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 4154\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 349860.90625\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.03017914667725563\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.035358645021915436\n",
      "          model: {}\n",
      "          policy_loss: 0.008038992062211037\n",
      "          total_loss: 12597.7197265625\n",
      "          vf_explained_var: 0.6852481961250305\n",
      "          vf_loss: 227.1036834716797\n",
      "    num_agent_steps_sampled: 623844\n",
      "    num_agent_steps_trained: 623844\n",
      "    num_steps_sampled: 623844\n",
      "    num_steps_trained: 623844\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.87142857142857\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09036988624659983\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0915036107441987\n",
      "    mean_inference_ms: 1.001664935309703\n",
      "    mean_raw_obs_processing_ms: 0.11914484323677424\n",
      "  time_since_restore: 760.4820206165314\n",
      "  time_this_iter_s: 9.821559190750122\n",
      "  time_total_s: 760.4820206165314\n",
      "  timers:\n",
      "    learn_throughput: 1277.707\n",
      "    learn_time_ms: 6259.65\n",
      "    load_throughput: 23759503.784\n",
      "    load_time_ms: 0.337\n",
      "    sample_throughput: 813.532\n",
      "    sample_time_ms: 9831.21\n",
      "    update_time_ms: 2.794\n",
      "  timestamp: 1645201557\n",
      "  timesteps_since_restore: 623844\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 623844\n",
      "  training_iteration: 78\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:25:59 (running for 00:12:55.86)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         760.482</td><td style=\"text-align: right;\">623844</td><td style=\"text-align: right;\">  183.61</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            183.61</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:26:04 (running for 00:13:00.92)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         760.482</td><td style=\"text-align: right;\">623844</td><td style=\"text-align: right;\">  183.61</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            183.61</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 631842\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-26-07\n",
      "  done: false\n",
      "  episode_len_mean: 181.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 181.27\n",
      "  episode_reward_min: 82.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 4199\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 524791.375\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02766423299908638\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022483861073851585\n",
      "          model: {}\n",
      "          policy_loss: 0.009451253339648247\n",
      "          total_loss: 12017.818359375\n",
      "          vf_explained_var: 0.6944977641105652\n",
      "          vf_loss: 218.4730987548828\n",
      "    num_agent_steps_sampled: 631842\n",
      "    num_agent_steps_trained: 631842\n",
      "    num_steps_sampled: 631842\n",
      "    num_steps_trained: 631842\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.36428571428571\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09036687766099373\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09147510202078779\n",
      "    mean_inference_ms: 1.0015743732804943\n",
      "    mean_raw_obs_processing_ms: 0.11917097798976566\n",
      "  time_since_restore: 770.418949842453\n",
      "  time_this_iter_s: 9.93692922592163\n",
      "  time_total_s: 770.418949842453\n",
      "  timers:\n",
      "    learn_throughput: 1274.779\n",
      "    learn_time_ms: 6274.031\n",
      "    load_throughput: 23434190.284\n",
      "    load_time_ms: 0.341\n",
      "    sample_throughput: 811.599\n",
      "    sample_time_ms: 9854.622\n",
      "    update_time_ms: 2.84\n",
      "  timestamp: 1645201567\n",
      "  timesteps_since_restore: 631842\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 631842\n",
      "  training_iteration: 79\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:26:10 (running for 00:13:06.83)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         770.419</td><td style=\"text-align: right;\">631842</td><td style=\"text-align: right;\">  181.27</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            181.27</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:26:15 (running for 00:13:11.89)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         770.419</td><td style=\"text-align: right;\">631842</td><td style=\"text-align: right;\">  181.27</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            181.27</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 639840\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-26-17\n",
      "  done: false\n",
      "  episode_len_mean: 180.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 180.33\n",
      "  episode_reward_min: 82.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 4242\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 787187.0625\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.0327552855014801\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.040627431124448776\n",
      "          model: {}\n",
      "          policy_loss: 0.008761856704950333\n",
      "          total_loss: 32230.064453125\n",
      "          vf_explained_var: 0.6407372355461121\n",
      "          vf_loss: 248.6653594970703\n",
      "    num_agent_steps_sampled: 639840\n",
      "    num_agent_steps_trained: 639840\n",
      "    num_steps_sampled: 639840\n",
      "    num_steps_trained: 639840\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.13571428571429\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09036370710576044\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09146372589334632\n",
      "    mean_inference_ms: 1.001520613742841\n",
      "    mean_raw_obs_processing_ms: 0.11914688093717764\n",
      "  time_since_restore: 780.3699979782104\n",
      "  time_this_iter_s: 9.951048135757446\n",
      "  time_total_s: 780.3699979782104\n",
      "  timers:\n",
      "    learn_throughput: 1272.293\n",
      "    learn_time_ms: 6286.288\n",
      "    load_throughput: 23195991.835\n",
      "    load_time_ms: 0.345\n",
      "    sample_throughput: 811.483\n",
      "    sample_time_ms: 9856.026\n",
      "    update_time_ms: 2.859\n",
      "  timestamp: 1645201577\n",
      "  timesteps_since_restore: 639840\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 639840\n",
      "  training_iteration: 80\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:26:21 (running for 00:13:17.80)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">          780.37</td><td style=\"text-align: right;\">639840</td><td style=\"text-align: right;\">  180.33</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            180.33</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:26:26 (running for 00:13:22.87)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">          780.37</td><td style=\"text-align: right;\">639840</td><td style=\"text-align: right;\">  180.33</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            180.33</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 647838\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-26-26\n",
      "  done: false\n",
      "  episode_len_mean: 175.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.69\n",
      "  episode_reward_min: 83.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 4288\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1180780.5\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.03205905854701996\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028700711205601692\n",
      "          model: {}\n",
      "          policy_loss: 0.015816766768693924\n",
      "          total_loss: 34152.7109375\n",
      "          vf_explained_var: 0.6421068906784058\n",
      "          vf_loss: 263.4527893066406\n",
      "    num_agent_steps_sampled: 647838\n",
      "    num_agent_steps_trained: 647838\n",
      "    num_steps_sampled: 647838\n",
      "    num_steps_trained: 647838\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.67857142857142\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09034406399833383\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09144185888541745\n",
      "    mean_inference_ms: 1.0011562481296408\n",
      "    mean_raw_obs_processing_ms: 0.11907068363428\n",
      "  time_since_restore: 789.9614808559418\n",
      "  time_this_iter_s: 9.591482877731323\n",
      "  time_total_s: 789.9614808559418\n",
      "  timers:\n",
      "    learn_throughput: 1271.63\n",
      "    learn_time_ms: 6289.568\n",
      "    load_throughput: 22764687.427\n",
      "    load_time_ms: 0.351\n",
      "    sample_throughput: 811.518\n",
      "    sample_time_ms: 9855.608\n",
      "    update_time_ms: 2.893\n",
      "  timestamp: 1645201586\n",
      "  timesteps_since_restore: 647838\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 647838\n",
      "  training_iteration: 81\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:26:31 (running for 00:13:28.43)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         789.961</td><td style=\"text-align: right;\">647838</td><td style=\"text-align: right;\">  175.69</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            175.69</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 655836\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-26-36\n",
      "  done: false\n",
      "  episode_len_mean: 178.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 178.1\n",
      "  episode_reward_min: 83.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 4333\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1771170.875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.027066215872764587\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03411105275154114\n",
      "          model: {}\n",
      "          policy_loss: 0.017079602926969528\n",
      "          total_loss: 60672.71484375\n",
      "          vf_explained_var: 0.7053281664848328\n",
      "          vf_loss: 256.1925964355469\n",
      "    num_agent_steps_sampled: 655836\n",
      "    num_agent_steps_trained: 655836\n",
      "    num_steps_sampled: 655836\n",
      "    num_steps_trained: 655836\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.64285714285714\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09031771072423751\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09140527229045388\n",
      "    mean_inference_ms: 1.000606357313243\n",
      "    mean_raw_obs_processing_ms: 0.11901385103282408\n",
      "  time_since_restore: 799.9354772567749\n",
      "  time_this_iter_s: 9.97399640083313\n",
      "  time_total_s: 799.9354772567749\n",
      "  timers:\n",
      "    learn_throughput: 1265.447\n",
      "    learn_time_ms: 6320.297\n",
      "    load_throughput: 23237769.044\n",
      "    load_time_ms: 0.344\n",
      "    sample_throughput: 811.702\n",
      "    sample_time_ms: 9853.368\n",
      "    update_time_ms: 3.026\n",
      "  timestamp: 1645201596\n",
      "  timesteps_since_restore: 655836\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 655836\n",
      "  training_iteration: 82\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:26:36 (running for 00:13:33.45)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         799.935</td><td style=\"text-align: right;\">655836</td><td style=\"text-align: right;\">   178.1</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">             178.1</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:26:41 (running for 00:13:38.48)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         799.935</td><td style=\"text-align: right;\">655836</td><td style=\"text-align: right;\">   178.1</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">             178.1</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 663834\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-26-46\n",
      "  done: false\n",
      "  episode_len_mean: 175.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.92\n",
      "  episode_reward_min: 83.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 4378\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2656756.25\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02069110795855522\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030612369999289513\n",
      "          model: {}\n",
      "          policy_loss: 0.017735665664076805\n",
      "          total_loss: 81551.5703125\n",
      "          vf_explained_var: 0.6727303862571716\n",
      "          vf_loss: 221.94873046875\n",
      "    num_agent_steps_sampled: 663834\n",
      "    num_agent_steps_trained: 663834\n",
      "    num_steps_sampled: 663834\n",
      "    num_steps_trained: 663834\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.46428571428571\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09031586351769602\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09139820927031864\n",
      "    mean_inference_ms: 1.0004259977366456\n",
      "    mean_raw_obs_processing_ms: 0.11899702082136289\n",
      "  time_since_restore: 809.7701532840729\n",
      "  time_this_iter_s: 9.834676027297974\n",
      "  time_total_s: 809.7701532840729\n",
      "  timers:\n",
      "    learn_throughput: 1267.024\n",
      "    learn_time_ms: 6312.432\n",
      "    load_throughput: 23720862.249\n",
      "    load_time_ms: 0.337\n",
      "    sample_throughput: 808.727\n",
      "    sample_time_ms: 9889.615\n",
      "    update_time_ms: 3.034\n",
      "  timestamp: 1645201606\n",
      "  timesteps_since_restore: 663834\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 663834\n",
      "  training_iteration: 83\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:26:47 (running for 00:13:44.34)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">          809.77</td><td style=\"text-align: right;\">663834</td><td style=\"text-align: right;\">  175.92</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            175.92</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:26:52 (running for 00:13:49.36)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">          809.77</td><td style=\"text-align: right;\">663834</td><td style=\"text-align: right;\">  175.92</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            175.92</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 671832\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-26-56\n",
      "  done: false\n",
      "  episode_len_mean: 175.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.39\n",
      "  episode_reward_min: 85.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 4424\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3985134.5\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.018582915887236595\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03589525818824768\n",
      "          model: {}\n",
      "          policy_loss: 0.009562049061059952\n",
      "          total_loss: 143311.625\n",
      "          vf_explained_var: 0.7043545246124268\n",
      "          vf_loss: 264.1917724609375\n",
      "    num_agent_steps_sampled: 671832\n",
      "    num_agent_steps_trained: 671832\n",
      "    num_steps_sampled: 671832\n",
      "    num_steps_trained: 671832\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.87857142857143\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09032835800321287\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09141830524923211\n",
      "    mean_inference_ms: 1.0004646923850593\n",
      "    mean_raw_obs_processing_ms: 0.11897724012950758\n",
      "  time_since_restore: 819.5488302707672\n",
      "  time_this_iter_s: 9.778676986694336\n",
      "  time_total_s: 819.5488302707672\n",
      "  timers:\n",
      "    learn_throughput: 1268.627\n",
      "    learn_time_ms: 6304.453\n",
      "    load_throughput: 24121696.55\n",
      "    load_time_ms: 0.332\n",
      "    sample_throughput: 809.639\n",
      "    sample_time_ms: 9878.478\n",
      "    update_time_ms: 3.071\n",
      "  timestamp: 1645201616\n",
      "  timesteps_since_restore: 671832\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 671832\n",
      "  training_iteration: 84\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:26:58 (running for 00:13:55.13)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         819.549</td><td style=\"text-align: right;\">671832</td><td style=\"text-align: right;\">  175.39</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  85</td><td style=\"text-align: right;\">            175.39</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:27:03 (running for 00:14:00.15)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         819.549</td><td style=\"text-align: right;\">671832</td><td style=\"text-align: right;\">  175.39</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  85</td><td style=\"text-align: right;\">            175.39</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 679830\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-27-06\n",
      "  done: false\n",
      "  episode_len_mean: 176.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 176.08\n",
      "  episode_reward_min: 95.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 4471\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5977701.5\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.018849506974220276\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03997514769434929\n",
      "          model: {}\n",
      "          policy_loss: 0.0033460764680057764\n",
      "          total_loss: 239158.421875\n",
      "          vf_explained_var: 0.7054405212402344\n",
      "          vf_loss: 198.89663696289062\n",
      "    num_agent_steps_sampled: 679830\n",
      "    num_agent_steps_trained: 679830\n",
      "    num_steps_sampled: 679830\n",
      "    num_steps_trained: 679830\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.55714285714285\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09032894889204926\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0914196049943759\n",
      "    mean_inference_ms: 1.0002243783886575\n",
      "    mean_raw_obs_processing_ms: 0.11892531591712899\n",
      "  time_since_restore: 829.0201098918915\n",
      "  time_this_iter_s: 9.471279621124268\n",
      "  time_total_s: 829.0201098918915\n",
      "  timers:\n",
      "    learn_throughput: 1278.404\n",
      "    learn_time_ms: 6256.238\n",
      "    load_throughput: 24568656.359\n",
      "    load_time_ms: 0.326\n",
      "    sample_throughput: 810.855\n",
      "    sample_time_ms: 9863.661\n",
      "    update_time_ms: 3.018\n",
      "  timestamp: 1645201626\n",
      "  timesteps_since_restore: 679830\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 679830\n",
      "  training_iteration: 85\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:27:09 (running for 00:14:05.63)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">          829.02</td><td style=\"text-align: right;\">679830</td><td style=\"text-align: right;\">  176.08</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  95</td><td style=\"text-align: right;\">            176.08</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:27:14 (running for 00:14:10.65)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">          829.02</td><td style=\"text-align: right;\">679830</td><td style=\"text-align: right;\">  176.08</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  95</td><td style=\"text-align: right;\">            176.08</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 687828\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-27-15\n",
      "  done: false\n",
      "  episode_len_mean: 172.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 172.4\n",
      "  episode_reward_min: 92.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 4516\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8966552.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015572546981275082\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.035262372344732285\n",
      "          model: {}\n",
      "          policy_loss: 0.062292009592056274\n",
      "          total_loss: 316448.75\n",
      "          vf_explained_var: 0.6954411268234253\n",
      "          vf_loss: 266.78271484375\n",
      "    num_agent_steps_sampled: 687828\n",
      "    num_agent_steps_trained: 687828\n",
      "    num_steps_sampled: 687828\n",
      "    num_steps_trained: 687828\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.91428571428571\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09032442337396622\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09138369453792468\n",
      "    mean_inference_ms: 1.000162412103657\n",
      "    mean_raw_obs_processing_ms: 0.11894090842202672\n",
      "  time_since_restore: 838.6570181846619\n",
      "  time_this_iter_s: 9.636908292770386\n",
      "  time_total_s: 838.6570181846619\n",
      "  timers:\n",
      "    learn_throughput: 1282.961\n",
      "    learn_time_ms: 6234.016\n",
      "    load_throughput: 24770023.918\n",
      "    load_time_ms: 0.323\n",
      "    sample_throughput: 814.533\n",
      "    sample_time_ms: 9819.127\n",
      "    update_time_ms: 2.992\n",
      "  timestamp: 1645201635\n",
      "  timesteps_since_restore: 687828\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 687828\n",
      "  training_iteration: 86\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:27:19 (running for 00:14:16.28)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         838.657</td><td style=\"text-align: right;\">687828</td><td style=\"text-align: right;\">   172.4</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">             172.4</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:27:24 (running for 00:14:21.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         838.657</td><td style=\"text-align: right;\">687828</td><td style=\"text-align: right;\">   172.4</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">             172.4</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 695826\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-27-25\n",
      "  done: false\n",
      "  episode_len_mean: 178.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 178.7\n",
      "  episode_reward_min: 84.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 4558\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 13449829.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.016379328444600105\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.035057488828897476\n",
      "          model: {}\n",
      "          policy_loss: 0.014942247420549393\n",
      "          total_loss: 471731.75\n",
      "          vf_explained_var: 0.7189261317253113\n",
      "          vf_loss: 214.45413208007812\n",
      "    num_agent_steps_sampled: 695826\n",
      "    num_agent_steps_trained: 695826\n",
      "    num_steps_sampled: 695826\n",
      "    num_steps_trained: 695826\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.0153846153846\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09031931710436822\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09134209813625682\n",
      "    mean_inference_ms: 1.0004661526937175\n",
      "    mean_raw_obs_processing_ms: 0.1190017249233475\n",
      "  time_since_restore: 848.230774641037\n",
      "  time_this_iter_s: 9.573756456375122\n",
      "  time_total_s: 848.230774641037\n",
      "  timers:\n",
      "    learn_throughput: 1285.468\n",
      "    learn_time_ms: 6221.86\n",
      "    load_throughput: 24782833.475\n",
      "    load_time_ms: 0.323\n",
      "    sample_throughput: 816.537\n",
      "    sample_time_ms: 9795.026\n",
      "    update_time_ms: 2.931\n",
      "  timestamp: 1645201645\n",
      "  timesteps_since_restore: 695826\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 695826\n",
      "  training_iteration: 87\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:27:30 (running for 00:14:26.88)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         848.231</td><td style=\"text-align: right;\">695826</td><td style=\"text-align: right;\">   178.7</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  84</td><td style=\"text-align: right;\">             178.7</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 703824\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-27-34\n",
      "  done: false\n",
      "  episode_len_mean: 180.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 180.2\n",
      "  episode_reward_min: 82.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 4604\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 20174742.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.016136789694428444\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02838767133653164\n",
      "          model: {}\n",
      "          policy_loss: 0.011051194742321968\n",
      "          total_loss: 572964.375\n",
      "          vf_explained_var: 0.641631007194519\n",
      "          vf_loss: 250.49288940429688\n",
      "    num_agent_steps_sampled: 703824\n",
      "    num_agent_steps_trained: 703824\n",
      "    num_steps_sampled: 703824\n",
      "    num_steps_trained: 703824\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.9357142857143\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09033266208244636\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09136271105448802\n",
      "    mean_inference_ms: 1.0001369305851082\n",
      "    mean_raw_obs_processing_ms: 0.11892898863613163\n",
      "  time_since_restore: 857.8470439910889\n",
      "  time_this_iter_s: 9.61626935005188\n",
      "  time_total_s: 857.8470439910889\n",
      "  timers:\n",
      "    learn_throughput: 1290.822\n",
      "    learn_time_ms: 6196.053\n",
      "    load_throughput: 24649895.945\n",
      "    load_time_ms: 0.324\n",
      "    sample_throughput: 817.108\n",
      "    sample_time_ms: 9788.185\n",
      "    update_time_ms: 2.896\n",
      "  timestamp: 1645201654\n",
      "  timesteps_since_restore: 703824\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 703824\n",
      "  training_iteration: 88\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:27:35 (running for 00:14:32.48)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         857.847</td><td style=\"text-align: right;\">703824</td><td style=\"text-align: right;\">   180.2</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">             180.2</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:27:41 (running for 00:14:37.54)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         857.847</td><td style=\"text-align: right;\">703824</td><td style=\"text-align: right;\">   180.2</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">             180.2</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 711822\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-27-44\n",
      "  done: false\n",
      "  episode_len_mean: 179.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 179.92\n",
      "  episode_reward_min: 82.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 4649\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 30262114.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015072358772158623\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.034289922565221786\n",
      "          model: {}\n",
      "          policy_loss: 0.010392429307103157\n",
      "          total_loss: 1037933.125\n",
      "          vf_explained_var: 0.6202378273010254\n",
      "          vf_loss: 247.5883026123047\n",
      "    num_agent_steps_sampled: 711822\n",
      "    num_agent_steps_trained: 711822\n",
      "    num_steps_sampled: 711822\n",
      "    num_steps_trained: 711822\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.03571428571429\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0903519165122897\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09138681880884912\n",
      "    mean_inference_ms: 1.0001023855689635\n",
      "    mean_raw_obs_processing_ms: 0.11890748656386725\n",
      "  time_since_restore: 867.6215968132019\n",
      "  time_this_iter_s: 9.774552822113037\n",
      "  time_total_s: 867.6215968132019\n",
      "  timers:\n",
      "    learn_throughput: 1294.724\n",
      "    learn_time_ms: 6177.38\n",
      "    load_throughput: 24731674.574\n",
      "    load_time_ms: 0.323\n",
      "    sample_throughput: 819.081\n",
      "    sample_time_ms: 9764.601\n",
      "    update_time_ms: 2.801\n",
      "  timestamp: 1645201664\n",
      "  timesteps_since_restore: 711822\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 711822\n",
      "  training_iteration: 89\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:27:46 (running for 00:14:43.28)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         867.622</td><td style=\"text-align: right;\">711822</td><td style=\"text-align: right;\">  179.92</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            179.92</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:27:51 (running for 00:14:48.33)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         867.622</td><td style=\"text-align: right;\">711822</td><td style=\"text-align: right;\">  179.92</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            179.92</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 719820\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-27-54\n",
      "  done: false\n",
      "  episode_len_mean: 175.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.42\n",
      "  episode_reward_min: 82.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 4696\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 45393172.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.017005939036607742\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03598577156662941\n",
      "          model: {}\n",
      "          policy_loss: 0.006174434442073107\n",
      "          total_loss: 1633780.0\n",
      "          vf_explained_var: 0.6789669990539551\n",
      "          vf_loss: 271.77667236328125\n",
      "    num_agent_steps_sampled: 719820\n",
      "    num_agent_steps_trained: 719820\n",
      "    num_steps_sampled: 719820\n",
      "    num_steps_trained: 719820\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.30714285714285\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0903582735061162\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09137633050040908\n",
      "    mean_inference_ms: 0.9999427514134623\n",
      "    mean_raw_obs_processing_ms: 0.1189060431920705\n",
      "  time_since_restore: 877.3389768600464\n",
      "  time_this_iter_s: 9.717380046844482\n",
      "  time_total_s: 877.3389768600464\n",
      "  timers:\n",
      "    learn_throughput: 1299.37\n",
      "    learn_time_ms: 6155.289\n",
      "    load_throughput: 25411744.104\n",
      "    load_time_ms: 0.315\n",
      "    sample_throughput: 820.788\n",
      "    sample_time_ms: 9744.298\n",
      "    update_time_ms: 2.824\n",
      "  timestamp: 1645201674\n",
      "  timesteps_since_restore: 719820\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 719820\n",
      "  training_iteration: 90\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:27:57 (running for 00:14:54.02)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         877.339</td><td style=\"text-align: right;\">719820</td><td style=\"text-align: right;\">  175.42</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            175.42</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:28:02 (running for 00:14:59.08)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         877.339</td><td style=\"text-align: right;\">719820</td><td style=\"text-align: right;\">  175.42</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            175.42</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 727818\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-28-04\n",
      "  done: false\n",
      "  episode_len_mean: 175.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.74\n",
      "  episode_reward_min: 82.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 4739\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 68089760.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015359561890363693\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024026723578572273\n",
      "          model: {}\n",
      "          policy_loss: -0.004799428395926952\n",
      "          total_loss: 1636256.75\n",
      "          vf_explained_var: 0.6107749342918396\n",
      "          vf_loss: 282.9231262207031\n",
      "    num_agent_steps_sampled: 727818\n",
      "    num_agent_steps_trained: 727818\n",
      "    num_steps_sampled: 727818\n",
      "    num_steps_trained: 727818\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.68571428571428\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09035568260873802\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09138596034488129\n",
      "    mean_inference_ms: 0.9999796426967364\n",
      "    mean_raw_obs_processing_ms: 0.11886715189564376\n",
      "  time_since_restore: 886.9467751979828\n",
      "  time_this_iter_s: 9.607798337936401\n",
      "  time_total_s: 886.9467751979828\n",
      "  timers:\n",
      "    learn_throughput: 1300.863\n",
      "    learn_time_ms: 6148.228\n",
      "    load_throughput: 26146565.387\n",
      "    load_time_ms: 0.306\n",
      "    sample_throughput: 821.91\n",
      "    sample_time_ms: 9730.99\n",
      "    update_time_ms: 2.854\n",
      "  timestamp: 1645201684\n",
      "  timesteps_since_restore: 727818\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 727818\n",
      "  training_iteration: 91\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:28:08 (running for 00:15:04.66)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         886.947</td><td style=\"text-align: right;\">727818</td><td style=\"text-align: right;\">  175.74</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            175.74</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:28:13 (running for 00:15:09.72)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         886.947</td><td style=\"text-align: right;\">727818</td><td style=\"text-align: right;\">  175.74</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            175.74</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 735816\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-28-13\n",
      "  done: false\n",
      "  episode_len_mean: 178.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 178.89\n",
      "  episode_reward_min: 82.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 4786\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 102134632.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015480014495551586\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.034655649214982986\n",
      "          model: {}\n",
      "          policy_loss: 0.013635833747684956\n",
      "          total_loss: 3539801.5\n",
      "          vf_explained_var: 0.6412198543548584\n",
      "          vf_loss: 259.53814697265625\n",
      "    num_agent_steps_sampled: 735816\n",
      "    num_agent_steps_trained: 735816\n",
      "    num_steps_sampled: 735816\n",
      "    num_steps_trained: 735816\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.3923076923077\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09035172158681369\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09139172005191541\n",
      "    mean_inference_ms: 0.9999749100030882\n",
      "    mean_raw_obs_processing_ms: 0.1188292044011553\n",
      "  time_since_restore: 896.4747288227081\n",
      "  time_this_iter_s: 9.527953624725342\n",
      "  time_total_s: 896.4747288227081\n",
      "  timers:\n",
      "    learn_throughput: 1310.892\n",
      "    learn_time_ms: 6101.188\n",
      "    load_throughput: 25906281.097\n",
      "    load_time_ms: 0.309\n",
      "    sample_throughput: 822.291\n",
      "    sample_time_ms: 9726.48\n",
      "    update_time_ms: 2.721\n",
      "  timestamp: 1645201693\n",
      "  timesteps_since_restore: 735816\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 735816\n",
      "  training_iteration: 92\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:28:18 (running for 00:15:15.22)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         896.475</td><td style=\"text-align: right;\">735816</td><td style=\"text-align: right;\">  178.89</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            178.89</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 743814\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-28-23\n",
      "  done: false\n",
      "  episode_len_mean: 175.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.61\n",
      "  episode_reward_min: 83.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 4831\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 153201952.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.016739631071686745\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03533244878053665\n",
      "          model: {}\n",
      "          policy_loss: 0.007582902442663908\n",
      "          total_loss: 5413278.0\n",
      "          vf_explained_var: 0.6169330477714539\n",
      "          vf_loss: 278.5379333496094\n",
      "    num_agent_steps_sampled: 743814\n",
      "    num_agent_steps_trained: 743814\n",
      "    num_steps_sampled: 743814\n",
      "    num_steps_trained: 743814\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.46428571428571\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09034870026691269\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09138944786035577\n",
      "    mean_inference_ms: 0.9995963496950816\n",
      "    mean_raw_obs_processing_ms: 0.1187809218329961\n",
      "  time_since_restore: 906.0224719047546\n",
      "  time_this_iter_s: 9.547743082046509\n",
      "  time_total_s: 906.0224719047546\n",
      "  timers:\n",
      "    learn_throughput: 1316.886\n",
      "    learn_time_ms: 6073.419\n",
      "    load_throughput: 25201745.468\n",
      "    load_time_ms: 0.317\n",
      "    sample_throughput: 826.35\n",
      "    sample_time_ms: 9678.712\n",
      "    update_time_ms: 2.673\n",
      "  timestamp: 1645201703\n",
      "  timesteps_since_restore: 743814\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 743814\n",
      "  training_iteration: 93\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:28:24 (running for 00:15:20.82)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         906.022</td><td style=\"text-align: right;\">743814</td><td style=\"text-align: right;\">  175.61</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            175.61</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:28:29 (running for 00:15:25.84)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         906.022</td><td style=\"text-align: right;\">743814</td><td style=\"text-align: right;\">  175.61</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            175.61</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 751812\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-28-32\n",
      "  done: false\n",
      "  episode_len_mean: 178.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 178.67\n",
      "  episode_reward_min: 89.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 4874\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 229802928.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015067513100802898\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021531853824853897\n",
      "          model: {}\n",
      "          policy_loss: 0.009540822356939316\n",
      "          total_loss: 4948364.0\n",
      "          vf_explained_var: 0.620751678943634\n",
      "          vf_loss: 280.77716064453125\n",
      "    num_agent_steps_sampled: 751812\n",
      "    num_agent_steps_trained: 751812\n",
      "    num_steps_sampled: 751812\n",
      "    num_steps_trained: 751812\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.79285714285713\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09033115205665682\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09136075060401838\n",
      "    mean_inference_ms: 1.0000515048737875\n",
      "    mean_raw_obs_processing_ms: 0.11883363973204517\n",
      "  time_since_restore: 915.71120429039\n",
      "  time_this_iter_s: 9.688732385635376\n",
      "  time_total_s: 915.71120429039\n",
      "  timers:\n",
      "    learn_throughput: 1317.875\n",
      "    learn_time_ms: 6068.859\n",
      "    load_throughput: 24982159.214\n",
      "    load_time_ms: 0.32\n",
      "    sample_throughput: 829.186\n",
      "    sample_time_ms: 9645.601\n",
      "    update_time_ms: 2.635\n",
      "  timestamp: 1645201712\n",
      "  timesteps_since_restore: 751812\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 751812\n",
      "  training_iteration: 94\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:28:35 (running for 00:15:31.55)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         915.711</td><td style=\"text-align: right;\">751812</td><td style=\"text-align: right;\">  178.67</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            178.67</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:28:40 (running for 00:15:36.57)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         915.711</td><td style=\"text-align: right;\">751812</td><td style=\"text-align: right;\">  178.67</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            178.67</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 759810\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-28-42\n",
      "  done: false\n",
      "  episode_len_mean: 180.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 180.86\n",
      "  episode_reward_min: 86.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 4919\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 344704384.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.019704725593328476\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0517522431910038\n",
      "          model: {}\n",
      "          policy_loss: 0.010383008979260921\n",
      "          total_loss: 17839504.0\n",
      "          vf_explained_var: 0.6285430788993835\n",
      "          vf_loss: 278.7911682128906\n",
      "    num_agent_steps_sampled: 759810\n",
      "    num_agent_steps_trained: 759810\n",
      "    num_steps_sampled: 759810\n",
      "    num_steps_trained: 759810\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.38571428571429\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09032863375921373\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09136366858733914\n",
      "    mean_inference_ms: 1.000221984781989\n",
      "    mean_raw_obs_processing_ms: 0.11883143036620272\n",
      "  time_since_restore: 925.4364035129547\n",
      "  time_this_iter_s: 9.725199222564697\n",
      "  time_total_s: 925.4364035129547\n",
      "  timers:\n",
      "    learn_throughput: 1314.634\n",
      "    learn_time_ms: 6083.822\n",
      "    load_throughput: 23412928.107\n",
      "    load_time_ms: 0.342\n",
      "    sample_throughput: 828.704\n",
      "    sample_time_ms: 9651.211\n",
      "    update_time_ms: 2.627\n",
      "  timestamp: 1645201722\n",
      "  timesteps_since_restore: 759810\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 759810\n",
      "  training_iteration: 95\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:28:45 (running for 00:15:42.29)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         925.436</td><td style=\"text-align: right;\">759810</td><td style=\"text-align: right;\">  180.86</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            180.86</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:28:50 (running for 00:15:47.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         925.436</td><td style=\"text-align: right;\">759810</td><td style=\"text-align: right;\">  180.86</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            180.86</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 767808\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-28-52\n",
      "  done: false\n",
      "  episode_len_mean: 180.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 180.76\n",
      "  episode_reward_min: 86.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 4964\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 517056576.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.0192567165941\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03270900249481201\n",
      "          model: {}\n",
      "          policy_loss: 0.002466714009642601\n",
      "          total_loss: 16912686.0\n",
      "          vf_explained_var: 0.540783166885376\n",
      "          vf_loss: 279.6125793457031\n",
      "    num_agent_steps_sampled: 767808\n",
      "    num_agent_steps_trained: 767808\n",
      "    num_steps_sampled: 767808\n",
      "    num_steps_trained: 767808\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.89230769230768\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09033260750827304\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09138137764975285\n",
      "    mean_inference_ms: 1.0001520703005835\n",
      "    mean_raw_obs_processing_ms: 0.11879693969302572\n",
      "  time_since_restore: 934.9651188850403\n",
      "  time_this_iter_s: 9.528715372085571\n",
      "  time_total_s: 934.9651188850403\n",
      "  timers:\n",
      "    learn_throughput: 1315.614\n",
      "    learn_time_ms: 6079.292\n",
      "    load_throughput: 23365635.852\n",
      "    load_time_ms: 0.342\n",
      "    sample_throughput: 827.945\n",
      "    sample_time_ms: 9660.063\n",
      "    update_time_ms: 2.734\n",
      "  timestamp: 1645201732\n",
      "  timesteps_since_restore: 767808\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 767808\n",
      "  training_iteration: 96\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:28:56 (running for 00:15:52.84)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         934.965</td><td style=\"text-align: right;\">767808</td><td style=\"text-align: right;\">  180.76</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            180.76</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:29:01 (running for 00:15:57.86)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         934.965</td><td style=\"text-align: right;\">767808</td><td style=\"text-align: right;\">  180.76</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            180.76</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 775806\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-29-01\n",
      "  done: false\n",
      "  episode_len_mean: 177.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 177.0\n",
      "  episode_reward_min: 89.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 5011\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 775584896.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.018412386998534203\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03816717490553856\n",
      "          model: {}\n",
      "          policy_loss: 0.008891875855624676\n",
      "          total_loss: 29602126.0\n",
      "          vf_explained_var: 0.6485508680343628\n",
      "          vf_loss: 243.449951171875\n",
      "    num_agent_steps_sampled: 775806\n",
      "    num_agent_steps_trained: 775806\n",
      "    num_steps_sampled: 775806\n",
      "    num_steps_trained: 775806\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.55714285714285\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09032425213073657\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09135938205432151\n",
      "    mean_inference_ms: 0.999362327523541\n",
      "    mean_raw_obs_processing_ms: 0.11873666039520052\n",
      "  time_since_restore: 944.567298412323\n",
      "  time_this_iter_s: 9.602179527282715\n",
      "  time_total_s: 944.567298412323\n",
      "  timers:\n",
      "    learn_throughput: 1314.558\n",
      "    learn_time_ms: 6084.174\n",
      "    load_throughput: 23432553.361\n",
      "    load_time_ms: 0.341\n",
      "    sample_throughput: 828.516\n",
      "    sample_time_ms: 9653.409\n",
      "    update_time_ms: 2.766\n",
      "  timestamp: 1645201741\n",
      "  timesteps_since_restore: 775806\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 775806\n",
      "  training_iteration: 97\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:29:06 (running for 00:16:03.47)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         944.567</td><td style=\"text-align: right;\">775806</td><td style=\"text-align: right;\">     177</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">               177</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 783804\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-29-11\n",
      "  done: false\n",
      "  episode_len_mean: 170.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 170.75\n",
      "  episode_reward_min: 75.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 5057\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1163377280.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01670977845788002\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.038859352469444275\n",
      "          model: {}\n",
      "          policy_loss: 0.013450484722852707\n",
      "          total_loss: 45208292.0\n",
      "          vf_explained_var: 0.7009167075157166\n",
      "          vf_loss: 208.15846252441406\n",
      "    num_agent_steps_sampled: 783804\n",
      "    num_agent_steps_trained: 783804\n",
      "    num_steps_sampled: 783804\n",
      "    num_steps_trained: 783804\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.47142857142858\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09031680317404404\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09136118120105412\n",
      "    mean_inference_ms: 0.9991241358213117\n",
      "    mean_raw_obs_processing_ms: 0.11868793973465244\n",
      "  time_since_restore: 954.452329158783\n",
      "  time_this_iter_s: 9.885030746459961\n",
      "  time_total_s: 954.452329158783\n",
      "  timers:\n",
      "    learn_throughput: 1308.475\n",
      "    learn_time_ms: 6112.461\n",
      "    load_throughput: 23811785.486\n",
      "    load_time_ms: 0.336\n",
      "    sample_throughput: 828.215\n",
      "    sample_time_ms: 9656.916\n",
      "    update_time_ms: 2.84\n",
      "  timestamp: 1645201751\n",
      "  timesteps_since_restore: 783804\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 783804\n",
      "  training_iteration: 98\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:29:12 (running for 00:16:09.34)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         954.452</td><td style=\"text-align: right;\">783804</td><td style=\"text-align: right;\">  170.75</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  75</td><td style=\"text-align: right;\">            170.75</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:29:17 (running for 00:16:14.41)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         954.452</td><td style=\"text-align: right;\">783804</td><td style=\"text-align: right;\">  170.75</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  75</td><td style=\"text-align: right;\">            170.75</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 791802\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-29-21\n",
      "  done: false\n",
      "  episode_len_mean: 174.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 174.25\n",
      "  episode_reward_min: 75.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 5103\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1745065984.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01817074976861477\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.036087650805711746\n",
      "          model: {}\n",
      "          policy_loss: 0.008245465345680714\n",
      "          total_loss: 62975640.0\n",
      "          vf_explained_var: 0.5662992596626282\n",
      "          vf_loss: 310.2822570800781\n",
      "    num_agent_steps_sampled: 791802\n",
      "    num_agent_steps_trained: 791802\n",
      "    num_steps_sampled: 791802\n",
      "    num_steps_trained: 791802\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.43571428571428\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09030767700828651\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09134430670250476\n",
      "    mean_inference_ms: 0.9991382438039352\n",
      "    mean_raw_obs_processing_ms: 0.11869786119633162\n",
      "  time_since_restore: 964.023101568222\n",
      "  time_this_iter_s: 9.570772409439087\n",
      "  time_total_s: 964.023101568222\n",
      "  timers:\n",
      "    learn_throughput: 1312.514\n",
      "    learn_time_ms: 6093.649\n",
      "    load_throughput: 23876187.468\n",
      "    load_time_ms: 0.335\n",
      "    sample_throughput: 825.907\n",
      "    sample_time_ms: 9683.894\n",
      "    update_time_ms: 2.821\n",
      "  timestamp: 1645201761\n",
      "  timesteps_since_restore: 791802\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 791802\n",
      "  training_iteration: 99\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:29:23 (running for 00:16:19.93)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         964.023</td><td style=\"text-align: right;\">791802</td><td style=\"text-align: right;\">  174.25</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  75</td><td style=\"text-align: right;\">            174.25</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:29:28 (running for 00:16:24.98)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         964.023</td><td style=\"text-align: right;\">791802</td><td style=\"text-align: right;\">  174.25</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  75</td><td style=\"text-align: right;\">            174.25</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 799800\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-29-30\n",
      "  done: false\n",
      "  episode_len_mean: 176.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 176.91\n",
      "  episode_reward_min: 81.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 5147\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2617598976.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.017206257209181786\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030296584591269493\n",
      "          model: {}\n",
      "          policy_loss: 0.00477088475599885\n",
      "          total_loss: 79304568.0\n",
      "          vf_explained_var: 0.6168866157531738\n",
      "          vf_loss: 257.26800537109375\n",
      "    num_agent_steps_sampled: 799800\n",
      "    num_agent_steps_trained: 799800\n",
      "    num_steps_sampled: 799800\n",
      "    num_steps_trained: 799800\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.76153846153846\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.090292424145705\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09131939922318943\n",
      "    mean_inference_ms: 0.9991076046727997\n",
      "    mean_raw_obs_processing_ms: 0.11871081966181503\n",
      "  time_since_restore: 973.5221245288849\n",
      "  time_this_iter_s: 9.499022960662842\n",
      "  time_total_s: 973.5221245288849\n",
      "  timers:\n",
      "    learn_throughput: 1315.988\n",
      "    learn_time_ms: 6077.562\n",
      "    load_throughput: 23079493.218\n",
      "    load_time_ms: 0.347\n",
      "    sample_throughput: 828.003\n",
      "    sample_time_ms: 9659.381\n",
      "    update_time_ms: 2.798\n",
      "  timestamp: 1645201770\n",
      "  timesteps_since_restore: 799800\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 799800\n",
      "  training_iteration: 100\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:29:33 (running for 00:16:30.46)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         973.522</td><td style=\"text-align: right;\">799800</td><td style=\"text-align: right;\">  176.91</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  81</td><td style=\"text-align: right;\">            176.91</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:29:38 (running for 00:16:35.51)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         973.522</td><td style=\"text-align: right;\">799800</td><td style=\"text-align: right;\">  176.91</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  81</td><td style=\"text-align: right;\">            176.91</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 807798\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-29-40\n",
      "  done: false\n",
      "  episode_len_mean: 172.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 172.02\n",
      "  episode_reward_min: 82.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 5196\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3926398464.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015534854494035244\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.037979044020175934\n",
      "          model: {}\n",
      "          policy_loss: 0.006346900016069412\n",
      "          total_loss: 149121072.0\n",
      "          vf_explained_var: 0.663542628288269\n",
      "          vf_loss: 223.0501251220703\n",
      "    num_agent_steps_sampled: 807798\n",
      "    num_agent_steps_trained: 807798\n",
      "    num_steps_sampled: 807798\n",
      "    num_steps_trained: 807798\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.70714285714287\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09028998238512957\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09133175297051256\n",
      "    mean_inference_ms: 0.9990794335375139\n",
      "    mean_raw_obs_processing_ms: 0.11870017429408046\n",
      "  time_since_restore: 983.3554000854492\n",
      "  time_this_iter_s: 9.833275556564331\n",
      "  time_total_s: 983.3554000854492\n",
      "  timers:\n",
      "    learn_throughput: 1311.593\n",
      "    learn_time_ms: 6097.927\n",
      "    load_throughput: 22931193.788\n",
      "    load_time_ms: 0.349\n",
      "    sample_throughput: 829.169\n",
      "    sample_time_ms: 9645.806\n",
      "    update_time_ms: 2.741\n",
      "  timestamp: 1645201780\n",
      "  timesteps_since_restore: 807798\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 807798\n",
      "  training_iteration: 101\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:29:44 (running for 00:16:41.33)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         983.355</td><td style=\"text-align: right;\">807798</td><td style=\"text-align: right;\">  172.02</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            172.02</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:29:49 (running for 00:16:46.38)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         983.355</td><td style=\"text-align: right;\">807798</td><td style=\"text-align: right;\">  172.02</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            172.02</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 815796\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-29-50\n",
      "  done: false\n",
      "  episode_len_mean: 169.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 169.52\n",
      "  episode_reward_min: 84.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 5243\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5889597952.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.017362983897328377\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04731199890375137\n",
      "          model: {}\n",
      "          policy_loss: 0.005953929387032986\n",
      "          total_loss: 278648960.0\n",
      "          vf_explained_var: 0.5877343416213989\n",
      "          vf_loss: 297.5069885253906\n",
      "    num_agent_steps_sampled: 815796\n",
      "    num_agent_steps_trained: 815796\n",
      "    num_steps_sampled: 815796\n",
      "    num_steps_trained: 815796\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.40666666666667\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09030063990360018\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09134561818905394\n",
      "    mean_inference_ms: 0.9987274010722241\n",
      "    mean_raw_obs_processing_ms: 0.11867177117339381\n",
      "  time_since_restore: 993.2258610725403\n",
      "  time_this_iter_s: 9.870460987091064\n",
      "  time_total_s: 993.2258610725403\n",
      "  timers:\n",
      "    learn_throughput: 1304.178\n",
      "    learn_time_ms: 6132.597\n",
      "    load_throughput: 23195991.835\n",
      "    load_time_ms: 0.345\n",
      "    sample_throughput: 827.517\n",
      "    sample_time_ms: 9665.057\n",
      "    update_time_ms: 2.844\n",
      "  timestamp: 1645201790\n",
      "  timesteps_since_restore: 815796\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 815796\n",
      "  training_iteration: 102\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:29:55 (running for 00:16:52.22)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         993.226</td><td style=\"text-align: right;\">815796</td><td style=\"text-align: right;\">  169.52</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  84</td><td style=\"text-align: right;\">            169.52</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 823794\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-30-00\n",
      "  done: false\n",
      "  episode_len_mean: 174.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 174.14\n",
      "  episode_reward_min: 86.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 5288\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8834396160.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.017300976440310478\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030447224155068398\n",
      "          model: {}\n",
      "          policy_loss: 0.006139153148978949\n",
      "          total_loss: 268983136.0\n",
      "          vf_explained_var: 0.6175438761711121\n",
      "          vf_loss: 281.6767883300781\n",
      "    num_agent_steps_sampled: 823794\n",
      "    num_agent_steps_trained: 823794\n",
      "    num_steps_sampled: 823794\n",
      "    num_steps_trained: 823794\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.55\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09031237134902756\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09132986826630503\n",
      "    mean_inference_ms: 0.9989427345720259\n",
      "    mean_raw_obs_processing_ms: 0.11872379300911767\n",
      "  time_since_restore: 1003.0913443565369\n",
      "  time_this_iter_s: 9.865483283996582\n",
      "  time_total_s: 1003.0913443565369\n",
      "  timers:\n",
      "    learn_throughput: 1297.93\n",
      "    learn_time_ms: 6162.12\n",
      "    load_throughput: 24000889.599\n",
      "    load_time_ms: 0.333\n",
      "    sample_throughput: 824.369\n",
      "    sample_time_ms: 9701.971\n",
      "    update_time_ms: 2.879\n",
      "  timestamp: 1645201800\n",
      "  timesteps_since_restore: 823794\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 823794\n",
      "  training_iteration: 103\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:30:01 (running for 00:16:58.10)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         1003.09</td><td style=\"text-align: right;\">823794</td><td style=\"text-align: right;\">  174.14</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            174.14</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:30:06 (running for 00:17:03.12)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         1003.09</td><td style=\"text-align: right;\">823794</td><td style=\"text-align: right;\">  174.14</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            174.14</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 831792\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-30-10\n",
      "  done: false\n",
      "  episode_len_mean: 171.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 171.86\n",
      "  episode_reward_min: 78.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 5335\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 13251595264.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.012773887254297733\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03066391497850418\n",
      "          model: {}\n",
      "          policy_loss: 0.018102293834090233\n",
      "          total_loss: 406346016.0\n",
      "          vf_explained_var: 0.7224076390266418\n",
      "          vf_loss: 213.92855834960938\n",
      "    num_agent_steps_sampled: 831792\n",
      "    num_agent_steps_trained: 831792\n",
      "    num_steps_sampled: 831792\n",
      "    num_steps_trained: 831792\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.65714285714286\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09033648596834248\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09132182957395418\n",
      "    mean_inference_ms: 0.9991103608041629\n",
      "    mean_raw_obs_processing_ms: 0.11878091096645342\n",
      "  time_since_restore: 1013.2868444919586\n",
      "  time_this_iter_s: 10.195500135421753\n",
      "  time_total_s: 1013.2868444919586\n",
      "  timers:\n",
      "    learn_throughput: 1292.599\n",
      "    learn_time_ms: 6187.533\n",
      "    load_throughput: 24301683.13\n",
      "    load_time_ms: 0.329\n",
      "    sample_throughput: 819.686\n",
      "    sample_time_ms: 9757.4\n",
      "    update_time_ms: 2.842\n",
      "  timestamp: 1645201810\n",
      "  timesteps_since_restore: 831792\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 831792\n",
      "  training_iteration: 104\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:30:11 (running for 00:17:08.32)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1013.29</td><td style=\"text-align: right;\">831792</td><td style=\"text-align: right;\">  171.86</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            171.86</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:30:16 (running for 00:17:13.35)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1013.29</td><td style=\"text-align: right;\">831792</td><td style=\"text-align: right;\">  171.86</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            171.86</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:30:21 (running for 00:17:18.42)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1013.29</td><td style=\"text-align: right;\">831792</td><td style=\"text-align: right;\">  171.86</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            171.86</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 839790\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-30-22\n",
      "  done: false\n",
      "  episode_len_mean: 167.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 167.53\n",
      "  episode_reward_min: 78.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 5383\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 19877392384.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.014623143710196018\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02144324965775013\n",
      "          model: {}\n",
      "          policy_loss: 0.00421122694388032\n",
      "          total_loss: 426236128.0\n",
      "          vf_explained_var: 0.6993339657783508\n",
      "          vf_loss: 218.77320861816406\n",
      "    num_agent_steps_sampled: 839790\n",
      "    num_agent_steps_trained: 839790\n",
      "    num_steps_sampled: 839790\n",
      "    num_steps_trained: 839790\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.6125\n",
      "    ram_util_percent: 17.8\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09054181291204477\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09152425397635172\n",
      "    mean_inference_ms: 1.000939271720418\n",
      "    mean_raw_obs_processing_ms: 0.11898318780747219\n",
      "  time_since_restore: 1024.5779430866241\n",
      "  time_this_iter_s: 11.291098594665527\n",
      "  time_total_s: 1024.5779430866241\n",
      "  timers:\n",
      "    learn_throughput: 1289.005\n",
      "    learn_time_ms: 6204.788\n",
      "    load_throughput: 26057203.194\n",
      "    load_time_ms: 0.307\n",
      "    sample_throughput: 806.076\n",
      "    sample_time_ms: 9922.142\n",
      "    update_time_ms: 2.885\n",
      "  timestamp: 1645201822\n",
      "  timesteps_since_restore: 839790\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 839790\n",
      "  training_iteration: 105\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:30:27 (running for 00:17:23.65)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1024.58</td><td style=\"text-align: right;\">839790</td><td style=\"text-align: right;\">  167.53</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            167.53</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 847788\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-30-31\n",
      "  done: false\n",
      "  episode_len_mean: 167.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 167.73\n",
      "  episode_reward_min: 75.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 5431\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 29816088576.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.017910093069076538\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04431944712996483\n",
      "          model: {}\n",
      "          policy_loss: 0.010942744091153145\n",
      "          total_loss: 1321432832.0\n",
      "          vf_explained_var: 0.7199295163154602\n",
      "          vf_loss: 206.4915313720703\n",
      "    num_agent_steps_sampled: 847788\n",
      "    num_agent_steps_trained: 847788\n",
      "    num_steps_sampled: 847788\n",
      "    num_steps_trained: 847788\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.67857142857143\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09072156156205892\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09170499889582517\n",
      "    mean_inference_ms: 1.0024718242546578\n",
      "    mean_raw_obs_processing_ms: 0.11916135645624307\n",
      "  time_since_restore: 1034.175420999527\n",
      "  time_this_iter_s: 9.597477912902832\n",
      "  time_total_s: 1034.175420999527\n",
      "  timers:\n",
      "    learn_throughput: 1286.132\n",
      "    learn_time_ms: 6218.648\n",
      "    load_throughput: 25549157.191\n",
      "    load_time_ms: 0.313\n",
      "    sample_throughput: 805.259\n",
      "    sample_time_ms: 9932.211\n",
      "    update_time_ms: 2.77\n",
      "  timestamp: 1645201831\n",
      "  timesteps_since_restore: 847788\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 847788\n",
      "  training_iteration: 106\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:30:32 (running for 00:17:29.26)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1034.18</td><td style=\"text-align: right;\">847788</td><td style=\"text-align: right;\">  167.73</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  75</td><td style=\"text-align: right;\">            167.73</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:30:37 (running for 00:17:34.28)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1034.18</td><td style=\"text-align: right;\">847788</td><td style=\"text-align: right;\">  167.73</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  75</td><td style=\"text-align: right;\">            167.73</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 855786\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-30-41\n",
      "  done: false\n",
      "  episode_len_mean: 173.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 173.8\n",
      "  episode_reward_min: 75.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 5476\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 44724133888.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01881362684071064\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026799630373716354\n",
      "          model: {}\n",
      "          policy_loss: 0.012687703594565392\n",
      "          total_loss: 1198590592.0\n",
      "          vf_explained_var: 0.7563487887382507\n",
      "          vf_loss: 202.57102966308594\n",
      "    num_agent_steps_sampled: 855786\n",
      "    num_agent_steps_trained: 855786\n",
      "    num_steps_sampled: 855786\n",
      "    num_steps_trained: 855786\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.55\n",
      "    ram_util_percent: 17.81428571428572\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09072318265088913\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09170062498469048\n",
      "    mean_inference_ms: 1.002741333164336\n",
      "    mean_raw_obs_processing_ms: 0.11919787180400593\n",
      "  time_since_restore: 1043.9688172340393\n",
      "  time_this_iter_s: 9.793396234512329\n",
      "  time_total_s: 1043.9688172340393\n",
      "  timers:\n",
      "    learn_throughput: 1283.304\n",
      "    learn_time_ms: 6232.348\n",
      "    load_throughput: 24759054.832\n",
      "    load_time_ms: 0.323\n",
      "    sample_throughput: 803.703\n",
      "    sample_time_ms: 9951.435\n",
      "    update_time_ms: 2.84\n",
      "  timestamp: 1645201841\n",
      "  timesteps_since_restore: 855786\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 855786\n",
      "  training_iteration: 107\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:30:43 (running for 00:17:40.11)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1043.97</td><td style=\"text-align: right;\">855786</td><td style=\"text-align: right;\">   173.8</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  75</td><td style=\"text-align: right;\">             173.8</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:30:48 (running for 00:17:45.14)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1043.97</td><td style=\"text-align: right;\">855786</td><td style=\"text-align: right;\">   173.8</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  75</td><td style=\"text-align: right;\">             173.8</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 863784\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-30-51\n",
      "  done: false\n",
      "  episode_len_mean: 175.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.17\n",
      "  episode_reward_min: 79.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 5521\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 67086200832.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.014768538996577263\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02741328626871109\n",
      "          model: {}\n",
      "          policy_loss: 0.011270120739936829\n",
      "          total_loss: 1839053312.0\n",
      "          vf_explained_var: 0.7269150018692017\n",
      "          vf_loss: 208.00836181640625\n",
      "    num_agent_steps_sampled: 863784\n",
      "    num_agent_steps_trained: 863784\n",
      "    num_steps_sampled: 863784\n",
      "    num_steps_trained: 863784\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.81428571428572\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09071214195450501\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09167761387176832\n",
      "    mean_inference_ms: 1.0030389354869929\n",
      "    mean_raw_obs_processing_ms: 0.11923839822229933\n",
      "  time_since_restore: 1053.6127927303314\n",
      "  time_this_iter_s: 9.643975496292114\n",
      "  time_total_s: 1053.6127927303314\n",
      "  timers:\n",
      "    learn_throughput: 1287.215\n",
      "    learn_time_ms: 6213.415\n",
      "    load_throughput: 24177328.571\n",
      "    load_time_ms: 0.331\n",
      "    sample_throughput: 802.995\n",
      "    sample_time_ms: 9960.215\n",
      "    update_time_ms: 2.785\n",
      "  timestamp: 1645201851\n",
      "  timesteps_since_restore: 863784\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 863784\n",
      "  training_iteration: 108\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:30:54 (running for 00:17:50.79)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1053.61</td><td style=\"text-align: right;\">863784</td><td style=\"text-align: right;\">  175.17</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  79</td><td style=\"text-align: right;\">            175.17</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:30:59 (running for 00:17:55.81)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1053.61</td><td style=\"text-align: right;\">863784</td><td style=\"text-align: right;\">  175.17</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  79</td><td style=\"text-align: right;\">            175.17</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 871782\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-31-00\n",
      "  done: false\n",
      "  episode_len_mean: 176.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 176.72\n",
      "  episode_reward_min: 79.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 5566\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 100629299200.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01721767708659172\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03084140084683895\n",
      "          model: {}\n",
      "          policy_loss: -0.0015674836467951536\n",
      "          total_loss: 3103548416.0\n",
      "          vf_explained_var: 0.7191342115402222\n",
      "          vf_loss: 211.60504150390625\n",
      "    num_agent_steps_sampled: 871782\n",
      "    num_agent_steps_trained: 871782\n",
      "    num_steps_sampled: 871782\n",
      "    num_steps_trained: 871782\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.66153846153847\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09070165209241407\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09167971839640444\n",
      "    mean_inference_ms: 1.0029731546792027\n",
      "    mean_raw_obs_processing_ms: 0.11919479115642975\n",
      "  time_since_restore: 1063.1553783416748\n",
      "  time_this_iter_s: 9.542585611343384\n",
      "  time_total_s: 1063.1553783416748\n",
      "  timers:\n",
      "    learn_throughput: 1285.932\n",
      "    learn_time_ms: 6219.613\n",
      "    load_throughput: 24386481.093\n",
      "    load_time_ms: 0.328\n",
      "    sample_throughput: 805.287\n",
      "    sample_time_ms: 9931.865\n",
      "    update_time_ms: 2.876\n",
      "  timestamp: 1645201860\n",
      "  timesteps_since_restore: 871782\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 871782\n",
      "  training_iteration: 109\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:31:04 (running for 00:18:01.36)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1063.16</td><td style=\"text-align: right;\">871782</td><td style=\"text-align: right;\">  176.72</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  79</td><td style=\"text-align: right;\">            176.72</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:31:09 (running for 00:18:06.38)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1063.16</td><td style=\"text-align: right;\">871782</td><td style=\"text-align: right;\">  176.72</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  79</td><td style=\"text-align: right;\">            176.72</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 879780\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-31-10\n",
      "  done: false\n",
      "  episode_len_mean: 173.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 173.81\n",
      "  episode_reward_min: 76.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 5613\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 150943940608.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.017176074907183647\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02982879802584648\n",
      "          model: {}\n",
      "          policy_loss: 0.0007339449948631227\n",
      "          total_loss: 4502476288.0\n",
      "          vf_explained_var: 0.6761935353279114\n",
      "          vf_loss: 205.54095458984375\n",
      "    num_agent_steps_sampled: 879780\n",
      "    num_agent_steps_trained: 879780\n",
      "    num_steps_sampled: 879780\n",
      "    num_steps_trained: 879780\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.32857142857144\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09068798342459797\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09166712170636095\n",
      "    mean_inference_ms: 1.0025178417714173\n",
      "    mean_raw_obs_processing_ms: 0.1191233704442088\n",
      "  time_since_restore: 1072.8074593544006\n",
      "  time_this_iter_s: 9.65208101272583\n",
      "  time_total_s: 1072.8074593544006\n",
      "  timers:\n",
      "    learn_throughput: 1284.895\n",
      "    learn_time_ms: 6224.633\n",
      "    load_throughput: 24804823.567\n",
      "    load_time_ms: 0.322\n",
      "    sample_throughput: 803.927\n",
      "    sample_time_ms: 9948.667\n",
      "    update_time_ms: 2.837\n",
      "  timestamp: 1645201870\n",
      "  timesteps_since_restore: 879780\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 879780\n",
      "  training_iteration: 110\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:31:15 (running for 00:18:12.05)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1072.81</td><td style=\"text-align: right;\">879780</td><td style=\"text-align: right;\">  173.81</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  76</td><td style=\"text-align: right;\">            173.81</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 887778\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-31-20\n",
      "  done: false\n",
      "  episode_len_mean: 170.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 170.59\n",
      "  episode_reward_min: 76.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 5660\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 226415919104.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.014762600883841515\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.032579246908426285\n",
      "          model: {}\n",
      "          policy_loss: 0.009258219040930271\n",
      "          total_loss: 7376460288.0\n",
      "          vf_explained_var: 0.6758654713630676\n",
      "          vf_loss: 239.13084411621094\n",
      "    num_agent_steps_sampled: 887778\n",
      "    num_agent_steps_trained: 887778\n",
      "    num_steps_sampled: 887778\n",
      "    num_steps_trained: 887778\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.27142857142857\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09067252422584528\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09163558221169041\n",
      "    mean_inference_ms: 1.0018671843842697\n",
      "    mean_raw_obs_processing_ms: 0.11905967158555303\n",
      "  time_since_restore: 1082.679934501648\n",
      "  time_this_iter_s: 9.872475147247314\n",
      "  time_total_s: 1082.679934501648\n",
      "  timers:\n",
      "    learn_throughput: 1283.424\n",
      "    learn_time_ms: 6231.767\n",
      "    load_throughput: 23884687.356\n",
      "    load_time_ms: 0.335\n",
      "    sample_throughput: 803.824\n",
      "    sample_time_ms: 9949.935\n",
      "    update_time_ms: 2.881\n",
      "  timestamp: 1645201880\n",
      "  timesteps_since_restore: 887778\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 887778\n",
      "  training_iteration: 111\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:31:21 (running for 00:18:17.88)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1082.68</td><td style=\"text-align: right;\">887778</td><td style=\"text-align: right;\">  170.59</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  76</td><td style=\"text-align: right;\">            170.59</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:31:26 (running for 00:18:22.95)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1082.68</td><td style=\"text-align: right;\">887778</td><td style=\"text-align: right;\">  170.59</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  76</td><td style=\"text-align: right;\">            170.59</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 895776\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-31-30\n",
      "  done: false\n",
      "  episode_len_mean: 172.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 172.78\n",
      "  episode_reward_min: 82.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 5705\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 339623870464.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01939159631729126\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03057202510535717\n",
      "          model: {}\n",
      "          policy_loss: -0.002337542362511158\n",
      "          total_loss: 10382990336.0\n",
      "          vf_explained_var: 0.7536791563034058\n",
      "          vf_loss: 192.53424072265625\n",
      "    num_agent_steps_sampled: 895776\n",
      "    num_agent_steps_trained: 895776\n",
      "    num_steps_sampled: 895776\n",
      "    num_steps_trained: 895776\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.37142857142855\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09065893566629352\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09160242579562158\n",
      "    mean_inference_ms: 1.0020493736255836\n",
      "    mean_raw_obs_processing_ms: 0.11909250648944364\n",
      "  time_since_restore: 1092.5069150924683\n",
      "  time_this_iter_s: 9.826980590820312\n",
      "  time_total_s: 1092.5069150924683\n",
      "  timers:\n",
      "    learn_throughput: 1285.123\n",
      "    learn_time_ms: 6223.529\n",
      "    load_throughput: 23534476.913\n",
      "    load_time_ms: 0.34\n",
      "    sample_throughput: 802.906\n",
      "    sample_time_ms: 9961.318\n",
      "    update_time_ms: 2.834\n",
      "  timestamp: 1645201890\n",
      "  timesteps_since_restore: 895776\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 895776\n",
      "  training_iteration: 112\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:31:32 (running for 00:18:28.75)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1092.51</td><td style=\"text-align: right;\">895776</td><td style=\"text-align: right;\">  172.78</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            172.78</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:31:37 (running for 00:18:33.80)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1092.51</td><td style=\"text-align: right;\">895776</td><td style=\"text-align: right;\">  172.78</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            172.78</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 903774\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-31-39\n",
      "  done: false\n",
      "  episode_len_mean: 175.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.84\n",
      "  episode_reward_min: 82.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 5751\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 509435838464.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.018059125170111656\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025093132629990578\n",
      "          model: {}\n",
      "          policy_loss: 0.0024632408749312162\n",
      "          total_loss: 12783341568.0\n",
      "          vf_explained_var: 0.6955623030662537\n",
      "          vf_loss: 247.39205932617188\n",
      "    num_agent_steps_sampled: 903774\n",
      "    num_agent_steps_trained: 903774\n",
      "    num_steps_sampled: 903774\n",
      "    num_steps_trained: 903774\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.95714285714287\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09065778981129567\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09161073046988025\n",
      "    mean_inference_ms: 1.002462291317141\n",
      "    mean_raw_obs_processing_ms: 0.11910914911668784\n",
      "  time_since_restore: 1102.246033191681\n",
      "  time_this_iter_s: 9.739118099212646\n",
      "  time_total_s: 1102.246033191681\n",
      "  timers:\n",
      "    learn_throughput: 1287.809\n",
      "    learn_time_ms: 6210.548\n",
      "    load_throughput: 23320155.295\n",
      "    load_time_ms: 0.343\n",
      "    sample_throughput: 803.539\n",
      "    sample_time_ms: 9953.467\n",
      "    update_time_ms: 2.886\n",
      "  timestamp: 1645201899\n",
      "  timesteps_since_restore: 903774\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 903774\n",
      "  training_iteration: 113\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:31:42 (running for 00:18:39.51)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1102.25</td><td style=\"text-align: right;\">903774</td><td style=\"text-align: right;\">  175.84</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            175.84</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:31:48 (running for 00:18:44.58)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1102.25</td><td style=\"text-align: right;\">903774</td><td style=\"text-align: right;\">  175.84</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            175.84</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 911772\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-31-49\n",
      "  done: false\n",
      "  episode_len_mean: 176.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 176.47\n",
      "  episode_reward_min: 77.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 5794\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 764153757696.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015968939289450645\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024248365312814713\n",
      "          model: {}\n",
      "          policy_loss: 0.009318090043962002\n",
      "          total_loss: 18529480704.0\n",
      "          vf_explained_var: 0.659763514995575\n",
      "          vf_loss: 259.66357421875\n",
      "    num_agent_steps_sampled: 911772\n",
      "    num_agent_steps_trained: 911772\n",
      "    num_steps_sampled: 911772\n",
      "    num_steps_trained: 911772\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.92857142857142\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09066407306646976\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09164222415759692\n",
      "    mean_inference_ms: 1.0025172728159462\n",
      "    mean_raw_obs_processing_ms: 0.11907821249351454\n",
      "  time_since_restore: 1112.0232329368591\n",
      "  time_this_iter_s: 9.777199745178223\n",
      "  time_total_s: 1112.0232329368591\n",
      "  timers:\n",
      "    learn_throughput: 1292.395\n",
      "    learn_time_ms: 6188.508\n",
      "    load_throughput: 23294245.811\n",
      "    load_time_ms: 0.343\n",
      "    sample_throughput: 806.219\n",
      "    sample_time_ms: 9920.376\n",
      "    update_time_ms: 2.972\n",
      "  timestamp: 1645201909\n",
      "  timesteps_since_restore: 911772\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 911772\n",
      "  training_iteration: 114\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:31:53 (running for 00:18:50.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1112.02</td><td style=\"text-align: right;\">911772</td><td style=\"text-align: right;\">  176.47</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  77</td><td style=\"text-align: right;\">            176.47</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:31:58 (running for 00:18:55.37)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1112.02</td><td style=\"text-align: right;\">911772</td><td style=\"text-align: right;\">  176.47</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  77</td><td style=\"text-align: right;\">            176.47</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 919770\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-31-59\n",
      "  done: false\n",
      "  episode_len_mean: 181.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 181.52\n",
      "  episode_reward_min: 77.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 5839\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1146230669312.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.016263948753476143\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02086438052356243\n",
      "          model: {}\n",
      "          policy_loss: 0.007133981678634882\n",
      "          total_loss: 23915393024.0\n",
      "          vf_explained_var: 0.6758930683135986\n",
      "          vf_loss: 230.38275146484375\n",
      "    num_agent_steps_sampled: 919770\n",
      "    num_agent_steps_trained: 919770\n",
      "    num_steps_sampled: 919770\n",
      "    num_steps_trained: 919770\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.42142857142856\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09065620390867458\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09162414135124866\n",
      "    mean_inference_ms: 1.0025303090957352\n",
      "    mean_raw_obs_processing_ms: 0.11909337479587094\n",
      "  time_since_restore: 1121.7474722862244\n",
      "  time_this_iter_s: 9.724239349365234\n",
      "  time_total_s: 1121.7474722862244\n",
      "  timers:\n",
      "    learn_throughput: 1295.249\n",
      "    learn_time_ms: 6174.876\n",
      "    load_throughput: 23445655.152\n",
      "    load_time_ms: 0.341\n",
      "    sample_throughput: 819.877\n",
      "    sample_time_ms: 9755.118\n",
      "    update_time_ms: 3.008\n",
      "  timestamp: 1645201919\n",
      "  timesteps_since_restore: 919770\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 919770\n",
      "  training_iteration: 115\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:32:04 (running for 00:19:01.07)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         1121.75</td><td style=\"text-align: right;\">919770</td><td style=\"text-align: right;\">  181.52</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  77</td><td style=\"text-align: right;\">            181.52</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 927768\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-32-09\n",
      "  done: false\n",
      "  episode_len_mean: 184.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 184.21\n",
      "  episode_reward_min: 78.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 5882\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1719345872896.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.018771253526210785\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024176446720957756\n",
      "          model: {}\n",
      "          policy_loss: 0.008609569631516933\n",
      "          total_loss: 41567674368.0\n",
      "          vf_explained_var: 0.6432411074638367\n",
      "          vf_loss: 262.84222412109375\n",
      "    num_agent_steps_sampled: 927768\n",
      "    num_agent_steps_trained: 927768\n",
      "    num_steps_sampled: 927768\n",
      "    num_steps_trained: 927768\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.0142857142857\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09064859962176537\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09162269457649888\n",
      "    mean_inference_ms: 1.0026720256045472\n",
      "    mean_raw_obs_processing_ms: 0.11909574421140895\n",
      "  time_since_restore: 1131.4898149967194\n",
      "  time_this_iter_s: 9.742342710494995\n",
      "  time_total_s: 1131.4898149967194\n",
      "  timers:\n",
      "    learn_throughput: 1294.195\n",
      "    learn_time_ms: 6179.903\n",
      "    load_throughput: 23555960.531\n",
      "    load_time_ms: 0.34\n",
      "    sample_throughput: 820.2\n",
      "    sample_time_ms: 9751.283\n",
      "    update_time_ms: 3.037\n",
      "  timestamp: 1645201929\n",
      "  timesteps_since_restore: 927768\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 927768\n",
      "  training_iteration: 116\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:32:10 (running for 00:19:06.82)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         1131.49</td><td style=\"text-align: right;\">927768</td><td style=\"text-align: right;\">  184.21</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            184.21</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:32:15 (running for 00:19:11.84)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         1131.49</td><td style=\"text-align: right;\">927768</td><td style=\"text-align: right;\">  184.21</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            184.21</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 935766\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-32-18\n",
      "  done: false\n",
      "  episode_len_mean: 180.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 180.98\n",
      "  episode_reward_min: 80.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 5927\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2579018809344.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01943632960319519\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.031632404774427414\n",
      "          model: {}\n",
      "          policy_loss: -0.005124614108353853\n",
      "          total_loss: 81580564480.0\n",
      "          vf_explained_var: 0.6985751390457153\n",
      "          vf_loss: 218.0629425048828\n",
      "    num_agent_steps_sampled: 935766\n",
      "    num_agent_steps_trained: 935766\n",
      "    num_steps_sampled: 935766\n",
      "    num_steps_trained: 935766\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.40714285714286\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09064129709257467\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09162162455043216\n",
      "    mean_inference_ms: 1.002792818448253\n",
      "    mean_raw_obs_processing_ms: 0.11909816030478153\n",
      "  time_since_restore: 1141.1365773677826\n",
      "  time_this_iter_s: 9.646762371063232\n",
      "  time_total_s: 1141.1365773677826\n",
      "  timers:\n",
      "    learn_throughput: 1296.242\n",
      "    learn_time_ms: 6170.145\n",
      "    load_throughput: 24284091.061\n",
      "    load_time_ms: 0.329\n",
      "    sample_throughput: 820.183\n",
      "    sample_time_ms: 9751.478\n",
      "    update_time_ms: 2.985\n",
      "  timestamp: 1645201938\n",
      "  timesteps_since_restore: 935766\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 935766\n",
      "  training_iteration: 117\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:32:20 (running for 00:19:17.49)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1141.14</td><td style=\"text-align: right;\">935766</td><td style=\"text-align: right;\">  180.98</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  80</td><td style=\"text-align: right;\">            180.98</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:32:25 (running for 00:19:22.52)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1141.14</td><td style=\"text-align: right;\">935766</td><td style=\"text-align: right;\">  180.98</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  80</td><td style=\"text-align: right;\">            180.98</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 943764\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-32-29\n",
      "  done: false\n",
      "  episode_len_mean: 179.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 179.29\n",
      "  episode_reward_min: 80.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 5971\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3868528214016.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01775774359703064\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022481361404061317\n",
      "          model: {}\n",
      "          policy_loss: 0.01451136264950037\n",
      "          total_loss: 86969778176.0\n",
      "          vf_explained_var: 0.6423279643058777\n",
      "          vf_loss: 272.0989685058594\n",
      "    num_agent_steps_sampled: 943764\n",
      "    num_agent_steps_trained: 943764\n",
      "    num_steps_sampled: 943764\n",
      "    num_steps_trained: 943764\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.97142857142858\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09064050188499712\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.091616197964033\n",
      "    mean_inference_ms: 1.002583935572236\n",
      "    mean_raw_obs_processing_ms: 0.11908421430971287\n",
      "  time_since_restore: 1151.1970872879028\n",
      "  time_this_iter_s: 10.06050992012024\n",
      "  time_total_s: 1151.1970872879028\n",
      "  timers:\n",
      "    learn_throughput: 1290.425\n",
      "    learn_time_ms: 6197.96\n",
      "    load_throughput: 24289366.007\n",
      "    load_time_ms: 0.329\n",
      "    sample_throughput: 819.869\n",
      "    sample_time_ms: 9755.214\n",
      "    update_time_ms: 3.028\n",
      "  timestamp: 1645201949\n",
      "  timesteps_since_restore: 943764\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 943764\n",
      "  training_iteration: 118\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:32:31 (running for 00:19:27.59)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">          1151.2</td><td style=\"text-align: right;\">943764</td><td style=\"text-align: right;\">  179.29</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  80</td><td style=\"text-align: right;\">            179.29</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:32:36 (running for 00:19:32.61)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">          1151.2</td><td style=\"text-align: right;\">943764</td><td style=\"text-align: right;\">  179.29</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  80</td><td style=\"text-align: right;\">            179.29</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 951762\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-32-39\n",
      "  done: false\n",
      "  episode_len_mean: 179.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 179.8\n",
      "  episode_reward_min: 80.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 6016\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5802792321024.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02156093157827854\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03287080302834511\n",
      "          model: {}\n",
      "          policy_loss: 0.006975677330046892\n",
      "          total_loss: 190742446080.0\n",
      "          vf_explained_var: 0.7483492493629456\n",
      "          vf_loss: 171.0938720703125\n",
      "    num_agent_steps_sampled: 951762\n",
      "    num_agent_steps_trained: 951762\n",
      "    num_steps_sampled: 951762\n",
      "    num_steps_trained: 951762\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.28666666666665\n",
      "    ram_util_percent: 17.826666666666668\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09065486410249449\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09164098564735688\n",
      "    mean_inference_ms: 1.0026548769703454\n",
      "    mean_raw_obs_processing_ms: 0.11907617697512894\n",
      "  time_since_restore: 1161.3082301616669\n",
      "  time_this_iter_s: 10.111142873764038\n",
      "  time_total_s: 1161.3082301616669\n",
      "  timers:\n",
      "    learn_throughput: 1283.833\n",
      "    learn_time_ms: 6229.782\n",
      "    load_throughput: 23781400.391\n",
      "    load_time_ms: 0.336\n",
      "    sample_throughput: 815.351\n",
      "    sample_time_ms: 9809.275\n",
      "    update_time_ms: 3.046\n",
      "  timestamp: 1645201959\n",
      "  timesteps_since_restore: 951762\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 951762\n",
      "  training_iteration: 119\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:32:41 (running for 00:19:37.74)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1161.31</td><td style=\"text-align: right;\">951762</td><td style=\"text-align: right;\">   179.8</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  80</td><td style=\"text-align: right;\">             179.8</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:32:46 (running for 00:19:42.76)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1161.31</td><td style=\"text-align: right;\">951762</td><td style=\"text-align: right;\">   179.8</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  80</td><td style=\"text-align: right;\">             179.8</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 959760\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-32-48\n",
      "  done: false\n",
      "  episode_len_mean: 178.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 178.44\n",
      "  episode_reward_min: 88.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 6061\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8704188481536.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.023482972756028175\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021703286096453667\n",
      "          model: {}\n",
      "          policy_loss: 0.012493106536567211\n",
      "          total_loss: 188909502464.0\n",
      "          vf_explained_var: 0.6359081268310547\n",
      "          vf_loss: 296.27392578125\n",
      "    num_agent_steps_sampled: 959760\n",
      "    num_agent_steps_trained: 959760\n",
      "    num_steps_sampled: 959760\n",
      "    num_steps_trained: 959760\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.84285714285714\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09066956340444245\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09167073051441625\n",
      "    mean_inference_ms: 1.0028533738531678\n",
      "    mean_raw_obs_processing_ms: 0.11907814668684479\n",
      "  time_since_restore: 1171.0891284942627\n",
      "  time_this_iter_s: 9.780898332595825\n",
      "  time_total_s: 1171.0891284942627\n",
      "  timers:\n",
      "    learn_throughput: 1280.951\n",
      "    learn_time_ms: 6243.798\n",
      "    load_throughput: 23997455.749\n",
      "    load_time_ms: 0.333\n",
      "    sample_throughput: 812.768\n",
      "    sample_time_ms: 9840.451\n",
      "    update_time_ms: 3.057\n",
      "  timestamp: 1645201968\n",
      "  timesteps_since_restore: 959760\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 959760\n",
      "  training_iteration: 120\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:32:52 (running for 00:19:48.59)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1171.09</td><td style=\"text-align: right;\">959760</td><td style=\"text-align: right;\">  178.44</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  88</td><td style=\"text-align: right;\">            178.44</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:32:57 (running for 00:19:53.61)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1171.09</td><td style=\"text-align: right;\">959760</td><td style=\"text-align: right;\">  178.44</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  88</td><td style=\"text-align: right;\">            178.44</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 967758\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-32-58\n",
      "  done: false\n",
      "  episode_len_mean: 177.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 177.26\n",
      "  episode_reward_min: 88.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 6107\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 13056283246592.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.019815783947706223\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026419997215270996\n",
      "          model: {}\n",
      "          policy_loss: 0.009311514906585217\n",
      "          total_loss: 344946966528.0\n",
      "          vf_explained_var: 0.662196934223175\n",
      "          vf_loss: 236.1876220703125\n",
      "    num_agent_steps_sampled: 967758\n",
      "    num_agent_steps_trained: 967758\n",
      "    num_steps_sampled: 967758\n",
      "    num_steps_trained: 967758\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.27857142857142\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09067784949436238\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09165432750546308\n",
      "    mean_inference_ms: 1.0028905736575928\n",
      "    mean_raw_obs_processing_ms: 0.11913410419149065\n",
      "  time_since_restore: 1180.8467786312103\n",
      "  time_this_iter_s: 9.757650136947632\n",
      "  time_total_s: 1180.8467786312103\n",
      "  timers:\n",
      "    learn_throughput: 1285.424\n",
      "    learn_time_ms: 6222.071\n",
      "    load_throughput: 24254242.927\n",
      "    load_time_ms: 0.33\n",
      "    sample_throughput: 810.751\n",
      "    sample_time_ms: 9864.933\n",
      "    update_time_ms: 2.952\n",
      "  timestamp: 1645201978\n",
      "  timesteps_since_restore: 967758\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 967758\n",
      "  training_iteration: 121\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:33:02 (running for 00:19:59.38)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1180.85</td><td style=\"text-align: right;\">967758</td><td style=\"text-align: right;\">  177.26</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  88</td><td style=\"text-align: right;\">            177.26</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:33:07 (running for 00:20:04.40)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1180.85</td><td style=\"text-align: right;\">967758</td><td style=\"text-align: right;\">  177.26</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  88</td><td style=\"text-align: right;\">            177.26</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 975756\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-33-08\n",
      "  done: false\n",
      "  episode_len_mean: 175.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.84\n",
      "  episode_reward_min: 89.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 6151\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 19584423821312.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.016291748732328415\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03314802795648575\n",
      "          model: {}\n",
      "          policy_loss: 0.01192372664809227\n",
      "          total_loss: 649185001472.0\n",
      "          vf_explained_var: 0.7558867335319519\n",
      "          vf_loss: 177.1375732421875\n",
      "    num_agent_steps_sampled: 975756\n",
      "    num_agent_steps_trained: 975756\n",
      "    num_steps_sampled: 975756\n",
      "    num_steps_trained: 975756\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.63571428571429\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09068707188615535\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09166614588348915\n",
      "    mean_inference_ms: 1.0034755496490346\n",
      "    mean_raw_obs_processing_ms: 0.1191631331651189\n",
      "  time_since_restore: 1190.9130170345306\n",
      "  time_this_iter_s: 10.066238403320312\n",
      "  time_total_s: 1190.9130170345306\n",
      "  timers:\n",
      "    learn_throughput: 1288.674\n",
      "    learn_time_ms: 6206.378\n",
      "    load_throughput: 24395348.26\n",
      "    load_time_ms: 0.328\n",
      "    sample_throughput: 809.303\n",
      "    sample_time_ms: 9882.579\n",
      "    update_time_ms: 2.907\n",
      "  timestamp: 1645201988\n",
      "  timesteps_since_restore: 975756\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 975756\n",
      "  training_iteration: 122\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:33:12 (running for 00:20:09.47)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1190.91</td><td style=\"text-align: right;\">975756</td><td style=\"text-align: right;\">  175.84</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            175.84</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:33:17 (running for 00:20:14.49)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1190.91</td><td style=\"text-align: right;\">975756</td><td style=\"text-align: right;\">  175.84</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            175.84</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 983754\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-33-18\n",
      "  done: false\n",
      "  episode_len_mean: 179.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 179.52\n",
      "  episode_reward_min: 93.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 6194\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 29376636780544.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.0180740337818861\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026938676834106445\n",
      "          model: {}\n",
      "          policy_loss: 0.014655353501439095\n",
      "          total_loss: 791367712768.0\n",
      "          vf_explained_var: 0.6499242782592773\n",
      "          vf_loss: 262.8655090332031\n",
      "    num_agent_steps_sampled: 983754\n",
      "    num_agent_steps_trained: 983754\n",
      "    num_steps_sampled: 983754\n",
      "    num_steps_trained: 983754\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.39999999999999\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09068250573750553\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09167708299623081\n",
      "    mean_inference_ms: 1.003806642772856\n",
      "    mean_raw_obs_processing_ms: 0.11913930036546734\n",
      "  time_since_restore: 1200.4224202632904\n",
      "  time_this_iter_s: 9.509403228759766\n",
      "  time_total_s: 1200.4224202632904\n",
      "  timers:\n",
      "    learn_throughput: 1291.109\n",
      "    learn_time_ms: 6194.674\n",
      "    load_throughput: 24395348.26\n",
      "    load_time_ms: 0.328\n",
      "    sample_throughput: 811.53\n",
      "    sample_time_ms: 9855.463\n",
      "    update_time_ms: 2.936\n",
      "  timestamp: 1645201998\n",
      "  timesteps_since_restore: 983754\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 983754\n",
      "  training_iteration: 123\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:33:23 (running for 00:20:20.00)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1200.42</td><td style=\"text-align: right;\">983754</td><td style=\"text-align: right;\">  179.52</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  93</td><td style=\"text-align: right;\">            179.52</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 991752\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-33-27\n",
      "  done: false\n",
      "  episode_len_mean: 185.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 185.22\n",
      "  episode_reward_min: 90.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 6239\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 44064955170816.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01635696366429329\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04069727286696434\n",
      "          model: {}\n",
      "          policy_loss: -0.0040916502475738525\n",
      "          total_loss: 1793323433984.0\n",
      "          vf_explained_var: 0.6471855044364929\n",
      "          vf_loss: 240.763916015625\n",
      "    num_agent_steps_sampled: 991752\n",
      "    num_agent_steps_trained: 991752\n",
      "    num_steps_sampled: 991752\n",
      "    num_steps_trained: 991752\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.5153846153846\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09066560267384613\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09162574258133734\n",
      "    mean_inference_ms: 1.0033762959416521\n",
      "    mean_raw_obs_processing_ms: 0.11911676737300785\n",
      "  time_since_restore: 1209.9625425338745\n",
      "  time_this_iter_s: 9.540122270584106\n",
      "  time_total_s: 1209.9625425338745\n",
      "  timers:\n",
      "    learn_throughput: 1295.106\n",
      "    learn_time_ms: 6175.556\n",
      "    load_throughput: 23849028.432\n",
      "    load_time_ms: 0.335\n",
      "    sample_throughput: 812.891\n",
      "    sample_time_ms: 9838.964\n",
      "    update_time_ms: 2.873\n",
      "  timestamp: 1645202007\n",
      "  timesteps_since_restore: 991752\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 991752\n",
      "  training_iteration: 124\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:33:28 (running for 00:20:25.50)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         1209.96</td><td style=\"text-align: right;\">991752</td><td style=\"text-align: right;\">  185.22</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  90</td><td style=\"text-align: right;\">            185.22</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:33:34 (running for 00:20:30.56)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         1209.96</td><td style=\"text-align: right;\">991752</td><td style=\"text-align: right;\">  185.22</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  90</td><td style=\"text-align: right;\">            185.22</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 999750\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-33-37\n",
      "  done: false\n",
      "  episode_len_mean: 172.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 172.67\n",
      "  episode_reward_min: 86.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 6288\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 66097432756224.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01641971245408058\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022989168763160706\n",
      "          model: {}\n",
      "          policy_loss: 0.01281532272696495\n",
      "          total_loss: 1519525036032.0\n",
      "          vf_explained_var: 0.7018181681632996\n",
      "          vf_loss: 222.345458984375\n",
      "    num_agent_steps_sampled: 999750\n",
      "    num_agent_steps_trained: 999750\n",
      "    num_steps_sampled: 999750\n",
      "    num_steps_trained: 999750\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.66428571428573\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09065503985055161\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09160217913653038\n",
      "    mean_inference_ms: 1.0025811758097547\n",
      "    mean_raw_obs_processing_ms: 0.11905353942620996\n",
      "  time_since_restore: 1219.7372436523438\n",
      "  time_this_iter_s: 9.774701118469238\n",
      "  time_total_s: 1219.7372436523438\n",
      "  timers:\n",
      "    learn_throughput: 1293.313\n",
      "    learn_time_ms: 6184.116\n",
      "    load_throughput: 23905111.802\n",
      "    load_time_ms: 0.335\n",
      "    sample_throughput: 814.752\n",
      "    sample_time_ms: 9816.478\n",
      "    update_time_ms: 2.878\n",
      "  timestamp: 1645202017\n",
      "  timesteps_since_restore: 999750\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 999750\n",
      "  training_iteration: 125\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:33:39 (running for 00:20:36.30)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         1219.74</td><td style=\"text-align: right;\">999750</td><td style=\"text-align: right;\">  172.67</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            172.67</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:33:44 (running for 00:20:41.35)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         1219.74</td><td style=\"text-align: right;\">999750</td><td style=\"text-align: right;\">  172.67</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            172.67</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1007748\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-33-47\n",
      "  done: false\n",
      "  episode_len_mean: 169.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 169.33\n",
      "  episode_reward_min: 86.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 6333\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 99146149134336.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.013934988528490067\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.041580818593502045\n",
      "          model: {}\n",
      "          policy_loss: 0.009231656789779663\n",
      "          total_loss: 4122577731584.0\n",
      "          vf_explained_var: 0.6879774928092957\n",
      "          vf_loss: 230.5967254638672\n",
      "    num_agent_steps_sampled: 1007748\n",
      "    num_agent_steps_trained: 1007748\n",
      "    num_steps_sampled: 1007748\n",
      "    num_steps_trained: 1007748\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.30714285714285\n",
      "    ram_util_percent: 17.84285714285715\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09064885665951655\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09162848538692493\n",
      "    mean_inference_ms: 1.0026371223519461\n",
      "    mean_raw_obs_processing_ms: 0.11901593492056688\n",
      "  time_since_restore: 1229.3086187839508\n",
      "  time_this_iter_s: 9.571375131607056\n",
      "  time_total_s: 1229.3086187839508\n",
      "  timers:\n",
      "    learn_throughput: 1295.438\n",
      "    learn_time_ms: 6173.975\n",
      "    load_throughput: 24347542.018\n",
      "    load_time_ms: 0.328\n",
      "    sample_throughput: 814.618\n",
      "    sample_time_ms: 9818.102\n",
      "    update_time_ms: 2.831\n",
      "  timestamp: 1645202027\n",
      "  timesteps_since_restore: 1007748\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1007748\n",
      "  training_iteration: 126\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:33:50 (running for 00:20:46.90)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         1229.31</td><td style=\"text-align: right;\">1007748</td><td style=\"text-align: right;\">  169.33</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            169.33</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:33:55 (running for 00:20:51.97)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         1229.31</td><td style=\"text-align: right;\">1007748</td><td style=\"text-align: right;\">  169.33</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            169.33</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1015746\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-33-57\n",
      "  done: false\n",
      "  episode_len_mean: 172.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 172.26\n",
      "  episode_reward_min: 87.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 6379\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 148719215312896.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015161119401454926\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03585738688707352\n",
      "          model: {}\n",
      "          policy_loss: 0.014962166547775269\n",
      "          total_loss: 5332682145792.0\n",
      "          vf_explained_var: 0.6749987602233887\n",
      "          vf_loss: 215.76577758789062\n",
      "    num_agent_steps_sampled: 1015746\n",
      "    num_agent_steps_trained: 1015746\n",
      "    num_steps_sampled: 1015746\n",
      "    num_steps_trained: 1015746\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.07142857142857\n",
      "    ram_util_percent: 17.842857142857145\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09064172874624038\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09162367993731134\n",
      "    mean_inference_ms: 1.0024294515662187\n",
      "    mean_raw_obs_processing_ms: 0.11900569607865981\n",
      "  time_since_restore: 1238.9848773479462\n",
      "  time_this_iter_s: 9.676258563995361\n",
      "  time_total_s: 1238.9848773479462\n",
      "  timers:\n",
      "    learn_throughput: 1294.841\n",
      "    learn_time_ms: 6176.822\n",
      "    load_throughput: 24255996.668\n",
      "    load_time_ms: 0.33\n",
      "    sample_throughput: 815.458\n",
      "    sample_time_ms: 9807.982\n",
      "    update_time_ms: 2.836\n",
      "  timestamp: 1645202037\n",
      "  timesteps_since_restore: 1015746\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1015746\n",
      "  training_iteration: 127\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:34:01 (running for 00:20:57.61)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         1238.98</td><td style=\"text-align: right;\">1015746</td><td style=\"text-align: right;\">  172.26</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            172.26</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:34:06 (running for 00:21:02.67)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         1238.98</td><td style=\"text-align: right;\">1015746</td><td style=\"text-align: right;\">  172.26</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            172.26</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1023744\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-34-06\n",
      "  done: false\n",
      "  episode_len_mean: 180.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 180.28\n",
      "  episode_reward_min: 79.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 6422\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 223078839746560.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.016640163958072662\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.042282793670892715\n",
      "          model: {}\n",
      "          policy_loss: 0.0030292770825326443\n",
      "          total_loss: 9432396201984.0\n",
      "          vf_explained_var: 0.6998459100723267\n",
      "          vf_loss: 218.03102111816406\n",
      "    num_agent_steps_sampled: 1023744\n",
      "    num_agent_steps_trained: 1023744\n",
      "    num_steps_sampled: 1023744\n",
      "    num_steps_trained: 1023744\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.55714285714285\n",
      "    ram_util_percent: 17.850000000000005\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09063311294124161\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09161102487842346\n",
      "    mean_inference_ms: 1.0023938601416105\n",
      "    mean_raw_obs_processing_ms: 0.11902046782719575\n",
      "  time_since_restore: 1248.620693206787\n",
      "  time_this_iter_s: 9.635815858840942\n",
      "  time_total_s: 1248.620693206787\n",
      "  timers:\n",
      "    learn_throughput: 1301.718\n",
      "    learn_time_ms: 6144.19\n",
      "    load_throughput: 24686175.136\n",
      "    load_time_ms: 0.324\n",
      "    sample_throughput: 816.024\n",
      "    sample_time_ms: 9801.188\n",
      "    update_time_ms: 2.753\n",
      "  timestamp: 1645202046\n",
      "  timesteps_since_restore: 1023744\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1023744\n",
      "  training_iteration: 128\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:34:11 (running for 00:21:08.27)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         1248.62</td><td style=\"text-align: right;\">1023744</td><td style=\"text-align: right;\">  180.28</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  79</td><td style=\"text-align: right;\">            180.28</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1031742\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-34-16\n",
      "  done: false\n",
      "  episode_len_mean: 178.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 178.62\n",
      "  episode_reward_min: 79.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 6469\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 334618251231232.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015495890751481056\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.031813886016607285\n",
      "          model: {}\n",
      "          policy_loss: 0.008064111694693565\n",
      "          total_loss: 10645507407872.0\n",
      "          vf_explained_var: 0.7807513475418091\n",
      "          vf_loss: 207.55467224121094\n",
      "    num_agent_steps_sampled: 1031742\n",
      "    num_agent_steps_trained: 1031742\n",
      "    num_steps_sampled: 1031742\n",
      "    num_steps_trained: 1031742\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.92307692307692\n",
      "    ram_util_percent: 17.86923076923077\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09061848714751576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09160835349791246\n",
      "    mean_inference_ms: 1.0026754057057088\n",
      "    mean_raw_obs_processing_ms: 0.11902629828862382\n",
      "  time_since_restore: 1258.1781389713287\n",
      "  time_this_iter_s: 9.557445764541626\n",
      "  time_total_s: 1258.1781389713287\n",
      "  timers:\n",
      "    learn_throughput: 1308.955\n",
      "    learn_time_ms: 6110.219\n",
      "    load_throughput: 24757227.596\n",
      "    load_time_ms: 0.323\n",
      "    sample_throughput: 820.668\n",
      "    sample_time_ms: 9745.716\n",
      "    update_time_ms: 2.714\n",
      "  timestamp: 1645202056\n",
      "  timesteps_since_restore: 1031742\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1031742\n",
      "  training_iteration: 129\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:34:17 (running for 00:21:13.84)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         1258.18</td><td style=\"text-align: right;\">1031742</td><td style=\"text-align: right;\">  178.62</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  79</td><td style=\"text-align: right;\">            178.62</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:34:22 (running for 00:21:18.86)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         1258.18</td><td style=\"text-align: right;\">1031742</td><td style=\"text-align: right;\">  178.62</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  79</td><td style=\"text-align: right;\">            178.62</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1039740\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-34-26\n",
      "  done: false\n",
      "  episode_len_mean: 176.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 176.8\n",
      "  episode_reward_min: 86.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 6512\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 501927393624064.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.017211105674505234\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.035162266343832016\n",
      "          model: {}\n",
      "          policy_loss: 0.011512846685945988\n",
      "          total_loss: 17648905617408.0\n",
      "          vf_explained_var: 0.5523712038993835\n",
      "          vf_loss: 307.134765625\n",
      "    num_agent_steps_sampled: 1039740\n",
      "    num_agent_steps_trained: 1039740\n",
      "    num_steps_sampled: 1039740\n",
      "    num_steps_trained: 1039740\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.75\n",
      "    ram_util_percent: 17.88571428571429\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09059829909019243\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09157537591129167\n",
      "    mean_inference_ms: 1.0024300363781964\n",
      "    mean_raw_obs_processing_ms: 0.11901182944701741\n",
      "  time_since_restore: 1267.8913218975067\n",
      "  time_this_iter_s: 9.713182926177979\n",
      "  time_total_s: 1267.8913218975067\n",
      "  timers:\n",
      "    learn_throughput: 1308.39\n",
      "    learn_time_ms: 6112.858\n",
      "    load_throughput: 24795656.288\n",
      "    load_time_ms: 0.323\n",
      "    sample_throughput: 824.336\n",
      "    sample_time_ms: 9702.35\n",
      "    update_time_ms: 2.71\n",
      "  timestamp: 1645202066\n",
      "  timesteps_since_restore: 1039740\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1039740\n",
      "  training_iteration: 130\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:34:28 (running for 00:21:24.59)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         1267.89</td><td style=\"text-align: right;\">1039740</td><td style=\"text-align: right;\">   176.8</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">             176.8</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:34:33 (running for 00:21:29.61)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         1267.89</td><td style=\"text-align: right;\">1039740</td><td style=\"text-align: right;\">   176.8</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">             176.8</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1047738\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-34-35\n",
      "  done: false\n",
      "  episode_len_mean: 176.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 176.18\n",
      "  episode_reward_min: 86.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 6558\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 752891056881664.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01439234334975481\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020243579521775246\n",
      "          model: {}\n",
      "          policy_loss: 0.008676232770085335\n",
      "          total_loss: 15241209446400.0\n",
      "          vf_explained_var: 0.5776140689849854\n",
      "          vf_loss: 304.29852294921875\n",
      "    num_agent_steps_sampled: 1047738\n",
      "    num_agent_steps_trained: 1047738\n",
      "    num_steps_sampled: 1047738\n",
      "    num_steps_trained: 1047738\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.45\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09058671599207885\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09156381046844206\n",
      "    mean_inference_ms: 1.002306984996807\n",
      "    mean_raw_obs_processing_ms: 0.11899267901108868\n",
      "  time_since_restore: 1277.7172074317932\n",
      "  time_this_iter_s: 9.825885534286499\n",
      "  time_total_s: 1277.7172074317932\n",
      "  timers:\n",
      "    learn_throughput: 1305.884\n",
      "    learn_time_ms: 6124.585\n",
      "    load_throughput: 25431008.56\n",
      "    load_time_ms: 0.314\n",
      "    sample_throughput: 824.549\n",
      "    sample_time_ms: 9699.845\n",
      "    update_time_ms: 2.761\n",
      "  timestamp: 1645202075\n",
      "  timesteps_since_restore: 1047738\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1047738\n",
      "  training_iteration: 131\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:34:38 (running for 00:21:35.48)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         1277.72</td><td style=\"text-align: right;\">1047738</td><td style=\"text-align: right;\">  176.18</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            176.18</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:34:43 (running for 00:21:40.50)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         1277.72</td><td style=\"text-align: right;\">1047738</td><td style=\"text-align: right;\">  176.18</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  86</td><td style=\"text-align: right;\">            176.18</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1055736\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-34-45\n",
      "  done: false\n",
      "  episode_len_mean: 178.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 178.68\n",
      "  episode_reward_min: 89.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 6602\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1129336551768064.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.016152996569871902\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027666326612234116\n",
      "          model: {}\n",
      "          policy_loss: 0.006997932214289904\n",
      "          total_loss: 31244593135616.0\n",
      "          vf_explained_var: 0.643494188785553\n",
      "          vf_loss: 224.79788208007812\n",
      "    num_agent_steps_sampled: 1055736\n",
      "    num_agent_steps_trained: 1055736\n",
      "    num_steps_sampled: 1055736\n",
      "    num_steps_trained: 1055736\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.30714285714285\n",
      "    ram_util_percent: 17.81428571428572\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09058980821957593\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09157940863998437\n",
      "    mean_inference_ms: 1.0022403259453851\n",
      "    mean_raw_obs_processing_ms: 0.11896734565461708\n",
      "  time_since_restore: 1287.468902349472\n",
      "  time_this_iter_s: 9.751694917678833\n",
      "  time_total_s: 1287.468902349472\n",
      "  timers:\n",
      "    learn_throughput: 1305.549\n",
      "    learn_time_ms: 6126.158\n",
      "    load_throughput: 25222589.017\n",
      "    load_time_ms: 0.317\n",
      "    sample_throughput: 826.357\n",
      "    sample_time_ms: 9678.62\n",
      "    update_time_ms: 2.779\n",
      "  timestamp: 1645202085\n",
      "  timesteps_since_restore: 1055736\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1055736\n",
      "  training_iteration: 132\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:34:49 (running for 00:21:46.26)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         1287.47</td><td style=\"text-align: right;\">1055736</td><td style=\"text-align: right;\">  178.68</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            178.68</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:34:54 (running for 00:21:51.28)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         1287.47</td><td style=\"text-align: right;\">1055736</td><td style=\"text-align: right;\">  178.68</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            178.68</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1063734\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-34-55\n",
      "  done: false\n",
      "  episode_len_mean: 177.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 177.42\n",
      "  episode_reward_min: 90.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 6647\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1694004894760960.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.018055712804198265\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027434000745415688\n",
      "          model: {}\n",
      "          policy_loss: 0.010978116653859615\n",
      "          total_loss: 46473328721920.0\n",
      "          vf_explained_var: 0.7208957672119141\n",
      "          vf_loss: 239.12290954589844\n",
      "    num_agent_steps_sampled: 1063734\n",
      "    num_agent_steps_trained: 1063734\n",
      "    num_steps_sampled: 1063734\n",
      "    num_steps_trained: 1063734\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.53571428571429\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09058740313404667\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09157617586619837\n",
      "    mean_inference_ms: 1.0020447078740566\n",
      "    mean_raw_obs_processing_ms: 0.11894803257985286\n",
      "  time_since_restore: 1297.1423370838165\n",
      "  time_this_iter_s: 9.673434734344482\n",
      "  time_total_s: 1297.1423370838165\n",
      "  timers:\n",
      "    learn_throughput: 1302.378\n",
      "    learn_time_ms: 6141.075\n",
      "    load_throughput: 25429080.8\n",
      "    load_time_ms: 0.315\n",
      "    sample_throughput: 826.075\n",
      "    sample_time_ms: 9681.926\n",
      "    update_time_ms: 2.742\n",
      "  timestamp: 1645202095\n",
      "  timesteps_since_restore: 1063734\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1063734\n",
      "  training_iteration: 133\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:35:00 (running for 00:21:56.96)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         1297.14</td><td style=\"text-align: right;\">1063734</td><td style=\"text-align: right;\">  177.42</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  90</td><td style=\"text-align: right;\">            177.42</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1071732\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-35-04\n",
      "  done: false\n",
      "  episode_len_mean: 178.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 178.2\n",
      "  episode_reward_min: 90.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 6693\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2541007342141440.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01985141821205616\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030851546674966812\n",
      "          model: {}\n",
      "          policy_loss: 0.0024280534125864506\n",
      "          total_loss: 78394008010752.0\n",
      "          vf_explained_var: 0.6512030959129333\n",
      "          vf_loss: 232.56747436523438\n",
      "    num_agent_steps_sampled: 1071732\n",
      "    num_agent_steps_trained: 1071732\n",
      "    num_steps_sampled: 1071732\n",
      "    num_steps_trained: 1071732\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.5142857142857\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09057803229312388\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09157070114754852\n",
      "    mean_inference_ms: 1.001975768594844\n",
      "    mean_raw_obs_processing_ms: 0.11892573037800615\n",
      "  time_since_restore: 1306.770268201828\n",
      "  time_this_iter_s: 9.627931118011475\n",
      "  time_total_s: 1306.770268201828\n",
      "  timers:\n",
      "    learn_throughput: 1301.477\n",
      "    learn_time_ms: 6145.324\n",
      "    load_throughput: 25662517.895\n",
      "    load_time_ms: 0.312\n",
      "    sample_throughput: 824.385\n",
      "    sample_time_ms: 9701.781\n",
      "    update_time_ms: 2.754\n",
      "  timestamp: 1645202104\n",
      "  timesteps_since_restore: 1071732\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1071732\n",
      "  training_iteration: 134\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:35:06 (running for 00:22:02.56)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         1306.77</td><td style=\"text-align: right;\">1071732</td><td style=\"text-align: right;\">   178.2</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  90</td><td style=\"text-align: right;\">             178.2</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:35:11 (running for 00:22:07.62)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         1306.77</td><td style=\"text-align: right;\">1071732</td><td style=\"text-align: right;\">   178.2</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  90</td><td style=\"text-align: right;\">             178.2</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1079730\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-35-15\n",
      "  done: false\n",
      "  episode_len_mean: 179.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 179.52\n",
      "  episode_reward_min: 92.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 6737\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3811511013212160.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.018414942547678947\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018608612939715385\n",
      "          model: {}\n",
      "          policy_loss: 0.0003545522631611675\n",
      "          total_loss: 70926930542592.0\n",
      "          vf_explained_var: 0.7241148352622986\n",
      "          vf_loss: 202.3040008544922\n",
      "    num_agent_steps_sampled: 1079730\n",
      "    num_agent_steps_trained: 1079730\n",
      "    num_steps_sampled: 1079730\n",
      "    num_steps_trained: 1079730\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.00000000000001\n",
      "    ram_util_percent: 17.81428571428572\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09057851323149566\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09158067925669204\n",
      "    mean_inference_ms: 1.002401761452608\n",
      "    mean_raw_obs_processing_ms: 0.11894556067382439\n",
      "  time_since_restore: 1316.786894083023\n",
      "  time_this_iter_s: 10.016625881195068\n",
      "  time_total_s: 1316.786894083023\n",
      "  timers:\n",
      "    learn_throughput: 1298.301\n",
      "    learn_time_ms: 6160.361\n",
      "    load_throughput: 25529713.388\n",
      "    load_time_ms: 0.313\n",
      "    sample_throughput: 823.209\n",
      "    sample_time_ms: 9715.641\n",
      "    update_time_ms: 2.7\n",
      "  timestamp: 1645202115\n",
      "  timesteps_since_restore: 1079730\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1079730\n",
      "  training_iteration: 135\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:35:17 (running for 00:22:13.62)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         1316.79</td><td style=\"text-align: right;\">1079730</td><td style=\"text-align: right;\">  179.52</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">            179.52</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:35:22 (running for 00:22:18.68)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         1316.79</td><td style=\"text-align: right;\">1079730</td><td style=\"text-align: right;\">  179.52</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">            179.52</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1087728\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-35-24\n",
      "  done: false\n",
      "  episode_len_mean: 182.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 182.13\n",
      "  episode_reward_min: 91.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 6779\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3811511013212160.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015504542738199234\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01807515136897564\n",
      "          model: {}\n",
      "          policy_loss: 0.016475969925522804\n",
      "          total_loss: 68893641015296.0\n",
      "          vf_explained_var: 0.7460328340530396\n",
      "          vf_loss: 191.49798583984375\n",
      "    num_agent_steps_sampled: 1087728\n",
      "    num_agent_steps_trained: 1087728\n",
      "    num_steps_sampled: 1087728\n",
      "    num_steps_trained: 1087728\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.90714285714286\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09058894609170735\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09158928310914208\n",
      "    mean_inference_ms: 1.0030282301530986\n",
      "    mean_raw_obs_processing_ms: 0.11901160820228966\n",
      "  time_since_restore: 1326.6712975502014\n",
      "  time_this_iter_s: 9.884403467178345\n",
      "  time_total_s: 1326.6712975502014\n",
      "  timers:\n",
      "    learn_throughput: 1294.549\n",
      "    learn_time_ms: 6178.214\n",
      "    load_throughput: 25025023.045\n",
      "    load_time_ms: 0.32\n",
      "    sample_throughput: 820.806\n",
      "    sample_time_ms: 9744.085\n",
      "    update_time_ms: 2.72\n",
      "  timestamp: 1645202124\n",
      "  timesteps_since_restore: 1087728\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1087728\n",
      "  training_iteration: 136\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:35:27 (running for 00:22:24.52)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         1326.67</td><td style=\"text-align: right;\">1087728</td><td style=\"text-align: right;\">  182.13</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            182.13</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:35:33 (running for 00:22:29.59)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         1326.67</td><td style=\"text-align: right;\">1087728</td><td style=\"text-align: right;\">  182.13</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            182.13</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1095726\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-35-34\n",
      "  done: false\n",
      "  episode_len_mean: 184.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 184.41\n",
      "  episode_reward_min: 91.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 6823\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3811511013212160.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01474702451378107\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02334620989859104\n",
      "          model: {}\n",
      "          policy_loss: 0.006357541307806969\n",
      "          total_loss: 88984332009472.0\n",
      "          vf_explained_var: 0.7564335465431213\n",
      "          vf_loss: 189.60067749023438\n",
      "    num_agent_steps_sampled: 1095726\n",
      "    num_agent_steps_trained: 1095726\n",
      "    num_steps_sampled: 1095726\n",
      "    num_steps_trained: 1095726\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.06428571428573\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09059065714906549\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0915890842451644\n",
      "    mean_inference_ms: 1.0029784021372559\n",
      "    mean_raw_obs_processing_ms: 0.11900990095263474\n",
      "  time_since_restore: 1336.2816622257233\n",
      "  time_this_iter_s: 9.61036467552185\n",
      "  time_total_s: 1336.2816622257233\n",
      "  timers:\n",
      "    learn_throughput: 1296.317\n",
      "    learn_time_ms: 6169.785\n",
      "    load_throughput: 25041835.915\n",
      "    load_time_ms: 0.319\n",
      "    sample_throughput: 819.147\n",
      "    sample_time_ms: 9763.81\n",
      "    update_time_ms: 2.692\n",
      "  timestamp: 1645202134\n",
      "  timesteps_since_restore: 1095726\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1095726\n",
      "  training_iteration: 137\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:35:38 (running for 00:22:35.16)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         1336.28</td><td style=\"text-align: right;\">1095726</td><td style=\"text-align: right;\">  184.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            184.41</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:35:43 (running for 00:22:40.21)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         1336.28</td><td style=\"text-align: right;\">1095726</td><td style=\"text-align: right;\">  184.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            184.41</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1103724\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-35-44\n",
      "  done: false\n",
      "  episode_len_mean: 181.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 181.24\n",
      "  episode_reward_min: 93.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 6868\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5717266654035968.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.013427619822323322\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027323966845870018\n",
      "          model: {}\n",
      "          policy_loss: 0.007358838338404894\n",
      "          total_loss: 156218395983872.0\n",
      "          vf_explained_var: 0.7111720442771912\n",
      "          vf_loss: 239.7683563232422\n",
      "    num_agent_steps_sampled: 1103724\n",
      "    num_agent_steps_trained: 1103724\n",
      "    num_steps_sampled: 1103724\n",
      "    num_steps_trained: 1103724\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.92857142857142\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0905887624674667\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09159400826186054\n",
      "    mean_inference_ms: 1.0022233920015042\n",
      "    mean_raw_obs_processing_ms: 0.1189200136366005\n",
      "  time_since_restore: 1346.029602766037\n",
      "  time_this_iter_s: 9.74794054031372\n",
      "  time_total_s: 1346.029602766037\n",
      "  timers:\n",
      "    learn_throughput: 1292.867\n",
      "    learn_time_ms: 6186.25\n",
      "    load_throughput: 25124358.442\n",
      "    load_time_ms: 0.318\n",
      "    sample_throughput: 820.299\n",
      "    sample_time_ms: 9750.1\n",
      "    update_time_ms: 2.746\n",
      "  timestamp: 1645202144\n",
      "  timesteps_since_restore: 1103724\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1103724\n",
      "  training_iteration: 138\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:35:49 (running for 00:22:45.94)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         1346.03</td><td style=\"text-align: right;\">1103724</td><td style=\"text-align: right;\">  181.24</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  93</td><td style=\"text-align: right;\">            181.24</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1111722\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-35-53\n",
      "  done: false\n",
      "  episode_len_mean: 180.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 180.41\n",
      "  episode_reward_min: 93.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 6911\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8575899712618496.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.013210083357989788\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03478023409843445\n",
      "          model: {}\n",
      "          policy_loss: 0.004542372655123472\n",
      "          total_loss: 298271822053376.0\n",
      "          vf_explained_var: 0.650371789932251\n",
      "          vf_loss: 270.1175537109375\n",
      "    num_agent_steps_sampled: 1111722\n",
      "    num_agent_steps_trained: 1111722\n",
      "    num_steps_sampled: 1111722\n",
      "    num_steps_trained: 1111722\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.22142857142858\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09057951132944428\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09158982824336775\n",
      "    mean_inference_ms: 1.0023440729425857\n",
      "    mean_raw_obs_processing_ms: 0.11891895718069137\n",
      "  time_since_restore: 1355.5517408847809\n",
      "  time_this_iter_s: 9.522138118743896\n",
      "  time_total_s: 1355.5517408847809\n",
      "  timers:\n",
      "    learn_throughput: 1293.697\n",
      "    learn_time_ms: 6182.28\n",
      "    load_throughput: 25580328.955\n",
      "    load_time_ms: 0.313\n",
      "    sample_throughput: 818.856\n",
      "    sample_time_ms: 9767.29\n",
      "    update_time_ms: 2.754\n",
      "  timestamp: 1645202153\n",
      "  timesteps_since_restore: 1111722\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1111722\n",
      "  training_iteration: 139\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:35:54 (running for 00:22:51.47)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         1355.55</td><td style=\"text-align: right;\">1111722</td><td style=\"text-align: right;\">  180.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  93</td><td style=\"text-align: right;\">            180.41</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:35:59 (running for 00:22:56.50)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         1355.55</td><td style=\"text-align: right;\">1111722</td><td style=\"text-align: right;\">  180.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  93</td><td style=\"text-align: right;\">            180.41</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1119720\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-36-03\n",
      "  done: false\n",
      "  episode_len_mean: 178.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 178.27\n",
      "  episode_reward_min: 91.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 6957\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2863850105798656e+16\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.013968272134661674\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026269735768437386\n",
      "          model: {}\n",
      "          policy_loss: 0.009146529249846935\n",
      "          total_loss: 337929939451904.0\n",
      "          vf_explained_var: 0.7256619334220886\n",
      "          vf_loss: 208.42190551757812\n",
      "    num_agent_steps_sampled: 1119720\n",
      "    num_agent_steps_trained: 1119720\n",
      "    num_steps_sampled: 1119720\n",
      "    num_steps_trained: 1119720\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.58571428571427\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09056182709654921\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.091565481717347\n",
      "    mean_inference_ms: 1.0022855442596081\n",
      "    mean_raw_obs_processing_ms: 0.11891695859607278\n",
      "  time_since_restore: 1365.3172070980072\n",
      "  time_this_iter_s: 9.765466213226318\n",
      "  time_total_s: 1365.3172070980072\n",
      "  timers:\n",
      "    learn_throughput: 1292.975\n",
      "    learn_time_ms: 6185.733\n",
      "    load_throughput: 25137537.199\n",
      "    load_time_ms: 0.318\n",
      "    sample_throughput: 819.054\n",
      "    sample_time_ms: 9764.921\n",
      "    update_time_ms: 2.83\n",
      "  timestamp: 1645202163\n",
      "  timesteps_since_restore: 1119720\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1119720\n",
      "  training_iteration: 140\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:36:05 (running for 00:23:02.27)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         1365.32</td><td style=\"text-align: right;\">1119720</td><td style=\"text-align: right;\">  178.27</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            178.27</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:36:10 (running for 00:23:07.30)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         1365.32</td><td style=\"text-align: right;\">1119720</td><td style=\"text-align: right;\">  178.27</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            178.27</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1127718\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-36-13\n",
      "  done: false\n",
      "  episode_len_mean: 170.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 170.62\n",
      "  episode_reward_min: 87.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 7006\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.929577408495616e+16\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01615303009748459\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03454536199569702\n",
      "          model: {}\n",
      "          policy_loss: -0.001189784612506628\n",
      "          total_loss: 666579528318976.0\n",
      "          vf_explained_var: 0.7683669924736023\n",
      "          vf_loss: 169.940185546875\n",
      "    num_agent_steps_sampled: 1127718\n",
      "    num_agent_steps_trained: 1127718\n",
      "    num_steps_sampled: 1127718\n",
      "    num_steps_trained: 1127718\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.76153846153845\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09056519845978084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09156867272490973\n",
      "    mean_inference_ms: 1.0013547972005312\n",
      "    mean_raw_obs_processing_ms: 0.11881287659061249\n",
      "  time_since_restore: 1375.0101299285889\n",
      "  time_this_iter_s: 9.692922830581665\n",
      "  time_total_s: 1375.0101299285889\n",
      "  timers:\n",
      "    learn_throughput: 1296.676\n",
      "    learn_time_ms: 6168.078\n",
      "    load_throughput: 24952427.397\n",
      "    load_time_ms: 0.321\n",
      "    sample_throughput: 818.355\n",
      "    sample_time_ms: 9773.262\n",
      "    update_time_ms: 2.903\n",
      "  timestamp: 1645202173\n",
      "  timesteps_since_restore: 1127718\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1127718\n",
      "  training_iteration: 141\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:36:16 (running for 00:23:12.99)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         1375.01</td><td style=\"text-align: right;\">1127718</td><td style=\"text-align: right;\">  170.62</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            170.62</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:36:21 (running for 00:23:18.01)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         1375.01</td><td style=\"text-align: right;\">1127718</td><td style=\"text-align: right;\">  170.62</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            170.62</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1135716\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-36-23\n",
      "  done: false\n",
      "  episode_len_mean: 170.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 170.31\n",
      "  episode_reward_min: 87.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 7052\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.8943662201176064e+16\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015808507800102234\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03301934152841568\n",
      "          model: {}\n",
      "          policy_loss: -0.0034812563098967075\n",
      "          total_loss: 955700687667200.0\n",
      "          vf_explained_var: 0.7599189281463623\n",
      "          vf_loss: 194.40066528320312\n",
      "    num_agent_steps_sampled: 1135716\n",
      "    num_agent_steps_trained: 1135716\n",
      "    num_steps_sampled: 1135716\n",
      "    num_steps_trained: 1135716\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.85333333333332\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09056714700015778\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09155835247050464\n",
      "    mean_inference_ms: 1.000899663053054\n",
      "    mean_raw_obs_processing_ms: 0.11877883863116777\n",
      "  time_since_restore: 1384.896879196167\n",
      "  time_this_iter_s: 9.886749267578125\n",
      "  time_total_s: 1384.896879196167\n",
      "  timers:\n",
      "    learn_throughput: 1291.421\n",
      "    learn_time_ms: 6193.178\n",
      "    load_throughput: 24808492.377\n",
      "    load_time_ms: 0.322\n",
      "    sample_throughput: 820.807\n",
      "    sample_time_ms: 9744.065\n",
      "    update_time_ms: 2.958\n",
      "  timestamp: 1645202183\n",
      "  timesteps_since_restore: 1135716\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1135716\n",
      "  training_iteration: 142\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:36:27 (running for 00:23:23.91)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">          1384.9</td><td style=\"text-align: right;\">1135716</td><td style=\"text-align: right;\">  170.31</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            170.31</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:36:32 (running for 00:23:28.93)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">          1384.9</td><td style=\"text-align: right;\">1135716</td><td style=\"text-align: right;\">  170.31</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            170.31</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1143714\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-36-33\n",
      "  done: false\n",
      "  episode_len_mean: 177.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 177.74\n",
      "  episode_reward_min: 87.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 7095\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.341549222802227e+16\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.017490537837147713\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03271690383553505\n",
      "          model: {}\n",
      "          policy_loss: 0.010284353978931904\n",
      "          total_loss: 1420420712497152.0\n",
      "          vf_explained_var: 0.7362378239631653\n",
      "          vf_loss: 198.7538299560547\n",
      "    num_agent_steps_sampled: 1143714\n",
      "    num_agent_steps_trained: 1143714\n",
      "    num_steps_sampled: 1143714\n",
      "    num_steps_trained: 1143714\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.32142857142857\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0905591973162911\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09154435592755206\n",
      "    mean_inference_ms: 1.0018689262065974\n",
      "    mean_raw_obs_processing_ms: 0.11889264276417282\n",
      "  time_since_restore: 1395.0338609218597\n",
      "  time_this_iter_s: 10.136981725692749\n",
      "  time_total_s: 1395.0338609218597\n",
      "  timers:\n",
      "    learn_throughput: 1284.75\n",
      "    learn_time_ms: 6225.335\n",
      "    load_throughput: 24552472.658\n",
      "    load_time_ms: 0.326\n",
      "    sample_throughput: 817.524\n",
      "    sample_time_ms: 9783.197\n",
      "    update_time_ms: 2.931\n",
      "  timestamp: 1645202193\n",
      "  timesteps_since_restore: 1143714\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1143714\n",
      "  training_iteration: 143\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:36:37 (running for 00:23:34.07)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         1395.03</td><td style=\"text-align: right;\">1143714</td><td style=\"text-align: right;\">  177.74</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            177.74</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:36:42 (running for 00:23:39.10)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         1395.03</td><td style=\"text-align: right;\">1143714</td><td style=\"text-align: right;\">  177.74</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            177.74</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1151712\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-36-43\n",
      "  done: false\n",
      "  episode_len_mean: 182.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 182.64\n",
      "  episode_reward_min: 88.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 7139\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 6.512324048951706e+16\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01839900203049183\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03685648366808891\n",
      "          model: {}\n",
      "          policy_loss: 0.009186402894556522\n",
      "          total_loss: 2400213750775808.0\n",
      "          vf_explained_var: 0.7375677227973938\n",
      "          vf_loss: 199.96380615234375\n",
      "    num_agent_steps_sampled: 1151712\n",
      "    num_agent_steps_trained: 1151712\n",
      "    num_steps_sampled: 1151712\n",
      "    num_steps_trained: 1151712\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.35000000000001\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09055988316828514\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09154735072167203\n",
      "    mean_inference_ms: 1.0024533997977634\n",
      "    mean_raw_obs_processing_ms: 0.11894282392585946\n",
      "  time_since_restore: 1405.0567677021027\n",
      "  time_this_iter_s: 10.02290678024292\n",
      "  time_total_s: 1405.0567677021027\n",
      "  timers:\n",
      "    learn_throughput: 1278.205\n",
      "    learn_time_ms: 6257.214\n",
      "    load_throughput: 24937588.011\n",
      "    load_time_ms: 0.321\n",
      "    sample_throughput: 814.219\n",
      "    sample_time_ms: 9822.905\n",
      "    update_time_ms: 2.89\n",
      "  timestamp: 1645202203\n",
      "  timesteps_since_restore: 1151712\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1151712\n",
      "  training_iteration: 144\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:36:47 (running for 00:23:44.15)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         1405.06</td><td style=\"text-align: right;\">1151712</td><td style=\"text-align: right;\">  182.64</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  88</td><td style=\"text-align: right;\">            182.64</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:36:52 (running for 00:23:49.18)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         1405.06</td><td style=\"text-align: right;\">1151712</td><td style=\"text-align: right;\">  182.64</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  88</td><td style=\"text-align: right;\">            182.64</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1159710\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-36-53\n",
      "  done: false\n",
      "  episode_len_mean: 181.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 181.17\n",
      "  episode_reward_min: 88.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 7182\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 9.768485643930829e+16\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01699572615325451\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027803227305412292\n",
      "          model: {}\n",
      "          policy_loss: 0.014300989918410778\n",
      "          total_loss: 2715954513444864.0\n",
      "          vf_explained_var: 0.7391105890274048\n",
      "          vf_loss: 196.02940368652344\n",
      "    num_agent_steps_sampled: 1159710\n",
      "    num_agent_steps_trained: 1159710\n",
      "    num_steps_sampled: 1159710\n",
      "    num_steps_trained: 1159710\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.49999999999999\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09055846113517665\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09154093332823127\n",
      "    mean_inference_ms: 1.0019196569671296\n",
      "    mean_raw_obs_processing_ms: 0.11888106445486471\n",
      "  time_since_restore: 1414.495934009552\n",
      "  time_this_iter_s: 9.43916630744934\n",
      "  time_total_s: 1414.495934009552\n",
      "  timers:\n",
      "    learn_throughput: 1287.94\n",
      "    learn_time_ms: 6209.914\n",
      "    load_throughput: 25098042.34\n",
      "    load_time_ms: 0.319\n",
      "    sample_throughput: 812.484\n",
      "    sample_time_ms: 9843.892\n",
      "    update_time_ms: 2.932\n",
      "  timestamp: 1645202213\n",
      "  timesteps_since_restore: 1159710\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1159710\n",
      "  training_iteration: 145\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:36:58 (running for 00:23:54.63)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">          1414.5</td><td style=\"text-align: right;\">1159710</td><td style=\"text-align: right;\">  181.17</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  88</td><td style=\"text-align: right;\">            181.17</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1167708\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-37-02\n",
      "  done: false\n",
      "  episode_len_mean: 179.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 179.46\n",
      "  episode_reward_min: 91.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 7228\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.4652729324889702e+17\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.019396919757127762\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02698495425283909\n",
      "          model: {}\n",
      "          policy_loss: 0.007660800125449896\n",
      "          total_loss: 3954033060478976.0\n",
      "          vf_explained_var: 0.6894116401672363\n",
      "          vf_loss: 216.33944702148438\n",
      "    num_agent_steps_sampled: 1167708\n",
      "    num_agent_steps_trained: 1167708\n",
      "    num_steps_sampled: 1167708\n",
      "    num_steps_trained: 1167708\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.60714285714286\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0905524287250035\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09153891721804332\n",
      "    mean_inference_ms: 1.0015873651000904\n",
      "    mean_raw_obs_processing_ms: 0.1188324319543596\n",
      "  time_since_restore: 1424.3866338729858\n",
      "  time_this_iter_s: 9.890699863433838\n",
      "  time_total_s: 1424.3866338729858\n",
      "  timers:\n",
      "    learn_throughput: 1286.423\n",
      "    learn_time_ms: 6217.24\n",
      "    load_throughput: 25356041.868\n",
      "    load_time_ms: 0.315\n",
      "    sample_throughput: 816.964\n",
      "    sample_time_ms: 9789.901\n",
      "    update_time_ms: 2.959\n",
      "  timestamp: 1645202222\n",
      "  timesteps_since_restore: 1167708\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1167708\n",
      "  training_iteration: 146\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:37:03 (running for 00:24:00.49)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         1424.39</td><td style=\"text-align: right;\">1167708</td><td style=\"text-align: right;\">  179.46</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            179.46</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:37:09 (running for 00:24:05.57)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         1424.39</td><td style=\"text-align: right;\">1167708</td><td style=\"text-align: right;\">  179.46</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            179.46</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1175706\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-37-12\n",
      "  done: false\n",
      "  episode_len_mean: 179.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 179.52\n",
      "  episode_reward_min: 87.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 7272\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.1979093128341094e+17\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.014992945827543736\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0229206420481205\n",
      "          model: {}\n",
      "          policy_loss: 0.01014819648116827\n",
      "          total_loss: 5037748066975744.0\n",
      "          vf_explained_var: 0.7656106352806091\n",
      "          vf_loss: 184.6363983154297\n",
      "    num_agent_steps_sampled: 1175706\n",
      "    num_agent_steps_trained: 1175706\n",
      "    num_steps_sampled: 1175706\n",
      "    num_steps_trained: 1175706\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.10714285714285\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09055483269928075\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09153217763449564\n",
      "    mean_inference_ms: 1.001722958553878\n",
      "    mean_raw_obs_processing_ms: 0.11885459829925772\n",
      "  time_since_restore: 1434.3198957443237\n",
      "  time_this_iter_s: 9.93326187133789\n",
      "  time_total_s: 1434.3198957443237\n",
      "  timers:\n",
      "    learn_throughput: 1281.959\n",
      "    learn_time_ms: 6238.889\n",
      "    load_throughput: 25537487.357\n",
      "    load_time_ms: 0.313\n",
      "    sample_throughput: 815.422\n",
      "    sample_time_ms: 9808.418\n",
      "    update_time_ms: 2.942\n",
      "  timestamp: 1645202232\n",
      "  timesteps_since_restore: 1175706\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1175706\n",
      "  training_iteration: 147\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:37:14 (running for 00:24:11.45)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         1434.32</td><td style=\"text-align: right;\">1175706</td><td style=\"text-align: right;\">  179.52</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            179.52</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:37:19 (running for 00:24:16.51)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         1434.32</td><td style=\"text-align: right;\">1175706</td><td style=\"text-align: right;\">  179.52</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">            179.52</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1183704\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-37-22\n",
      "  done: false\n",
      "  episode_len_mean: 179.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 179.3\n",
      "  episode_reward_min: 87.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 7316\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.296863969251164e+17\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.016490168869495392\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023954343050718307\n",
      "          model: {}\n",
      "          policy_loss: 0.01017394196242094\n",
      "          total_loss: 7897419970772992.0\n",
      "          vf_explained_var: 0.6557630300521851\n",
      "          vf_loss: 262.4823303222656\n",
      "    num_agent_steps_sampled: 1183704\n",
      "    num_agent_steps_trained: 1183704\n",
      "    num_steps_sampled: 1183704\n",
      "    num_steps_trained: 1183704\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.52857142857142\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09056115824996126\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09154291784218445\n",
      "    mean_inference_ms: 1.002179488729753\n",
      "    mean_raw_obs_processing_ms: 0.11887680029591617\n",
      "  time_since_restore: 1443.9414942264557\n",
      "  time_this_iter_s: 9.621598482131958\n",
      "  time_total_s: 1443.9414942264557\n",
      "  timers:\n",
      "    learn_throughput: 1285.364\n",
      "    learn_time_ms: 6222.362\n",
      "    load_throughput: 25373302.619\n",
      "    load_time_ms: 0.315\n",
      "    sample_throughput: 813.336\n",
      "    sample_time_ms: 9833.573\n",
      "    update_time_ms: 3.013\n",
      "  timestamp: 1645202242\n",
      "  timesteps_since_restore: 1183704\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1183704\n",
      "  training_iteration: 148\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:37:25 (running for 00:24:22.11)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         1443.94</td><td style=\"text-align: right;\">1183704</td><td style=\"text-align: right;\">   179.3</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">             179.3</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:37:30 (running for 00:24:27.17)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         1443.94</td><td style=\"text-align: right;\">1183704</td><td style=\"text-align: right;\">   179.3</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">             179.3</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1191702\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-37-32\n",
      "  done: false\n",
      "  episode_len_mean: 181.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 181.22\n",
      "  episode_reward_min: 93.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 7361\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.945296125675438e+17\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01635121926665306\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030274951830506325\n",
      "          model: {}\n",
      "          policy_loss: 0.0006429640343412757\n",
      "          total_loss: 1.4971861930606592e+16\n",
      "          vf_explained_var: 0.7364036440849304\n",
      "          vf_loss: 217.96978759765625\n",
      "    num_agent_steps_sampled: 1191702\n",
      "    num_agent_steps_trained: 1191702\n",
      "    num_steps_sampled: 1191702\n",
      "    num_steps_trained: 1191702\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.5857142857143\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09055350816870987\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09154625656701686\n",
      "    mean_inference_ms: 1.002002096045068\n",
      "    mean_raw_obs_processing_ms: 0.11883568076649714\n",
      "  time_since_restore: 1453.6164209842682\n",
      "  time_this_iter_s: 9.6749267578125\n",
      "  time_total_s: 1453.6164209842682\n",
      "  timers:\n",
      "    learn_throughput: 1282.259\n",
      "    learn_time_ms: 6237.428\n",
      "    load_throughput: 25094287.397\n",
      "    load_time_ms: 0.319\n",
      "    sample_throughput: 814.679\n",
      "    sample_time_ms: 9817.368\n",
      "    update_time_ms: 3.067\n",
      "  timestamp: 1645202252\n",
      "  timesteps_since_restore: 1191702\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1191702\n",
      "  training_iteration: 149\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:37:36 (running for 00:24:32.81)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         1453.62</td><td style=\"text-align: right;\">1191702</td><td style=\"text-align: right;\">  181.22</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  93</td><td style=\"text-align: right;\">            181.22</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:37:41 (running for 00:24:37.86)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         1453.62</td><td style=\"text-align: right;\">1191702</td><td style=\"text-align: right;\">  181.22</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  93</td><td style=\"text-align: right;\">            181.22</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1199700\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-37-42\n",
      "  done: false\n",
      "  episode_len_mean: 177.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 177.18\n",
      "  episode_reward_min: 93.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 7407\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 7.417943844915773e+17\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015611285343766212\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01706974022090435\n",
      "          model: {}\n",
      "          policy_loss: 0.00880836509168148\n",
      "          total_loss: 1.2662236824731648e+16\n",
      "          vf_explained_var: 0.7216398119926453\n",
      "          vf_loss: 195.787841796875\n",
      "    num_agent_steps_sampled: 1199700\n",
      "    num_agent_steps_trained: 1199700\n",
      "    num_steps_sampled: 1199700\n",
      "    num_steps_trained: 1199700\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.69999999999997\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09055099343665908\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09154091989606178\n",
      "    mean_inference_ms: 1.0017918463025\n",
      "    mean_raw_obs_processing_ms: 0.1188173787775181\n",
      "  time_since_restore: 1463.4569866657257\n",
      "  time_this_iter_s: 9.84056568145752\n",
      "  time_total_s: 1463.4569866657257\n",
      "  timers:\n",
      "    learn_throughput: 1284.38\n",
      "    learn_time_ms: 6227.128\n",
      "    load_throughput: 25434864.957\n",
      "    load_time_ms: 0.314\n",
      "    sample_throughput: 811.99\n",
      "    sample_time_ms: 9849.874\n",
      "    update_time_ms: 2.988\n",
      "  timestamp: 1645202262\n",
      "  timesteps_since_restore: 1199700\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1199700\n",
      "  training_iteration: 150\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:37:47 (running for 00:24:43.68)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         1463.46</td><td style=\"text-align: right;\">1199700</td><td style=\"text-align: right;\">  177.18</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  93</td><td style=\"text-align: right;\">            177.18</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1207698\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-37-51\n",
      "  done: false\n",
      "  episode_len_mean: 179.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 179.28\n",
      "  episode_reward_min: 91.0\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 7451\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 7.417943844915773e+17\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.014438859187066555\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02580190636217594\n",
      "          model: {}\n",
      "          policy_loss: 0.008952069096267223\n",
      "          total_loss: 1.913970785832141e+16\n",
      "          vf_explained_var: 0.7064846754074097\n",
      "          vf_loss: 194.0294647216797\n",
      "    num_agent_steps_sampled: 1207698\n",
      "    num_agent_steps_trained: 1207698\n",
      "    num_steps_sampled: 1207698\n",
      "    num_steps_trained: 1207698\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.42857142857143\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09055204995286392\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09154407603233089\n",
      "    mean_inference_ms: 1.0019853436513788\n",
      "    mean_raw_obs_processing_ms: 0.11882459470819509\n",
      "  time_since_restore: 1473.1040337085724\n",
      "  time_this_iter_s: 9.64704704284668\n",
      "  time_total_s: 1473.1040337085724\n",
      "  timers:\n",
      "    learn_throughput: 1282.034\n",
      "    learn_time_ms: 6238.525\n",
      "    load_throughput: 25568630.634\n",
      "    load_time_ms: 0.313\n",
      "    sample_throughput: 814.151\n",
      "    sample_time_ms: 9823.733\n",
      "    update_time_ms: 2.869\n",
      "  timestamp: 1645202271\n",
      "  timesteps_since_restore: 1207698\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1207698\n",
      "  training_iteration: 151\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:37:52 (running for 00:24:49.34)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">          1473.1</td><td style=\"text-align: right;\">1207698</td><td style=\"text-align: right;\">  179.28</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            179.28</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:37:57 (running for 00:24:54.36)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">          1473.1</td><td style=\"text-align: right;\">1207698</td><td style=\"text-align: right;\">  179.28</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  91</td><td style=\"text-align: right;\">            179.28</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1215696\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-38-01\n",
      "  done: false\n",
      "  episode_len_mean: 171.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 171.22\n",
      "  episode_reward_min: 89.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 7500\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1126916110971044e+18\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.010809448547661304\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03047117590904236\n",
      "          model: {}\n",
      "          policy_loss: 0.008219761773943901\n",
      "          total_loss: 3.3905023737921536e+16\n",
      "          vf_explained_var: 0.7013986706733704\n",
      "          vf_loss: 232.9622344970703\n",
      "    num_agent_steps_sampled: 1215696\n",
      "    num_agent_steps_trained: 1215696\n",
      "    num_steps_sampled: 1215696\n",
      "    num_steps_trained: 1215696\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.62142857142857\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09055309296232433\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09154373078132838\n",
      "    mean_inference_ms: 1.0013964859249398\n",
      "    mean_raw_obs_processing_ms: 0.11876359794409455\n",
      "  time_since_restore: 1483.0355253219604\n",
      "  time_this_iter_s: 9.931491613388062\n",
      "  time_total_s: 1483.0355253219604\n",
      "  timers:\n",
      "    learn_throughput: 1281.615\n",
      "    learn_time_ms: 6240.564\n",
      "    load_throughput: 26113999.215\n",
      "    load_time_ms: 0.306\n",
      "    sample_throughput: 813.02\n",
      "    sample_time_ms: 9837.396\n",
      "    update_time_ms: 2.835\n",
      "  timestamp: 1645202281\n",
      "  timesteps_since_restore: 1215696\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1215696\n",
      "  training_iteration: 152\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:38:03 (running for 00:25:00.30)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         1483.04</td><td style=\"text-align: right;\">1215696</td><td style=\"text-align: right;\">  171.22</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            171.22</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:38:08 (running for 00:25:05.32)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         1483.04</td><td style=\"text-align: right;\">1215696</td><td style=\"text-align: right;\">  171.22</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            171.22</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1223694\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-38-11\n",
      "  done: false\n",
      "  episode_len_mean: 170.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 170.91\n",
      "  episode_reward_min: 83.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 7546\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.6690373479261798e+18\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.012686069123446941\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03850838541984558\n",
      "          model: {}\n",
      "          policy_loss: 0.002192961983382702\n",
      "          total_loss: 6.42719350217769e+16\n",
      "          vf_explained_var: 0.7452660202980042\n",
      "          vf_loss: 196.0088348388672\n",
      "    num_agent_steps_sampled: 1223694\n",
      "    num_agent_steps_trained: 1223694\n",
      "    num_steps_sampled: 1223694\n",
      "    num_steps_trained: 1223694\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.75714285714285\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09055861983591815\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09155287669808082\n",
      "    mean_inference_ms: 1.0010864577024288\n",
      "    mean_raw_obs_processing_ms: 0.11872917244046494\n",
      "  time_since_restore: 1493.056039571762\n",
      "  time_this_iter_s: 10.020514249801636\n",
      "  time_total_s: 1493.056039571762\n",
      "  timers:\n",
      "    learn_throughput: 1283.004\n",
      "    learn_time_ms: 6233.81\n",
      "    load_throughput: 26028897.728\n",
      "    load_time_ms: 0.307\n",
      "    sample_throughput: 813.25\n",
      "    sample_time_ms: 9834.618\n",
      "    update_time_ms: 2.818\n",
      "  timestamp: 1645202291\n",
      "  timesteps_since_restore: 1223694\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1223694\n",
      "  training_iteration: 153\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:38:13 (running for 00:25:10.35)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         1493.06</td><td style=\"text-align: right;\">1223694</td><td style=\"text-align: right;\">  170.91</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            170.91</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:38:18 (running for 00:25:15.37)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         1493.06</td><td style=\"text-align: right;\">1223694</td><td style=\"text-align: right;\">  170.91</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            170.91</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1231692\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-38-21\n",
      "  done: false\n",
      "  episode_len_mean: 173.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 173.68\n",
      "  episode_reward_min: 83.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 7591\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.5035560906087465e+18\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01103411428630352\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030684595927596092\n",
      "          model: {}\n",
      "          policy_loss: 0.00362611492164433\n",
      "          total_loss: 7.682060110004224e+16\n",
      "          vf_explained_var: 0.7100272178649902\n",
      "          vf_loss: 220.3341064453125\n",
      "    num_agent_steps_sampled: 1231692\n",
      "    num_agent_steps_trained: 1231692\n",
      "    num_steps_sampled: 1231692\n",
      "    num_steps_trained: 1231692\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.37142857142858\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0905621114585205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09155667005236787\n",
      "    mean_inference_ms: 1.0016439401271202\n",
      "    mean_raw_obs_processing_ms: 0.1187897752160415\n",
      "  time_since_restore: 1502.6226105690002\n",
      "  time_this_iter_s: 9.56657099723816\n",
      "  time_total_s: 1502.6226105690002\n",
      "  timers:\n",
      "    learn_throughput: 1291.438\n",
      "    learn_time_ms: 6193.099\n",
      "    load_throughput: 26020821.744\n",
      "    load_time_ms: 0.307\n",
      "    sample_throughput: 814.212\n",
      "    sample_time_ms: 9822.999\n",
      "    update_time_ms: 2.827\n",
      "  timestamp: 1645202301\n",
      "  timesteps_since_restore: 1231692\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1231692\n",
      "  training_iteration: 154\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:38:24 (running for 00:25:20.94)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">         1502.62</td><td style=\"text-align: right;\">1231692</td><td style=\"text-align: right;\">  173.68</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            173.68</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:38:29 (running for 00:25:25.96)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">         1502.62</td><td style=\"text-align: right;\">1231692</td><td style=\"text-align: right;\">  173.68</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            173.68</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1239690\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-38-31\n",
      "  done: false\n",
      "  episode_len_mean: 172.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 172.39\n",
      "  episode_reward_min: 83.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 7639\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.75533413591312e+18\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.011605813167989254\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0336027592420578\n",
      "          model: {}\n",
      "          policy_loss: 0.004290419165045023\n",
      "          total_loss: 1.261895837202514e+17\n",
      "          vf_explained_var: 0.7568633556365967\n",
      "          vf_loss: 184.86053466796875\n",
      "    num_agent_steps_sampled: 1239690\n",
      "    num_agent_steps_trained: 1239690\n",
      "    num_steps_sampled: 1239690\n",
      "    num_steps_trained: 1239690\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.72142857142856\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09056362539652012\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09155793875580695\n",
      "    mean_inference_ms: 1.0016271024559609\n",
      "    mean_raw_obs_processing_ms: 0.1187957816602692\n",
      "  time_since_restore: 1512.3028631210327\n",
      "  time_this_iter_s: 9.68025255203247\n",
      "  time_total_s: 1512.3028631210327\n",
      "  timers:\n",
      "    learn_throughput: 1286.36\n",
      "    learn_time_ms: 6217.546\n",
      "    load_throughput: 25607666.711\n",
      "    load_time_ms: 0.312\n",
      "    sample_throughput: 817.626\n",
      "    sample_time_ms: 9781.983\n",
      "    update_time_ms: 2.764\n",
      "  timestamp: 1645202311\n",
      "  timesteps_since_restore: 1239690\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1239690\n",
      "  training_iteration: 155\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:38:35 (running for 00:25:31.65)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">          1512.3</td><td style=\"text-align: right;\">1239690</td><td style=\"text-align: right;\">  172.39</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            172.39</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:38:40 (running for 00:25:36.67)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">          1512.3</td><td style=\"text-align: right;\">1239690</td><td style=\"text-align: right;\">  172.39</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            172.39</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1247688\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-38-41\n",
      "  done: false\n",
      "  episode_len_mean: 166.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 166.36\n",
      "  episode_reward_min: 83.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 7687\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5.633001478747587e+18\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.012033025734126568\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024735579267144203\n",
      "          model: {}\n",
      "          policy_loss: 0.007380693685263395\n",
      "          total_loss: 1.3933556808024064e+17\n",
      "          vf_explained_var: 0.7816802859306335\n",
      "          vf_loss: 179.41720581054688\n",
      "    num_agent_steps_sampled: 1247688\n",
      "    num_agent_steps_trained: 1247688\n",
      "    num_steps_sampled: 1247688\n",
      "    num_steps_trained: 1247688\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.55\n",
      "    ram_util_percent: 17.828571428571433\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09056547995969344\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09155755458895103\n",
      "    mean_inference_ms: 1.0010068892024018\n",
      "    mean_raw_obs_processing_ms: 0.1187375193697516\n",
      "  time_since_restore: 1522.2177016735077\n",
      "  time_this_iter_s: 9.914838552474976\n",
      "  time_total_s: 1522.2177016735077\n",
      "  timers:\n",
      "    learn_throughput: 1285.27\n",
      "    learn_time_ms: 6222.818\n",
      "    load_throughput: 25836447.468\n",
      "    load_time_ms: 0.31\n",
      "    sample_throughput: 815.845\n",
      "    sample_time_ms: 9803.332\n",
      "    update_time_ms: 2.767\n",
      "  timestamp: 1645202321\n",
      "  timesteps_since_restore: 1247688\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1247688\n",
      "  training_iteration: 156\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:38:46 (running for 00:25:42.64)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   156</td><td style=\"text-align: right;\">         1522.22</td><td style=\"text-align: right;\">1247688</td><td style=\"text-align: right;\">  166.36</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">            166.36</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1255686\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-38-50\n",
      "  done: false\n",
      "  episode_len_mean: 165.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 165.03\n",
      "  episode_reward_min: 78.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 7734\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8.449501668365566e+18\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.014418575912714005\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028792323544621468\n",
      "          model: {}\n",
      "          policy_loss: 0.004602114204317331\n",
      "          total_loss: 2.432807946200023e+17\n",
      "          vf_explained_var: 0.6207066774368286\n",
      "          vf_loss: 264.4349060058594\n",
      "    num_agent_steps_sampled: 1255686\n",
      "    num_agent_steps_trained: 1255686\n",
      "    num_steps_sampled: 1255686\n",
      "    num_steps_trained: 1255686\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.95384615384616\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09055195088717906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09153698619775731\n",
      "    mean_inference_ms: 1.000971735473634\n",
      "    mean_raw_obs_processing_ms: 0.11874316528006519\n",
      "  time_since_restore: 1531.6962859630585\n",
      "  time_this_iter_s: 9.478584289550781\n",
      "  time_total_s: 1531.6962859630585\n",
      "  timers:\n",
      "    learn_throughput: 1291.193\n",
      "    learn_time_ms: 6194.27\n",
      "    load_throughput: 25363710.413\n",
      "    load_time_ms: 0.315\n",
      "    sample_throughput: 816.828\n",
      "    sample_time_ms: 9791.531\n",
      "    update_time_ms: 2.752\n",
      "  timestamp: 1645202330\n",
      "  timesteps_since_restore: 1255686\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1255686\n",
      "  training_iteration: 157\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:38:51 (running for 00:25:48.13)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">          1531.7</td><td style=\"text-align: right;\">1255686</td><td style=\"text-align: right;\">  165.03</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            165.03</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:38:56 (running for 00:25:53.15)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">          1531.7</td><td style=\"text-align: right;\">1255686</td><td style=\"text-align: right;\">  165.03</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            165.03</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1263684\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-39-00\n",
      "  done: false\n",
      "  episode_len_mean: 165.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 165.92\n",
      "  episode_reward_min: 78.0\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 7784\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2674253052304163e+19\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.014729836024343967\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028266459703445435\n",
      "          model: {}\n",
      "          policy_loss: -0.0004524744872469455\n",
      "          total_loss: 3.5825627885993984e+17\n",
      "          vf_explained_var: 0.7224758863449097\n",
      "          vf_loss: 178.37562561035156\n",
      "    num_agent_steps_sampled: 1263684\n",
      "    num_agent_steps_trained: 1263684\n",
      "    num_steps_sampled: 1263684\n",
      "    num_steps_trained: 1263684\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.2357142857143\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09053493155150776\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09150712390110474\n",
      "    mean_inference_ms: 1.0007190764902405\n",
      "    mean_raw_obs_processing_ms: 0.11872673892166155\n",
      "  time_since_restore: 1541.2397162914276\n",
      "  time_this_iter_s: 9.54343032836914\n",
      "  time_total_s: 1541.2397162914276\n",
      "  timers:\n",
      "    learn_throughput: 1293.437\n",
      "    learn_time_ms: 6183.526\n",
      "    load_throughput: 25197959.432\n",
      "    load_time_ms: 0.317\n",
      "    sample_throughput: 818.947\n",
      "    sample_time_ms: 9766.194\n",
      "    update_time_ms: 2.698\n",
      "  timestamp: 1645202340\n",
      "  timesteps_since_restore: 1263684\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1263684\n",
      "  training_iteration: 158\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:39:02 (running for 00:25:58.69)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         1541.24</td><td style=\"text-align: right;\">1263684</td><td style=\"text-align: right;\">  165.92</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            165.92</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:39:07 (running for 00:26:03.71)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         1541.24</td><td style=\"text-align: right;\">1263684</td><td style=\"text-align: right;\">  165.92</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            165.92</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1271682\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-39-09\n",
      "  done: false\n",
      "  episode_len_mean: 172.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 172.75\n",
      "  episode_reward_min: 78.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 7826\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.9011378478944616e+19\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.017637375742197037\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029657237231731415\n",
      "          model: {}\n",
      "          policy_loss: 0.003600837429985404\n",
      "          total_loss: 5.6382499287832986e+17\n",
      "          vf_explained_var: 0.7230594754219055\n",
      "          vf_loss: 185.13571166992188\n",
      "    num_agent_steps_sampled: 1271682\n",
      "    num_agent_steps_trained: 1271682\n",
      "    num_steps_sampled: 1271682\n",
      "    num_steps_trained: 1271682\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.5857142857143\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09052160386619644\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09149080590951476\n",
      "    mean_inference_ms: 1.000949475283534\n",
      "    mean_raw_obs_processing_ms: 0.11874428085279991\n",
      "  time_since_restore: 1550.7114007472992\n",
      "  time_this_iter_s: 9.471684455871582\n",
      "  time_total_s: 1550.7114007472992\n",
      "  timers:\n",
      "    learn_throughput: 1297.542\n",
      "    learn_time_ms: 6163.961\n",
      "    load_throughput: 25440651.746\n",
      "    load_time_ms: 0.314\n",
      "    sample_throughput: 819.916\n",
      "    sample_time_ms: 9754.658\n",
      "    update_time_ms: 2.64\n",
      "  timestamp: 1645202349\n",
      "  timesteps_since_restore: 1271682\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1271682\n",
      "  training_iteration: 159\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:39:12 (running for 00:26:09.20)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         1550.71</td><td style=\"text-align: right;\">1271682</td><td style=\"text-align: right;\">  172.75</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            172.75</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:39:17 (running for 00:26:14.23)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>RUNNING </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         1550.71</td><td style=\"text-align: right;\">1271682</td><td style=\"text-align: right;\">  172.75</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            172.75</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1279680\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-39-19\n",
      "  done: false\n",
      "  episode_len_mean: 175.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.96\n",
      "  episode_reward_min: 78.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 7875\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.8517067718416925e+19\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015109116211533546\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.07243618369102478\n",
      "          model: {}\n",
      "          policy_loss: 0.003030304564163089\n",
      "          total_loss: 2.0656677508266066e+18\n",
      "          vf_explained_var: 0.6918275952339172\n",
      "          vf_loss: 228.48342895507812\n",
      "    num_agent_steps_sampled: 1279680\n",
      "    num_agent_steps_trained: 1279680\n",
      "    num_steps_sampled: 1279680\n",
      "    num_steps_trained: 1279680\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.55714285714286\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09051457712037003\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09149510401133412\n",
      "    mean_inference_ms: 1.000996604164137\n",
      "    mean_raw_obs_processing_ms: 0.11872254066646316\n",
      "  time_since_restore: 1560.4129700660706\n",
      "  time_this_iter_s: 9.701569318771362\n",
      "  time_total_s: 1560.4129700660706\n",
      "  timers:\n",
      "    learn_throughput: 1298.431\n",
      "    learn_time_ms: 6159.742\n",
      "    load_throughput: 25502541.73\n",
      "    load_time_ms: 0.314\n",
      "    sample_throughput: 822.348\n",
      "    sample_time_ms: 9725.806\n",
      "    update_time_ms: 2.67\n",
      "  timestamp: 1645202359\n",
      "  timesteps_since_restore: 1279680\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1279680\n",
      "  training_iteration: 160\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 16:39:19,712\tWARNING worker.py:1257 -- Traceback (most recent call last):\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
      "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
      "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\t [[{{node default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 670, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 636, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 640, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 589, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "    return next(self.local_it)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 382, in gen_rollouts\n",
      "    yield self.sample()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 761, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 104, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 266, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 657, in _env_runner\n",
      "    eval_results = _do_policy_eval(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 1077, in _do_policy_eval\n",
      "    policy.compute_actions_from_input_dict(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py\", line 301, in compute_actions_from_input_dict\n",
      "    fetched = builder.get(to_fetch)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 48, in get\n",
      "    raise e\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "    self._executed = run_timeline(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 92, in run_timeline\n",
      "    fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "    results = self._do_run(handle, final_targets, final_fetches,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n",
      "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1396, in _do_call\n",
      "    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "      ray.worker.global_worker.main_loop()\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "      self.core_worker.run_task_loop()\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "      return method(__ray_actor, *args, **kwargs)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "      return method(self, *_args, **_kwargs)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "      self._build_policy_map(\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "      return method(self, *_args, **_kwargs)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "      self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "      self[policy_id] = class_(\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "      DynamicTFPolicy.__init__(\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "      action_dist = dist_class(dist_inputs, self.model)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "      super().__init__(inputs / temperature, model)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "      self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "      return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "Node: 'default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\n",
      "Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\t [[{{node default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\n",
      "Original stack trace for 'default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "    ray.worker.global_worker.main_loop()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "    self.core_worker.run_task_loop()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "    self._build_policy_map(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "    self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "    self[policy_id] = class_(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "    DynamicTFPolicy.__init__(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "    action_dist = dist_class(dist_inputs, self.model)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "    super().__init__(inputs / temperature, model)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "    self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "    return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4425, in sparse_softmax_cross_entropy_with_logits_v2\n",
      "    return sparse_softmax_cross_entropy_with_logits(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4338, in sparse_softmax_cross_entropy_with_logits\n",
      "    cost = _sparse_softmax_cross_entropy_with_rank_2_logits(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4237, in _sparse_softmax_cross_entropy_with_rank_2_logits\n",
      "    cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 11338, in sparse_softmax_cross_entropy_with_logits\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 740, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3776, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\n",
      "    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 770, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 591, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 725, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1953, in ray._raylet.CoreWorker.store_task_outputs\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/serialization.py\", line 367, in serialize\n",
      "    return self._serialize_to_msgpack(value)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/serialization.py\", line 323, in _serialize_to_msgpack\n",
      "    value = value.to_bytes()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/exceptions.py\", line 22, in to_bytes\n",
      "    serialized_exception=pickle.dumps(self),\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\", line 73, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\", line 620, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "TypeError: cannot pickle '_thread.RLock' object\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m 2022-02-18 16:39:19,697\tERROR tf_run_builder.py:46 -- Error fetching: [<tf.Tensor 'default_policy_wk2/cond_1/Merge:0' shape=(?,) dtype=int64>, {'action_prob': <tf.Tensor 'default_policy_wk2/Exp:0' shape=(?,) dtype=float32>, 'action_logp': <tf.Tensor 'default_policy_wk2/cond_2/Merge:0' shape=(?,) dtype=float32>, 'action_dist_inputs': <tf.Tensor 'default_policy_wk2/model/fc_out/BiasAdd:0' shape=(?, 2) dtype=float32>, 'vf_preds': <tf.Tensor 'default_policy_wk2/Reshape:0' shape=(?,) dtype=float32>}], feed_dict={<tf.Tensor 'default_policy_wk2/obs:0' shape=(?, 4) dtype=float32>: array([[-0.19326799, -0.04152026, -0.00322891, -0.08780944]],\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       dtype=float32), <tf.Tensor 'default_policy_wk2/is_training:0' shape=() dtype=bool>: False, <tf.Tensor 'default_policy_wk2/is_exploring:0' shape=() dtype=bool>: True, <tf.Tensor 'default_policy_wk2/timestep:0' shape=() dtype=int64>: 1279680}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return fn(*args)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \t [[{{node default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self._executed = run_timeline(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 92, in run_timeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     results = self._do_run(handle, final_targets, final_fetches,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1396, in _do_call\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Detected at node 'default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       self[policy_id] = class_(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       DynamicTFPolicy.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       action_dist = dist_class(dist_inputs, self.model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       super().__init__(inputs / temperature, model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Node: 'default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \t [[{{node default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Original stack trace for 'default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self[policy_id] = class_(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     DynamicTFPolicy.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     action_dist = dist_class(dist_inputs, self.model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     super().__init__(inputs / temperature, model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return dispatch_target(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4425, in sparse_softmax_cross_entropy_with_logits_v2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return dispatch_target(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4338, in sparse_softmax_cross_entropy_with_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     cost = _sparse_softmax_cross_entropy_with_rank_2_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4237, in _sparse_softmax_cross_entropy_with_rank_2_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 11338, in sparse_softmax_cross_entropy_with_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 740, in _apply_op_helper\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3776, in _create_op_internal\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     ret = Operation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m 2022-02-18 16:39:19,710\tERROR worker.py:432 -- SystemExit was raised from the worker.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return fn(*args)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \t [[{{node default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"python/ray/_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"python/ray/_raylet.pyx\", line 670, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"python/ray/_raylet.pyx\", line 636, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"python/ray/_raylet.pyx\", line 640, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"python/ray/_raylet.pyx\", line 589, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return next(self.local_it)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 382, in gen_rollouts\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     yield self.sample()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 761, in sample\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     batches = [self.input_reader.next()]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 104, in next\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     batches = [self.get_data()]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 266, in get_data\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     item = next(self._env_runner)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 657, in _env_runner\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     eval_results = _do_policy_eval(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 1077, in _do_policy_eval\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     policy.compute_actions_from_input_dict(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py\", line 301, in compute_actions_from_input_dict\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     fetched = builder.get(to_fetch)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 48, in get\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self._executed = run_timeline(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 92, in run_timeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     results = self._do_run(handle, final_targets, final_fetches,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1396, in _do_call\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Detected at node 'default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       self[policy_id] = class_(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       DynamicTFPolicy.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       action_dist = dist_class(dist_inputs, self.model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       super().__init__(inputs / temperature, model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m       return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Node: 'default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \t [[{{node default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Original stack trace for 'default_policy_wk2/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self[policy_id] = class_(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     DynamicTFPolicy.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     action_dist = dist_class(dist_inputs, self.model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__2022-02-18 16:39:19,754\tWARNING worker.py:1257 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff25d42d8f4d64cad25a0d867c01000000 Worker ID: 3605b1421c92504ddea05924827034194b7a324306cda395a92db993 Node ID: 147da9084cfdcd66dbce221942465ce530a1a84cd7d0b457ee7366fd Worker IP address: 10.182.0.2 Worker port: 40377 Worker PID: 25295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     super().__init__(inputs / temperature, model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return dispatch_target(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4425, in sparse_softmax_cross_entropy_with_logits_v2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return dispatch_target(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4338, in sparse_softmax_cross_entropy_with_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     cost = _sparse_softmax_cross_entropy_with_rank_2_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4237, in _sparse_softmax_cross_entropy_with_rank_2_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 11338, in sparse_softmax_cross_entropy_with_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 740, in _apply_op_helper\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3776, in _create_op_internal\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     ret = Operation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"python/ray/_raylet.pyx\", line 770, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"python/ray/_raylet.pyx\", line 591, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"python/ray/_raylet.pyx\", line 725, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1953, in ray._raylet.CoreWorker.store_task_outputs\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/serialization.py\", line 367, in serialize\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return self._serialize_to_msgpack(value)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/serialization.py\", line 323, in _serialize_to_msgpack\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     value = value.to_bytes()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/exceptions.py\", line 22, in to_bytes\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     serialized_exception=pickle.dumps(self),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\", line 73, in dumps\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     cp.dump(obj)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\", line 620, in dump\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m     return Pickler.dump(self, obj)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m TypeError: cannot pickle '_thread.RLock' object\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m   File \"python/ray/_raylet.pyx\", line 799, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25295)\u001b[0m SystemExit\n",
      "2022-02-18 16:39:19,758\tERROR trial_runner.py:927 -- Trial PPO_CartPole-v0_a6500_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 893, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 707, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 1733, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::PPOTrainer.train()\u001b[39m (pid=25294, ip=10.182.0.2, repr=PPOTrainer)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/tune/trainable.py\", line 315, in train\n",
      "    result = self.step()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 977, in step\n",
      "    raise e\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 963, in step\n",
      "    step_attempt_results = self.step_attempt()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 1042, in step_attempt\n",
      "    step_results = self._exec_plan_or_training_iteration_fn()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 1962, in _exec_plan_or_training_iteration_fn\n",
      "    results = next(self.train_exec_impl)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
      "    return next(self.built_iterator)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "    for item in it:\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "    for item in it:\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
      "    for item in it:\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 471, in base_iterator\n",
      "    yield ray.get(futures, timeout=timeout)\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 16:39:19,779\tWARNING worker.py:1257 -- Traceback (most recent call last):\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
      "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
      "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\t [[{{node default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 670, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 636, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 640, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 589, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "    return next(self.local_it)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 382, in gen_rollouts\n",
      "    yield self.sample()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 761, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 104, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 266, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 657, in _env_runner\n",
      "    eval_results = _do_policy_eval(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 1077, in _do_policy_eval\n",
      "    policy.compute_actions_from_input_dict(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py\", line 301, in compute_actions_from_input_dict\n",
      "    fetched = builder.get(to_fetch)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 48, in get\n",
      "    raise e\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "    self._executed = run_timeline(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 92, in run_timeline\n",
      "    fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "    results = self._do_run(handle, final_targets, final_fetches,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n",
      "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1396, in _do_call\n",
      "    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "      ray.worker.global_worker.main_loop()\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "      self.core_worker.run_task_loop()\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "      return method(__ray_actor, *args, **kwargs)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "      return method(self, *_args, **_kwargs)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "      self._build_policy_map(\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "      return method(self, *_args, **_kwargs)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "      self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "      self[policy_id] = class_(\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "      DynamicTFPolicy.__init__(\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "      action_dist = dist_class(dist_inputs, self.model)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "      super().__init__(inputs / temperature, model)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "      self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "      return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "Node: 'default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\n",
      "Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\t [[{{node default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\n",
      "Original stack trace for 'default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "    ray.worker.global_worker.main_loop()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "    self.core_worker.run_task_loop()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "    self._build_policy_map(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "    self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "    self[policy_id] = class_(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "    DynamicTFPolicy.__init__(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "    action_dist = dist_class(dist_inputs, self.model)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "    super().__init__(inputs / temperature, model)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "    self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "    return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4425, in sparse_softmax_cross_entropy_with_logits_v2\n",
      "    return sparse_softmax_cross_entropy_with_logits(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4338, in sparse_softmax_cross_entropy_with_logits\n",
      "    cost = _sparse_softmax_cross_entropy_with_rank_2_logits(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4237, in _sparse_softmax_cross_entropy_with_rank_2_logits\n",
      "    cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 11338, in sparse_softmax_cross_entropy_with_logits\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 740, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3776, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\n",
      "    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 770, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 591, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 725, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1953, in ray._raylet.CoreWorker.store_task_outputs\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/serialization.py\", line 367, in serialize\n",
      "    return self._serialize_to_msgpack(value)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/serialization.py\", line 323, in _serialize_to_msgpack\n",
      "    value = value.to_bytes()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/exceptions.py\", line 22, in to_bytes\n",
      "    serialized_exception=pickle.dumps(self),\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\", line 73, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\", line 620, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "TypeError: cannot pickle '_thread.RLock' object\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 16:39:19,818\tWARNING worker.py:1257 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffc10aa063c3384c9524cfa22c01000000 Worker ID: d3e9588ad340bae03390685e3953d59c7c2ddcf1d930625147c71365 Node ID: 147da9084cfdcd66dbce221942465ce530a1a84cd7d0b457ee7366fd Worker IP address: 10.182.0.2 Worker port: 46283 Worker PID: 25296\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m 2022-02-18 16:39:19,753\tWARNING trainer.py:973 -- Worker crashed during call to `step_attempt()`. To try to continue training without the failed worker, set `ignore_worker_failures=True`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m 2022-02-18 16:39:19,763\tERROR tf_run_builder.py:46 -- Error fetching: [<tf.Tensor 'default_policy_wk3/cond_1/Merge:0' shape=(?,) dtype=int64>, {'action_prob': <tf.Tensor 'default_policy_wk3/Exp:0' shape=(?,) dtype=float32>, 'action_logp': <tf.Tensor 'default_policy_wk3/cond_2/Merge:0' shape=(?,) dtype=float32>, 'action_dist_inputs': <tf.Tensor 'default_policy_wk3/model/fc_out/BiasAdd:0' shape=(?, 2) dtype=float32>, 'vf_preds': <tf.Tensor 'default_policy_wk3/Reshape:0' shape=(?,) dtype=float32>}], feed_dict={<tf.Tensor 'default_policy_wk3/obs:0' shape=(?, 4) dtype=float32>: array([[-0.01035111, -0.01144519, -0.00398951, -0.05570747]],\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       dtype=float32), <tf.Tensor 'default_policy_wk3/is_training:0' shape=() dtype=bool>: False, <tf.Tensor 'default_policy_wk3/is_exploring:0' shape=() dtype=bool>: True, <tf.Tensor 'default_policy_wk3/timestep:0' shape=() dtype=int64>: 1279680}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return fn(*args)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \t [[{{node default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self._executed = run_timeline(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 92, in run_timeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     results = self._do_run(handle, final_targets, final_fetches,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1396, in _do_call\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Detected at node 'default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       self[policy_id] = class_(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       DynamicTFPolicy.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       action_dist = dist_class(dist_inputs, self.model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       super().__init__(inputs / temperature, model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Node: 'default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \t [[{{node default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Original stack trace for 'default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self[policy_id] = class_(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     DynamicTFPolicy.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     action_dist = dist_class(dist_inputs, self.model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     super().__init__(inputs / temperature, model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return dispatch_target(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4425, in sparse_softmax_cross_entropy_with_logits_v2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return dispatch_target(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4338, in sparse_softmax_cross_entropy_with_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     cost = _sparse_softmax_cross_entropy_with_rank_2_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4237, in _sparse_softmax_cross_entropy_with_rank_2_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 11338, in sparse_softmax_cross_entropy_with_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 740, in _apply_op_helper\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3776, in _create_op_internal\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     ret = Operation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m 2022-02-18 16:39:19,775\tERROR worker.py:432 -- SystemExit was raised from the worker.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return fn(*args)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \t [[{{node default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"python/ray/_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"python/ray/_raylet.pyx\", line 670, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"python/ray/_raylet.pyx\", line 636, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"python/ray/_raylet.pyx\", line 640, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"python/ray/_raylet.pyx\", line 589, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return next(self.local_it)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 382, in gen_rollouts\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     yield self.sample()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 761, in sample\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     batches = [self.input_reader.next()]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 104, in next\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     batches = [self.get_data()]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 266, in get_data\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     item = next(self._env_runner)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 657, in _env_runner\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     eval_results = _do_policy_eval(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 1077, in _do_policy_eval\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     policy.compute_actions_from_input_dict(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py\", line 301, in compute_actions_from_input_dict\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     fetched = builder.get(to_fetch)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 48, in get\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self._executed = run_timeline(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 92, in run_timeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     results = self._do_run(handle, final_targets, final_fetches,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1396, in _do_call\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Detected at node 'default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       self[policy_id] = class_(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       DynamicTFPolicy.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       action_dist = dist_class(dist_inputs, self.model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       super().__init__(inputs / temperature, model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m       return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Node: 'default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \t [[{{node default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Original stack trace for 'default_policy_wk3/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self[policy_id] = class_(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     DynamicTFPolicy.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     action_dist = dist_class(dist_inputs, self.model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     super().__init__(inputs / temperature, model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return dispatch_target(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4425, in sparse_softmax_cross_entropy_with_logits_v2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return dispatch_target(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4338, in sparse_softmax_cross_entropy_with_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     cost = _sparse_softmax_cross_entropy_with_rank_2_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4237, in _sparse_softmax_cross_entropy_with_rank_2_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 11338, in sparse_softmax_cross_entropy_with_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 740, in _apply_op_helper\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3776, in _create_op_internal\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     ret = Operation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"python/ray/_raylet.pyx\", line 770, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"python/ray/_raylet.pyx\", line 591, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"python/ray/_raylet.pyx\", line 725, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1953, in ray._raylet.CoreWorker.store_task_outputs\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/serialization.py\", line 367, in serialize\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return self._serialize_to_msgpack(value)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/serialization.py\", line 323, in _serialize_to_msgpack\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     value = value.to_bytes()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/exceptions.py\", line 22, in to_bytes\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     serialized_exception=pickle.dumps(self),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\", line 73, in dumps\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     cp.dump(obj)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\", line 620, in dump\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m     return Pickler.dump(self, obj)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m TypeError: cannot pickle '_thread.RLock' object\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m   File \"python/ray/_raylet.pyx\", line 799, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25296)\u001b[0m SystemExit\n",
      "2022-02-18 16:39:19,875\tWARNING worker.py:1257 -- Traceback (most recent call last):\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
      "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
      "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\t [[{{node default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 670, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 636, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 640, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 589, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "    return next(self.local_it)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 382, in gen_rollouts\n",
      "    yield self.sample()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 761, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 104, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 266, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 657, in _env_runner\n",
      "    eval_results = _do_policy_eval(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 1077, in _do_policy_eval\n",
      "    policy.compute_actions_from_input_dict(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py\", line 301, in compute_actions_from_input_dict\n",
      "    fetched = builder.get(to_fetch)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 48, in get\n",
      "    raise e\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "    self._executed = run_timeline(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 92, in run_timeline\n",
      "    fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "    results = self._do_run(handle, final_targets, final_fetches,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n",
      "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1396, in _do_call\n",
      "    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "      ray.worker.global_worker.main_loop()\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "      self.core_worker.run_task_loop()\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "      return method(__ray_actor, *args, **kwargs)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "      return method(self, *_args, **_kwargs)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "      self._build_policy_map(\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "      return method(self, *_args, **_kwargs)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "      self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "      self[policy_id] = class_(\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "      DynamicTFPolicy.__init__(\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "      action_dist = dist_class(dist_inputs, self.model)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "      super().__init__(inputs / temperature, model)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "      self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "    File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "      return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "Node: 'default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\n",
      "Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\t [[{{node default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\n",
      "Original stack trace for 'default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "    ray.worker.global_worker.main_loop()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "    self.core_worker.run_task_loop()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "    self._build_policy_map(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "    self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "    self[policy_id] = class_(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "    DynamicTFPolicy.__init__(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "    action_dist = dist_class(dist_inputs, self.model)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "    super().__init__(inputs / temperature, model)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "    self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "    return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4425, in sparse_softmax_cross_entropy_with_logits_v2\n",
      "    return sparse_softmax_cross_entropy_with_logits(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4338, in sparse_softmax_cross_entropy_with_logits\n",
      "    cost = _sparse_softmax_cross_entropy_with_rank_2_logits(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4237, in _sparse_softmax_cross_entropy_with_rank_2_logits\n",
      "    cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 11338, in sparse_softmax_cross_entropy_with_logits\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 740, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3776, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\n",
      "    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 770, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 591, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 725, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1953, in ray._raylet.CoreWorker.store_task_outputs\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/serialization.py\", line 367, in serialize\n",
      "    return self._serialize_to_msgpack(value)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/serialization.py\", line 323, in _serialize_to_msgpack\n",
      "    value = value.to_bytes()\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/exceptions.py\", line 22, in to_bytes\n",
      "    serialized_exception=pickle.dumps(self),\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\", line 73, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\", line 620, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "TypeError: cannot pickle '_thread.RLock' object\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 16:39:19,917\tWARNING worker.py:1257 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff89a83c5f0fd39e63cb7a861e01000000 Worker ID: ee30c83e0eaeebc40e8aa9822ba5ed43105b9beb7e52629341b390b8 Node ID: 147da9084cfdcd66dbce221942465ce530a1a84cd7d0b457ee7366fd Worker IP address: 10.182.0.2 Worker port: 45543 Worker PID: 25293\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m 2022-02-18 16:39:19,860\tERROR tf_run_builder.py:46 -- Error fetching: [<tf.Tensor 'default_policy_wk1/cond_1/Merge:0' shape=(?,) dtype=int64>, {'action_prob': <tf.Tensor 'default_policy_wk1/Exp:0' shape=(?,) dtype=float32>, 'action_logp': <tf.Tensor 'default_policy_wk1/cond_2/Merge:0' shape=(?,) dtype=float32>, 'action_dist_inputs': <tf.Tensor 'default_policy_wk1/model/fc_out/BiasAdd:0' shape=(?, 2) dtype=float32>, 'vf_preds': <tf.Tensor 'default_policy_wk1/Reshape:0' shape=(?,) dtype=float32>}], feed_dict={<tf.Tensor 'default_policy_wk1/obs:0' shape=(?, 4) dtype=float32>: array([[-0.37686267, -0.32869864, -0.09448478, -0.42687413]],\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       dtype=float32), <tf.Tensor 'default_policy_wk1/is_training:0' shape=() dtype=bool>: False, <tf.Tensor 'default_policy_wk1/is_exploring:0' shape=() dtype=bool>: True, <tf.Tensor 'default_policy_wk1/timestep:0' shape=() dtype=int64>: 1279680}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return fn(*args)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \t [[{{node default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self._executed = run_timeline(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 92, in run_timeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     results = self._do_run(handle, final_targets, final_fetches,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1396, in _do_call\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Detected at node 'default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       self[policy_id] = class_(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       DynamicTFPolicy.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       action_dist = dist_class(dist_inputs, self.model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       super().__init__(inputs / temperature, model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Node: 'default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \t [[{{node default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Original stack trace for 'default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self[policy_id] = class_(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     DynamicTFPolicy.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     action_dist = dist_class(dist_inputs, self.model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     super().__init__(inputs / temperature, model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return dispatch_target(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4425, in sparse_softmax_cross_entropy_with_logits_v2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return dispatch_target(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4338, in sparse_softmax_cross_entropy_with_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     cost = _sparse_softmax_cross_entropy_with_rank_2_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4237, in _sparse_softmax_cross_entropy_with_rank_2_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 11338, in sparse_softmax_cross_entropy_with_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 740, in _apply_op_helper\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3776, in _create_op_internal\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     ret = Operation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m 2022-02-18 16:39:19,874\tERROR worker.py:432 -- SystemExit was raised from the worker.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return fn(*args)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \t [[{{node default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"python/ray/_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"python/ray/_raylet.pyx\", line 670, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"python/ray/_raylet.pyx\", line 636, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"python/ray/_raylet.pyx\", line 640, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"python/ray/_raylet.pyx\", line 589, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return next(self.local_it)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 382, in gen_rollouts\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     yield self.sample()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 761, in sample\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     batches = [self.input_reader.next()]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 104, in next\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     batches = [self.get_data()]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 266, in get_data\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     item = next(self._env_runner)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 657, in _env_runner\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     eval_results = _do_policy_eval(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 1077, in _do_policy_eval\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     policy.compute_actions_from_input_dict(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py\", line 301, in compute_actions_from_input_dict\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     fetched = builder.get(to_fetch)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 48, in get\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self._executed = run_timeline(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/utils/tf_run_builder.py\", line 92, in run_timeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     results = self._do_run(handle, final_targets, final_fetches,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1396, in _do_call\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Detected at node 'default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       self[policy_id] = class_(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       DynamicTFPolicy.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       action_dist = dist_class(dist_inputs, self.model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       super().__init__(inputs / temperature, model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m       return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Node: 'default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \t [[{{node default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Original stack trace for 'default_policy_wk1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/workers/default_worker.py\", line 218, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 432, in main_loop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 588, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1555, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 133, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self[policy_id] = class_(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 238, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     DynamicTFPolicy.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 336, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     action_dist = dist_class(dist_inputs, self.model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 62, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     super().__init__(inputs / temperature, model)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 29, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self.sampled_action_logp_op = self.logp(self.sample_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/models/tf/tf_action_dist.py\", line 70, in logp\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return -tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return dispatch_target(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4425, in sparse_softmax_cross_entropy_with_logits_v2\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return dispatch_target(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4338, in sparse_softmax_cross_entropy_with_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     cost = _sparse_softmax_cross_entropy_with_rank_2_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 4237, in _sparse_softmax_cross_entropy_with_rank_2_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 11338, in sparse_softmax_cross_entropy_with_logits\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 740, in _apply_op_helper\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3776, in _create_op_internal\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     ret = Operation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"python/ray/_raylet.pyx\", line 770, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"python/ray/_raylet.pyx\", line 591, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"python/ray/_raylet.pyx\", line 725, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1953, in ray._raylet.CoreWorker.store_task_outputs\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/serialization.py\", line 367, in serialize\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return self._serialize_to_msgpack(value)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/serialization.py\", line 323, in _serialize_to_msgpack\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     value = value.to_bytes()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/exceptions.py\", line 22, in to_bytes\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     serialized_exception=pickle.dumps(self),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\", line 73, in dumps\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     cp.dump(obj)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\", line 620, in dump\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m     return Pickler.dump(self, obj)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m TypeError: cannot pickle '_thread.RLock' object\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m   File \"python/ray/_raylet.pyx\", line 799, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25293)\u001b[0m SystemExit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00000:\n",
      "  agent_timesteps_total: 1279680\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-39-19\n",
      "  done: false\n",
      "  episode_len_mean: 175.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 175.96\n",
      "  episode_reward_min: 78.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 7875\n",
      "  experiment_id: 1e3b8871dafa4e98b74d8257bd49b0ad\n",
      "  experiment_tag: 0_lr=0.01\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.8517067718416925e+19\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.015109116211533546\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.07243618369102478\n",
      "          model: {}\n",
      "          policy_loss: 0.003030304564163089\n",
      "          total_loss: 2.0656677508266066e+18\n",
      "          vf_explained_var: 0.6918275952339172\n",
      "          vf_loss: 228.48342895507812\n",
      "    num_agent_steps_sampled: 1279680\n",
      "    num_agent_steps_trained: 1279680\n",
      "    num_steps_sampled: 1279680\n",
      "    num_steps_trained: 1279680\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.55714285714286\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 25294\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09051457712037003\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09149510401133412\n",
      "    mean_inference_ms: 1.000996604164137\n",
      "    mean_raw_obs_processing_ms: 0.11872254066646316\n",
      "  time_since_restore: 1560.4129700660706\n",
      "  time_this_iter_s: 9.701569318771362\n",
      "  time_total_s: 1560.4129700660706\n",
      "  timers:\n",
      "    learn_throughput: 1298.431\n",
      "    learn_time_ms: 6159.742\n",
      "    load_throughput: 25502541.73\n",
      "    load_time_ms: 0.314\n",
      "    sample_throughput: 822.348\n",
      "    sample_time_ms: 9725.806\n",
      "    update_time_ms: 2.67\n",
      "  timestamp: 1645202359\n",
      "  timesteps_since_restore: 1279680\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 1279680\n",
      "  training_iteration: 160\n",
      "  trial_id: a6500_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m 2022-02-18 16:39:20,008\tERROR worker_set.py:216 -- Failed to stop workers!\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 214, in stop\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m     ray.get(tids)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 1735, in get\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m     raise value\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=25294)\u001b[0m ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:39:22 (running for 00:26:19.23)<br>Memory usage on this node: 1.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=26960)\u001b[0m 2022-02-18 16:39:26,881\tINFO trainer.py:2054 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=26960)\u001b[0m 2022-02-18 16:39:26,882\tWARNING ppo.py:223 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 1333.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=26960)\u001b[0m 2022-02-18 16:39:26,882\tINFO ppo.py:249 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=26960)\u001b[0m 2022-02-18 16:39:26,882\tINFO trainer.py:790 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m 2022-02-18 16:39:32,754\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:39:27 (running for 00:26:24.42)<br>Memory usage on this node: 1.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=26960)\u001b[0m 2022-02-18 16:39:33,759\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26990)\u001b[0m 2022-02-18 16:39:34,108\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m 2022-02-18 16:39:34,355\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:39:34 (running for 00:26:31.33)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=26960)\u001b[0m 2022-02-18 16:39:38,081\tWARNING deprecation.py:45 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:39:39 (running for 00:26:36.34)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 7998\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-39-44\n",
      "  done: false\n",
      "  episode_len_mean: 21.7013698630137\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 76.0\n",
      "  episode_reward_mean: 21.7013698630137\n",
      "  episode_reward_min: 8.0\n",
      "  episodes_this_iter: 365\n",
      "  episodes_total: 365\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.6594997644424438\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03489064797759056\n",
      "          model: {}\n",
      "          policy_loss: -0.05243353173136711\n",
      "          total_loss: 94.6938247680664\n",
      "          vf_explained_var: 0.3513699471950531\n",
      "          vf_loss: 94.73927307128906\n",
      "    num_agent_steps_sampled: 7998\n",
      "    num_agent_steps_trained: 7998\n",
      "    num_steps_sampled: 7998\n",
      "    num_steps_trained: 7998\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.28125\n",
      "    ram_util_percent: 17.737499999999997\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09287743184606309\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09542912330977973\n",
      "    mean_inference_ms: 1.0232570317806107\n",
      "    mean_raw_obs_processing_ms: 0.14837130416424246\n",
      "  time_since_restore: 10.635114192962646\n",
      "  time_this_iter_s: 10.635114192962646\n",
      "  time_total_s: 10.635114192962646\n",
      "  timers:\n",
      "    learn_throughput: 1266.913\n",
      "    learn_time_ms: 6312.985\n",
      "    load_throughput: 17211925.804\n",
      "    load_time_ms: 0.465\n",
      "    sample_throughput: 1849.813\n",
      "    sample_time_ms: 4323.68\n",
      "    update_time_ms: 3.023\n",
      "  timestamp: 1645202384\n",
      "  timesteps_since_restore: 7998\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 7998\n",
      "  training_iteration: 1\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:39:45 (running for 00:26:42.02)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.6351</td><td style=\"text-align: right;\">   7998</td><td style=\"text-align: right;\"> 21.7014</td><td style=\"text-align: right;\">                  76</td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">           21.7014</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">175.96  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">          175.96  </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:39:50 (running for 00:26:47.04)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.6351</td><td style=\"text-align: right;\">   7998</td><td style=\"text-align: right;\"> 21.7014</td><td style=\"text-align: right;\">                  76</td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">           21.7014</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">175.96  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">          175.96  </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 15996\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-39-54\n",
      "  done: false\n",
      "  episode_len_mean: 49.617283950617285\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 142.0\n",
      "  episode_reward_mean: 49.617283950617285\n",
      "  episode_reward_min: 12.0\n",
      "  episodes_this_iter: 162\n",
      "  episodes_total: 527\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.6043333411216736\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020984916016459465\n",
      "          model: {}\n",
      "          policy_loss: -0.036363959312438965\n",
      "          total_loss: 335.28570556640625\n",
      "          vf_explained_var: 0.2368340939283371\n",
      "          vf_loss: 335.3157958984375\n",
      "    num_agent_steps_sampled: 15996\n",
      "    num_agent_steps_trained: 15996\n",
      "    num_steps_sampled: 15996\n",
      "    num_steps_trained: 15996\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.0\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09209007264923275\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0951670178130236\n",
      "    mean_inference_ms: 1.01967552794733\n",
      "    mean_raw_obs_processing_ms: 0.13907696386110857\n",
      "  time_since_restore: 20.511677980422974\n",
      "  time_this_iter_s: 9.876563787460327\n",
      "  time_total_s: 20.511677980422974\n",
      "  timers:\n",
      "    learn_throughput: 1275.332\n",
      "    learn_time_ms: 6271.307\n",
      "    load_throughput: 21012241.398\n",
      "    load_time_ms: 0.381\n",
      "    sample_throughput: 1117.184\n",
      "    sample_time_ms: 7159.071\n",
      "    update_time_ms: 3.021\n",
      "  timestamp: 1645202394\n",
      "  timesteps_since_restore: 15996\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 15996\n",
      "  training_iteration: 2\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:39:56 (running for 00:26:52.93)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         20.5117</td><td style=\"text-align: right;\">  15996</td><td style=\"text-align: right;\"> 49.6173</td><td style=\"text-align: right;\">                 142</td><td style=\"text-align: right;\">                  12</td><td style=\"text-align: right;\">           49.6173</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">175.96  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">          175.96  </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:40:01 (running for 00:26:57.94)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         20.5117</td><td style=\"text-align: right;\">  15996</td><td style=\"text-align: right;\"> 49.6173</td><td style=\"text-align: right;\">                 142</td><td style=\"text-align: right;\">                  12</td><td style=\"text-align: right;\">           49.6173</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">175.96  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">          175.96  </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 23994\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-40-03\n",
      "  done: false\n",
      "  episode_len_mean: 95.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 95.06\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 591\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5642139911651611\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009948174469172955\n",
      "          model: {}\n",
      "          policy_loss: -0.017392845824360847\n",
      "          total_loss: 771.7174682617188\n",
      "          vf_explained_var: 0.2204861044883728\n",
      "          vf_loss: 771.73046875\n",
      "    num_agent_steps_sampled: 23994\n",
      "    num_agent_steps_trained: 23994\n",
      "    num_steps_sampled: 23994\n",
      "    num_steps_trained: 23994\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.30000000000001\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09150400392928551\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09424031733402309\n",
      "    mean_inference_ms: 1.007223134099666\n",
      "    mean_raw_obs_processing_ms: 0.1347302881209618\n",
      "  time_since_restore: 30.06053400039673\n",
      "  time_this_iter_s: 9.548856019973755\n",
      "  time_total_s: 30.06053400039673\n",
      "  timers:\n",
      "    learn_throughput: 1288.145\n",
      "    learn_time_ms: 6208.928\n",
      "    load_throughput: 22031114.312\n",
      "    load_time_ms: 0.363\n",
      "    sample_throughput: 998.1\n",
      "    sample_time_ms: 8013.229\n",
      "    update_time_ms: 2.896\n",
      "  timestamp: 1645202403\n",
      "  timesteps_since_restore: 23994\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 23994\n",
      "  training_iteration: 3\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:40:06 (running for 00:27:03.50)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         30.0605</td><td style=\"text-align: right;\">  23994</td><td style=\"text-align: right;\">   95.06</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">             95.06</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:40:11 (running for 00:27:08.51)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         30.0605</td><td style=\"text-align: right;\">  23994</td><td style=\"text-align: right;\">   95.06</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">             95.06</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 31992\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-40-13\n",
      "  done: false\n",
      "  episode_len_mean: 147.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 147.55\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 636\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5594632029533386\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005807238165289164\n",
      "          model: {}\n",
      "          policy_loss: -0.00890549086034298\n",
      "          total_loss: 643.1326904296875\n",
      "          vf_explained_var: 0.28740066289901733\n",
      "          vf_loss: 643.1389770507812\n",
      "    num_agent_steps_sampled: 31992\n",
      "    num_agent_steps_trained: 31992\n",
      "    num_steps_sampled: 31992\n",
      "    num_steps_trained: 31992\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.03333333333332\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09131156728120896\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09370569198164684\n",
      "    mean_inference_ms: 1.002152000450682\n",
      "    mean_raw_obs_processing_ms: 0.13085313064037585\n",
      "  time_since_restore: 39.914644718170166\n",
      "  time_this_iter_s: 9.854110717773438\n",
      "  time_total_s: 39.914644718170166\n",
      "  timers:\n",
      "    learn_throughput: 1285.928\n",
      "    learn_time_ms: 6219.634\n",
      "    load_throughput: 22750792.399\n",
      "    load_time_ms: 0.352\n",
      "    sample_throughput: 947.908\n",
      "    sample_time_ms: 8437.527\n",
      "    update_time_ms: 2.947\n",
      "  timestamp: 1645202413\n",
      "  timesteps_since_restore: 31992\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 31992\n",
      "  training_iteration: 4\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:40:17 (running for 00:27:14.37)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         39.9146</td><td style=\"text-align: right;\">  31992</td><td style=\"text-align: right;\">  147.55</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            147.55</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:40:22 (running for 00:27:19.38)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         39.9146</td><td style=\"text-align: right;\">  31992</td><td style=\"text-align: right;\">  147.55</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            147.55</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 39990\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-40-23\n",
      "  done: false\n",
      "  episode_len_mean: 171.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 171.81\n",
      "  episode_reward_min: 26.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 683\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.558792233467102\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006564958952367306\n",
      "          model: {}\n",
      "          policy_loss: -0.009693954139947891\n",
      "          total_loss: 432.6029357910156\n",
      "          vf_explained_var: 0.41519588232040405\n",
      "          vf_loss: 432.60968017578125\n",
      "    num_agent_steps_sampled: 39990\n",
      "    num_agent_steps_trained: 39990\n",
      "    num_steps_sampled: 39990\n",
      "    num_steps_trained: 39990\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.03076923076922\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0910502161030615\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09325534152071173\n",
      "    mean_inference_ms: 0.9993601600664215\n",
      "    mean_raw_obs_processing_ms: 0.12810110505525013\n",
      "  time_since_restore: 49.52193760871887\n",
      "  time_this_iter_s: 9.607292890548706\n",
      "  time_total_s: 49.52193760871887\n",
      "  timers:\n",
      "    learn_throughput: 1289.638\n",
      "    learn_time_ms: 6201.74\n",
      "    load_throughput: 22970448.776\n",
      "    load_time_ms: 0.348\n",
      "    sample_throughput: 919.218\n",
      "    sample_time_ms: 8700.873\n",
      "    update_time_ms: 2.942\n",
      "  timestamp: 1645202423\n",
      "  timesteps_since_restore: 39990\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 39990\n",
      "  training_iteration: 5\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:40:28 (running for 00:27:25.01)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         49.5219</td><td style=\"text-align: right;\">  39990</td><td style=\"text-align: right;\">  171.81</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  26</td><td style=\"text-align: right;\">            171.81</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 47988\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-40-33\n",
      "  done: false\n",
      "  episode_len_mean: 179.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 179.71\n",
      "  episode_reward_min: 26.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 724\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.547218382358551\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005442402325570583\n",
      "          model: {}\n",
      "          policy_loss: -0.006023680791258812\n",
      "          total_loss: 311.1892395019531\n",
      "          vf_explained_var: 0.49997714161872864\n",
      "          vf_loss: 311.1928405761719\n",
      "    num_agent_steps_sampled: 47988\n",
      "    num_agent_steps_trained: 47988\n",
      "    num_steps_sampled: 47988\n",
      "    num_steps_trained: 47988\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.7357142857143\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09083290701409087\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09305351578505774\n",
      "    mean_inference_ms: 0.9982575107392339\n",
      "    mean_raw_obs_processing_ms: 0.12635174478177272\n",
      "  time_since_restore: 59.16095852851868\n",
      "  time_this_iter_s: 9.639020919799805\n",
      "  time_total_s: 59.16095852851868\n",
      "  timers:\n",
      "    learn_throughput: 1293.731\n",
      "    learn_time_ms: 6182.121\n",
      "    load_throughput: 22597536.808\n",
      "    load_time_ms: 0.354\n",
      "    sample_throughput: 901.704\n",
      "    sample_time_ms: 8869.869\n",
      "    update_time_ms: 2.845\n",
      "  timestamp: 1645202433\n",
      "  timesteps_since_restore: 47988\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 47988\n",
      "  training_iteration: 6\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:40:34 (running for 00:27:30.64)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">          59.161</td><td style=\"text-align: right;\">  47988</td><td style=\"text-align: right;\">  179.71</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  26</td><td style=\"text-align: right;\">            179.71</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:40:39 (running for 00:27:35.71)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">          59.161</td><td style=\"text-align: right;\">  47988</td><td style=\"text-align: right;\">  179.71</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  26</td><td style=\"text-align: right;\">            179.71</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 55986\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-40-42\n",
      "  done: false\n",
      "  episode_len_mean: 187.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 187.59\n",
      "  episode_reward_min: 53.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 766\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5554326772689819\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007328078616410494\n",
      "          model: {}\n",
      "          policy_loss: -0.0018689528806135058\n",
      "          total_loss: 267.6145935058594\n",
      "          vf_explained_var: 0.6139069199562073\n",
      "          vf_loss: 267.6131591796875\n",
      "    num_agent_steps_sampled: 55986\n",
      "    num_agent_steps_trained: 55986\n",
      "    num_steps_sampled: 55986\n",
      "    num_steps_trained: 55986\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.85000000000001\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09064336515839697\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0928200975523456\n",
      "    mean_inference_ms: 0.9962880941800293\n",
      "    mean_raw_obs_processing_ms: 0.12495870973864492\n",
      "  time_since_restore: 69.02850270271301\n",
      "  time_this_iter_s: 9.867544174194336\n",
      "  time_total_s: 69.02850270271301\n",
      "  timers:\n",
      "    learn_throughput: 1287.447\n",
      "    learn_time_ms: 6212.296\n",
      "    load_throughput: 22740877.759\n",
      "    load_time_ms: 0.352\n",
      "    sample_throughput: 891.481\n",
      "    sample_time_ms: 8971.586\n",
      "    update_time_ms: 3.022\n",
      "  timestamp: 1645202442\n",
      "  timesteps_since_restore: 55986\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 55986\n",
      "  training_iteration: 7\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:40:44 (running for 00:27:41.53)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         69.0285</td><td style=\"text-align: right;\">  55986</td><td style=\"text-align: right;\">  187.59</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            187.59</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:40:50 (running for 00:27:46.57)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         69.0285</td><td style=\"text-align: right;\">  55986</td><td style=\"text-align: right;\">  187.59</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            187.59</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 63984\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-40-52\n",
      "  done: false\n",
      "  episode_len_mean: 191.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 191.29\n",
      "  episode_reward_min: 53.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 808\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5224325060844421\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006804240867495537\n",
      "          model: {}\n",
      "          policy_loss: -0.009534833952784538\n",
      "          total_loss: 371.02264404296875\n",
      "          vf_explained_var: 0.4146706759929657\n",
      "          vf_loss: 371.02911376953125\n",
      "    num_agent_steps_sampled: 63984\n",
      "    num_agent_steps_trained: 63984\n",
      "    num_steps_sampled: 63984\n",
      "    num_steps_trained: 63984\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.97142857142856\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09064480825054036\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09267385427338888\n",
      "    mean_inference_ms: 0.9952024346824069\n",
      "    mean_raw_obs_processing_ms: 0.12411475235770833\n",
      "  time_since_restore: 78.67895221710205\n",
      "  time_this_iter_s: 9.650449514389038\n",
      "  time_total_s: 78.67895221710205\n",
      "  timers:\n",
      "    learn_throughput: 1291.189\n",
      "    learn_time_ms: 6194.292\n",
      "    load_throughput: 22894416.238\n",
      "    load_time_ms: 0.349\n",
      "    sample_throughput: 878.845\n",
      "    sample_time_ms: 9100.585\n",
      "    update_time_ms: 2.985\n",
      "  timestamp: 1645202452\n",
      "  timesteps_since_restore: 63984\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 63984\n",
      "  training_iteration: 8\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:40:55 (running for 00:27:52.21)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">          78.679</td><td style=\"text-align: right;\">  63984</td><td style=\"text-align: right;\">  191.29</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            191.29</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:41:00 (running for 00:27:57.25)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">          78.679</td><td style=\"text-align: right;\">  63984</td><td style=\"text-align: right;\">  191.29</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            191.29</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 71982\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-41-02\n",
      "  done: false\n",
      "  episode_len_mean: 194.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.08\n",
      "  episode_reward_min: 53.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 847\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5183038115501404\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005949188955128193\n",
      "          model: {}\n",
      "          policy_loss: -0.007932769134640694\n",
      "          total_loss: 343.9969787597656\n",
      "          vf_explained_var: 0.42266756296157837\n",
      "          vf_loss: 344.0022277832031\n",
      "    num_agent_steps_sampled: 71982\n",
      "    num_agent_steps_trained: 71982\n",
      "    num_steps_sampled: 71982\n",
      "    num_steps_trained: 71982\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.02142857142857\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0907909614577429\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0927254192423894\n",
      "    mean_inference_ms: 0.9950825707259938\n",
      "    mean_raw_obs_processing_ms: 0.12371506757695638\n",
      "  time_since_restore: 88.45371174812317\n",
      "  time_this_iter_s: 9.774759531021118\n",
      "  time_total_s: 88.45371174812317\n",
      "  timers:\n",
      "    learn_throughput: 1291.389\n",
      "    learn_time_ms: 6193.329\n",
      "    load_throughput: 22842883.448\n",
      "    load_time_ms: 0.35\n",
      "    sample_throughput: 872.626\n",
      "    sample_time_ms: 9165.439\n",
      "    update_time_ms: 2.974\n",
      "  timestamp: 1645202462\n",
      "  timesteps_since_restore: 71982\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 71982\n",
      "  training_iteration: 9\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:41:06 (running for 00:28:03.02)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         88.4537</td><td style=\"text-align: right;\">  71982</td><td style=\"text-align: right;\">  194.08</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            194.08</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:41:11 (running for 00:28:08.08)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         88.4537</td><td style=\"text-align: right;\">  71982</td><td style=\"text-align: right;\">  194.08</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            194.08</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 79980\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-41-12\n",
      "  done: false\n",
      "  episode_len_mean: 199.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.79\n",
      "  episode_reward_min: 179.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 888\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5003824830055237\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006886841729283333\n",
      "          model: {}\n",
      "          policy_loss: -0.01100973505526781\n",
      "          total_loss: 354.35101318359375\n",
      "          vf_explained_var: 0.46320492029190063\n",
      "          vf_loss: 354.35894775390625\n",
      "    num_agent_steps_sampled: 79980\n",
      "    num_agent_steps_trained: 79980\n",
      "    num_steps_sampled: 79980\n",
      "    num_steps_trained: 79980\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.07857142857142\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09100114382236643\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09294659347335033\n",
      "    mean_inference_ms: 0.9962788402236217\n",
      "    mean_raw_obs_processing_ms: 0.12351793337415179\n",
      "  time_since_restore: 98.24055671691895\n",
      "  time_this_iter_s: 9.786844968795776\n",
      "  time_total_s: 98.24055671691895\n",
      "  timers:\n",
      "    learn_throughput: 1292.413\n",
      "    learn_time_ms: 6188.422\n",
      "    load_throughput: 22860871.877\n",
      "    load_time_ms: 0.35\n",
      "    sample_throughput: 866.119\n",
      "    sample_time_ms: 9234.292\n",
      "    update_time_ms: 2.997\n",
      "  timestamp: 1645202472\n",
      "  timesteps_since_restore: 79980\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 79980\n",
      "  training_iteration: 10\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:41:17 (running for 00:28:13.83)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         98.2406</td><td style=\"text-align: right;\">  79980</td><td style=\"text-align: right;\">  199.79</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 179</td><td style=\"text-align: right;\">            199.79</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">       1560.41  </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 87978\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-41-21\n",
      "  done: false\n",
      "  episode_len_mean: 199.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.73\n",
      "  episode_reward_min: 173.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 928\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.49615252017974854\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006804135628044605\n",
      "          model: {}\n",
      "          policy_loss: -0.009154830127954483\n",
      "          total_loss: 345.8209533691406\n",
      "          vf_explained_var: 0.5539405941963196\n",
      "          vf_loss: 345.82708740234375\n",
      "    num_agent_steps_sampled: 87978\n",
      "    num_agent_steps_trained: 87978\n",
      "    num_steps_sampled: 87978\n",
      "    num_steps_trained: 87978\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.75\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09112518621388889\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09312645586813025\n",
      "    mean_inference_ms: 0.9972981068010288\n",
      "    mean_raw_obs_processing_ms: 0.12328956185339647\n",
      "  time_since_restore: 107.95399928092957\n",
      "  time_this_iter_s: 9.71344256401062\n",
      "  time_total_s: 107.95399928092957\n",
      "  timers:\n",
      "    learn_throughput: 1296.297\n",
      "    learn_time_ms: 6169.881\n",
      "    load_throughput: 23609010.762\n",
      "    load_time_ms: 0.339\n",
      "    sample_throughput: 817.96\n",
      "    sample_time_ms: 9777.983\n",
      "    update_time_ms: 2.946\n",
      "  timestamp: 1645202481\n",
      "  timesteps_since_restore: 87978\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 87978\n",
      "  training_iteration: 11\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:41:23 (running for 00:28:19.61)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         107.954</td><td style=\"text-align: right;\">  87978</td><td style=\"text-align: right;\">  199.73</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 173</td><td style=\"text-align: right;\">            199.73</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:41:28 (running for 00:28:24.62)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         107.954</td><td style=\"text-align: right;\">  87978</td><td style=\"text-align: right;\">  199.73</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 173</td><td style=\"text-align: right;\">            199.73</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 95976\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-41-31\n",
      "  done: false\n",
      "  episode_len_mean: 199.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.38\n",
      "  episode_reward_min: 165.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 967\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4766893982887268\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006947607267647982\n",
      "          model: {}\n",
      "          policy_loss: -0.007536696270108223\n",
      "          total_loss: 332.6318664550781\n",
      "          vf_explained_var: 0.5271322727203369\n",
      "          vf_loss: 332.63629150390625\n",
      "    num_agent_steps_sampled: 95976\n",
      "    num_agent_steps_trained: 95976\n",
      "    num_steps_sampled: 95976\n",
      "    num_steps_trained: 95976\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.62142857142855\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09105004999033377\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.093075885197231\n",
      "    mean_inference_ms: 0.996606076330068\n",
      "    mean_raw_obs_processing_ms: 0.12289294137666061\n",
      "  time_since_restore: 117.72973132133484\n",
      "  time_this_iter_s: 9.775732040405273\n",
      "  time_total_s: 117.72973132133484\n",
      "  timers:\n",
      "    learn_throughput: 1294.547\n",
      "    learn_time_ms: 6178.223\n",
      "    load_throughput: 23575826.405\n",
      "    load_time_ms: 0.339\n",
      "    sample_throughput: 821.145\n",
      "    sample_time_ms: 9740.062\n",
      "    update_time_ms: 2.918\n",
      "  timestamp: 1645202491\n",
      "  timesteps_since_restore: 95976\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 95976\n",
      "  training_iteration: 12\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:41:33 (running for 00:28:30.42)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">          117.73</td><td style=\"text-align: right;\">  95976</td><td style=\"text-align: right;\">  199.38</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 165</td><td style=\"text-align: right;\">            199.38</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:41:38 (running for 00:28:35.43)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">          117.73</td><td style=\"text-align: right;\">  95976</td><td style=\"text-align: right;\">  199.38</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 165</td><td style=\"text-align: right;\">            199.38</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 103974\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-41-41\n",
      "  done: false\n",
      "  episode_len_mean: 199.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.05\n",
      "  episode_reward_min: 165.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 1009\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.47966817021369934\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008124676533043385\n",
      "          model: {}\n",
      "          policy_loss: -0.013331171125173569\n",
      "          total_loss: 310.4997863769531\n",
      "          vf_explained_var: 0.6073994040489197\n",
      "          vf_loss: 310.5095520019531\n",
      "    num_agent_steps_sampled: 103974\n",
      "    num_agent_steps_trained: 103974\n",
      "    num_steps_sampled: 103974\n",
      "    num_steps_trained: 103974\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.57857142857142\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09106539418019931\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09311116345448092\n",
      "    mean_inference_ms: 0.99732900307542\n",
      "    mean_raw_obs_processing_ms: 0.12267798962128978\n",
      "  time_since_restore: 127.77682399749756\n",
      "  time_this_iter_s: 10.04709267616272\n",
      "  time_total_s: 127.77682399749756\n",
      "  timers:\n",
      "    learn_throughput: 1290.537\n",
      "    learn_time_ms: 6197.422\n",
      "    load_throughput: 23695728.892\n",
      "    load_time_ms: 0.338\n",
      "    sample_throughput: 817.904\n",
      "    sample_time_ms: 9778.656\n",
      "    update_time_ms: 2.969\n",
      "  timestamp: 1645202501\n",
      "  timesteps_since_restore: 103974\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 103974\n",
      "  training_iteration: 13\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:41:43 (running for 00:28:40.49)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         127.777</td><td style=\"text-align: right;\"> 103974</td><td style=\"text-align: right;\">  199.05</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 165</td><td style=\"text-align: right;\">            199.05</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:41:48 (running for 00:28:45.50)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         127.777</td><td style=\"text-align: right;\"> 103974</td><td style=\"text-align: right;\">  199.05</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 165</td><td style=\"text-align: right;\">            199.05</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 111972\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-41-51\n",
      "  done: false\n",
      "  episode_len_mean: 199.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.28\n",
      "  episode_reward_min: 167.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 1048\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4906061887741089\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007679905276745558\n",
      "          model: {}\n",
      "          policy_loss: -0.010675976984202862\n",
      "          total_loss: 368.8087463378906\n",
      "          vf_explained_var: 0.41719549894332886\n",
      "          vf_loss: 368.81591796875\n",
      "    num_agent_steps_sampled: 111972\n",
      "    num_agent_steps_trained: 111972\n",
      "    num_steps_sampled: 111972\n",
      "    num_steps_trained: 111972\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.62857142857142\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09107661076947583\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09309437030403317\n",
      "    mean_inference_ms: 0.9979171276024019\n",
      "    mean_raw_obs_processing_ms: 0.12247557366494281\n",
      "  time_since_restore: 137.25328755378723\n",
      "  time_this_iter_s: 9.476463556289673\n",
      "  time_total_s: 137.25328755378723\n",
      "  timers:\n",
      "    learn_throughput: 1296.065\n",
      "    learn_time_ms: 6170.988\n",
      "    load_throughput: 23749411.251\n",
      "    load_time_ms: 0.337\n",
      "    sample_throughput: 817.184\n",
      "    sample_time_ms: 9787.272\n",
      "    update_time_ms: 2.908\n",
      "  timestamp: 1645202511\n",
      "  timesteps_since_restore: 111972\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 111972\n",
      "  training_iteration: 14\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:41:54 (running for 00:28:51.00)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         137.253</td><td style=\"text-align: right;\"> 111972</td><td style=\"text-align: right;\">  199.28</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 167</td><td style=\"text-align: right;\">            199.28</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:41:59 (running for 00:28:56.01)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         137.253</td><td style=\"text-align: right;\"> 111972</td><td style=\"text-align: right;\">  199.28</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 167</td><td style=\"text-align: right;\">            199.28</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 119970\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-42-01\n",
      "  done: false\n",
      "  episode_len_mean: 199.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.39\n",
      "  episode_reward_min: 170.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 1089\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4741091728210449\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008279461413621902\n",
      "          model: {}\n",
      "          policy_loss: -0.005445880349725485\n",
      "          total_loss: 304.76971435546875\n",
      "          vf_explained_var: 0.5791780948638916\n",
      "          vf_loss: 304.77142333984375\n",
      "    num_agent_steps_sampled: 119970\n",
      "    num_agent_steps_trained: 119970\n",
      "    num_steps_sampled: 119970\n",
      "    num_steps_trained: 119970\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.33571428571427\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09098524879751656\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0930439054175816\n",
      "    mean_inference_ms: 0.997294247691002\n",
      "    mean_raw_obs_processing_ms: 0.12217075063526937\n",
      "  time_since_restore: 147.15427589416504\n",
      "  time_this_iter_s: 9.900988340377808\n",
      "  time_total_s: 147.15427589416504\n",
      "  timers:\n",
      "    learn_throughput: 1290.876\n",
      "    learn_time_ms: 6195.794\n",
      "    load_throughput: 23944356.454\n",
      "    load_time_ms: 0.334\n",
      "    sample_throughput: 819.008\n",
      "    sample_time_ms: 9765.467\n",
      "    update_time_ms: 2.906\n",
      "  timestamp: 1645202521\n",
      "  timesteps_since_restore: 119970\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 119970\n",
      "  training_iteration: 15\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:42:05 (running for 00:29:01.92)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         147.154</td><td style=\"text-align: right;\"> 119970</td><td style=\"text-align: right;\">  199.39</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 170</td><td style=\"text-align: right;\">            199.39</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:42:10 (running for 00:29:06.93)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         147.154</td><td style=\"text-align: right;\"> 119970</td><td style=\"text-align: right;\">  199.39</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 170</td><td style=\"text-align: right;\">            199.39</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 127968\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-42-11\n",
      "  done: false\n",
      "  episode_len_mean: 198.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.85\n",
      "  episode_reward_min: 160.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 1129\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.47636276483535767\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007954642176628113\n",
      "          model: {}\n",
      "          policy_loss: -0.01129329763352871\n",
      "          total_loss: 318.8043212890625\n",
      "          vf_explained_var: 0.5264664888381958\n",
      "          vf_loss: 318.8120422363281\n",
      "    num_agent_steps_sampled: 127968\n",
      "    num_agent_steps_trained: 127968\n",
      "    num_steps_sampled: 127968\n",
      "    num_steps_trained: 127968\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.02000000000001\n",
      "    ram_util_percent: 17.81333333333334\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09102052233677575\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09312403438399938\n",
      "    mean_inference_ms: 0.9978422900444147\n",
      "    mean_raw_obs_processing_ms: 0.12210547081169314\n",
      "  time_since_restore: 157.35656833648682\n",
      "  time_this_iter_s: 10.202292442321777\n",
      "  time_total_s: 157.35656833648682\n",
      "  timers:\n",
      "    learn_throughput: 1283.988\n",
      "    learn_time_ms: 6229.031\n",
      "    load_throughput: 24106096.143\n",
      "    load_time_ms: 0.332\n",
      "    sample_throughput: 815.038\n",
      "    sample_time_ms: 9813.043\n",
      "    update_time_ms: 3.036\n",
      "  timestamp: 1645202531\n",
      "  timesteps_since_restore: 127968\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 127968\n",
      "  training_iteration: 16\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:42:15 (running for 00:29:12.15)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         157.357</td><td style=\"text-align: right;\"> 127968</td><td style=\"text-align: right;\">  198.85</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 160</td><td style=\"text-align: right;\">            198.85</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:42:20 (running for 00:29:17.16)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         157.357</td><td style=\"text-align: right;\"> 127968</td><td style=\"text-align: right;\">  198.85</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 160</td><td style=\"text-align: right;\">            198.85</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 135966\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-42-21\n",
      "  done: false\n",
      "  episode_len_mean: 198.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.94\n",
      "  episode_reward_min: 160.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 1169\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4728504419326782\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009199677966535091\n",
      "          model: {}\n",
      "          policy_loss: -0.010839330963790417\n",
      "          total_loss: 353.416259765625\n",
      "          vf_explained_var: 0.5299060344696045\n",
      "          vf_loss: 353.4229736328125\n",
      "    num_agent_steps_sampled: 135966\n",
      "    num_agent_steps_trained: 135966\n",
      "    num_steps_sampled: 135966\n",
      "    num_steps_trained: 135966\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.67142857142855\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09114332145190568\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09324355085887309\n",
      "    mean_inference_ms: 0.9989699805109247\n",
      "    mean_raw_obs_processing_ms: 0.12220237859486305\n",
      "  time_since_restore: 167.17417979240417\n",
      "  time_this_iter_s: 9.817611455917358\n",
      "  time_total_s: 167.17417979240417\n",
      "  timers:\n",
      "    learn_throughput: 1287.707\n",
      "    learn_time_ms: 6211.039\n",
      "    load_throughput: 24085326.962\n",
      "    load_time_ms: 0.332\n",
      "    sample_throughput: 811.186\n",
      "    sample_time_ms: 9859.637\n",
      "    update_time_ms: 2.891\n",
      "  timestamp: 1645202541\n",
      "  timesteps_since_restore: 135966\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 135966\n",
      "  training_iteration: 17\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:42:26 (running for 00:29:22.99)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         167.174</td><td style=\"text-align: right;\"> 135966</td><td style=\"text-align: right;\">  198.94</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 160</td><td style=\"text-align: right;\">            198.94</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 143964\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-42-31\n",
      "  done: false\n",
      "  episode_len_mean: 198.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.44\n",
      "  episode_reward_min: 157.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 1210\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4781825840473175\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008859445340931416\n",
      "          model: {}\n",
      "          policy_loss: -0.019909843802452087\n",
      "          total_loss: 289.7783508300781\n",
      "          vf_explained_var: 0.6115982532501221\n",
      "          vf_loss: 289.7942810058594\n",
      "    num_agent_steps_sampled: 143964\n",
      "    num_agent_steps_trained: 143964\n",
      "    num_steps_sampled: 143964\n",
      "    num_steps_trained: 143964\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.95384615384616\n",
      "    ram_util_percent: 17.800000000000004\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09114679407542589\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0932613777618558\n",
      "    mean_inference_ms: 0.9990607253349996\n",
      "    mean_raw_obs_processing_ms: 0.12215491488093143\n",
      "  time_since_restore: 176.82338738441467\n",
      "  time_this_iter_s: 9.649207592010498\n",
      "  time_total_s: 176.82338738441467\n",
      "  timers:\n",
      "    learn_throughput: 1286.212\n",
      "    learn_time_ms: 6218.26\n",
      "    load_throughput: 24054240.207\n",
      "    load_time_ms: 0.332\n",
      "    sample_throughput: 813.294\n",
      "    sample_time_ms: 9834.079\n",
      "    update_time_ms: 2.931\n",
      "  timestamp: 1645202551\n",
      "  timesteps_since_restore: 143964\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 143964\n",
      "  training_iteration: 18\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:42:32 (running for 00:29:28.62)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         176.823</td><td style=\"text-align: right;\"> 143964</td><td style=\"text-align: right;\">  198.44</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 157</td><td style=\"text-align: right;\">            198.44</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:42:37 (running for 00:29:33.68)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         176.823</td><td style=\"text-align: right;\"> 143964</td><td style=\"text-align: right;\">  198.44</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 157</td><td style=\"text-align: right;\">            198.44</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 151962\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-42-40\n",
      "  done: false\n",
      "  episode_len_mean: 198.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.97\n",
      "  episode_reward_min: 157.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 1249\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.45983925461769104\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00810336135327816\n",
      "          model: {}\n",
      "          policy_loss: -0.00650775246322155\n",
      "          total_loss: 304.92364501953125\n",
      "          vf_explained_var: 0.5427325963973999\n",
      "          vf_loss: 304.9265441894531\n",
      "    num_agent_steps_sampled: 151962\n",
      "    num_agent_steps_trained: 151962\n",
      "    num_steps_sampled: 151962\n",
      "    num_steps_trained: 151962\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.86428571428571\n",
      "    ram_util_percent: 17.828571428571433\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09112105371487819\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09316827983378884\n",
      "    mean_inference_ms: 0.998452297446779\n",
      "    mean_raw_obs_processing_ms: 0.1220158618833253\n",
      "  time_since_restore: 186.59113383293152\n",
      "  time_this_iter_s: 9.767746448516846\n",
      "  time_total_s: 186.59113383293152\n",
      "  timers:\n",
      "    learn_throughput: 1285.503\n",
      "    learn_time_ms: 6221.69\n",
      "    load_throughput: 24363456.6\n",
      "    load_time_ms: 0.328\n",
      "    sample_throughput: 813.058\n",
      "    sample_time_ms: 9836.932\n",
      "    update_time_ms: 2.896\n",
      "  timestamp: 1645202560\n",
      "  timesteps_since_restore: 151962\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 151962\n",
      "  training_iteration: 19\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:42:42 (running for 00:29:39.42)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         186.591</td><td style=\"text-align: right;\"> 151962</td><td style=\"text-align: right;\">  198.97</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 157</td><td style=\"text-align: right;\">            198.97</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:42:47 (running for 00:29:44.46)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         186.591</td><td style=\"text-align: right;\"> 151962</td><td style=\"text-align: right;\">  198.97</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 157</td><td style=\"text-align: right;\">            198.97</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 159960\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-42-50\n",
      "  done: false\n",
      "  episode_len_mean: 198.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.77\n",
      "  episode_reward_min: 157.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 1289\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4812379777431488\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009620284661650658\n",
      "          model: {}\n",
      "          policy_loss: -0.012211381457746029\n",
      "          total_loss: 309.2613220214844\n",
      "          vf_explained_var: 0.5907812118530273\n",
      "          vf_loss: 309.26922607421875\n",
      "    num_agent_steps_sampled: 159960\n",
      "    num_agent_steps_trained: 159960\n",
      "    num_steps_sampled: 159960\n",
      "    num_steps_trained: 159960\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.33571428571429\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09106274074760816\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09308699615741797\n",
      "    mean_inference_ms: 0.9979020496915382\n",
      "    mean_raw_obs_processing_ms: 0.12184461074482358\n",
      "  time_since_restore: 196.48017716407776\n",
      "  time_this_iter_s: 9.88904333114624\n",
      "  time_total_s: 196.48017716407776\n",
      "  timers:\n",
      "    learn_throughput: 1281.928\n",
      "    learn_time_ms: 6239.04\n",
      "    load_throughput: 24599283.854\n",
      "    load_time_ms: 0.325\n",
      "    sample_throughput: 813.365\n",
      "    sample_time_ms: 9833.218\n",
      "    update_time_ms: 2.881\n",
      "  timestamp: 1645202570\n",
      "  timesteps_since_restore: 159960\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 159960\n",
      "  training_iteration: 20\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:42:53 (running for 00:29:50.33)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">          196.48</td><td style=\"text-align: right;\"> 159960</td><td style=\"text-align: right;\">  198.77</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 157</td><td style=\"text-align: right;\">            198.77</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:42:58 (running for 00:29:55.38)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">          196.48</td><td style=\"text-align: right;\"> 159960</td><td style=\"text-align: right;\">  198.77</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 157</td><td style=\"text-align: right;\">            198.77</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 167958\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-43-00\n",
      "  done: false\n",
      "  episode_len_mean: 199.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.19\n",
      "  episode_reward_min: 170.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 1330\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.47153523564338684\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00797189399600029\n",
      "          model: {}\n",
      "          policy_loss: -0.00448327511548996\n",
      "          total_loss: 220.4894561767578\n",
      "          vf_explained_var: 0.7078279256820679\n",
      "          vf_loss: 220.49032592773438\n",
      "    num_agent_steps_sampled: 167958\n",
      "    num_agent_steps_trained: 167958\n",
      "    num_steps_sampled: 167958\n",
      "    num_steps_trained: 167958\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.29333333333331\n",
      "    ram_util_percent: 17.9\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09108835514506015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09308909162711472\n",
      "    mean_inference_ms: 0.9979332438557978\n",
      "    mean_raw_obs_processing_ms: 0.12176562676533834\n",
      "  time_since_restore: 206.38765931129456\n",
      "  time_this_iter_s: 9.907482147216797\n",
      "  time_total_s: 206.38765931129456\n",
      "  timers:\n",
      "    learn_throughput: 1279.665\n",
      "    learn_time_ms: 6250.071\n",
      "    load_throughput: 24628179.57\n",
      "    load_time_ms: 0.325\n",
      "    sample_throughput: 811.254\n",
      "    sample_time_ms: 9858.807\n",
      "    update_time_ms: 2.903\n",
      "  timestamp: 1645202580\n",
      "  timesteps_since_restore: 167958\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 167958\n",
      "  training_iteration: 21\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:43:03 (running for 00:30:00.40)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         206.388</td><td style=\"text-align: right;\"> 167958</td><td style=\"text-align: right;\">  199.19</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 170</td><td style=\"text-align: right;\">            199.19</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:43:08 (running for 00:30:05.44)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         206.388</td><td style=\"text-align: right;\"> 167958</td><td style=\"text-align: right;\">  199.19</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 170</td><td style=\"text-align: right;\">            199.19</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 175956\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-43-10\n",
      "  done: false\n",
      "  episode_len_mean: 198.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.66\n",
      "  episode_reward_min: 139.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 1370\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4763014316558838\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009575357660651207\n",
      "          model: {}\n",
      "          policy_loss: -0.00923082698136568\n",
      "          total_loss: 286.87274169921875\n",
      "          vf_explained_var: 0.6425071358680725\n",
      "          vf_loss: 286.8776550292969\n",
      "    num_agent_steps_sampled: 175956\n",
      "    num_agent_steps_trained: 175956\n",
      "    num_steps_sampled: 175956\n",
      "    num_steps_trained: 175956\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.90714285714286\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09111360040706254\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09309632825770903\n",
      "    mean_inference_ms: 1.0008101545542658\n",
      "    mean_raw_obs_processing_ms: 0.12173789522581785\n",
      "  time_since_restore: 216.4519383907318\n",
      "  time_this_iter_s: 10.064279079437256\n",
      "  time_total_s: 216.4519383907318\n",
      "  timers:\n",
      "    learn_throughput: 1284.876\n",
      "    learn_time_ms: 6224.725\n",
      "    load_throughput: 24620949.279\n",
      "    load_time_ms: 0.325\n",
      "    sample_throughput: 805.94\n",
      "    sample_time_ms: 9923.818\n",
      "    update_time_ms: 2.915\n",
      "  timestamp: 1645202590\n",
      "  timesteps_since_restore: 175956\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 175956\n",
      "  training_iteration: 22\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:43:14 (running for 00:30:11.36)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         216.452</td><td style=\"text-align: right;\"> 175956</td><td style=\"text-align: right;\">  198.66</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 139</td><td style=\"text-align: right;\">            198.66</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:43:19 (running for 00:30:16.40)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         216.452</td><td style=\"text-align: right;\"> 175956</td><td style=\"text-align: right;\">  198.66</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 139</td><td style=\"text-align: right;\">            198.66</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 183954\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-43-20\n",
      "  done: false\n",
      "  episode_len_mean: 198.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.41\n",
      "  episode_reward_min: 139.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 1411\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4798944592475891\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009793457575142384\n",
      "          model: {}\n",
      "          policy_loss: -0.024921951815485954\n",
      "          total_loss: 230.01425170898438\n",
      "          vf_explained_var: 0.7419348359107971\n",
      "          vf_loss: 230.03477478027344\n",
      "    num_agent_steps_sampled: 183954\n",
      "    num_agent_steps_trained: 183954\n",
      "    num_steps_sampled: 183954\n",
      "    num_steps_trained: 183954\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.79285714285713\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0911276281851887\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09314039392868743\n",
      "    mean_inference_ms: 1.0037142072151939\n",
      "    mean_raw_obs_processing_ms: 0.12171650898852256\n",
      "  time_since_restore: 226.18296575546265\n",
      "  time_this_iter_s: 9.731027364730835\n",
      "  time_total_s: 226.18296575546265\n",
      "  timers:\n",
      "    learn_throughput: 1288.788\n",
      "    learn_time_ms: 6205.831\n",
      "    load_throughput: 24581258.439\n",
      "    load_time_ms: 0.325\n",
      "    sample_throughput: 809.037\n",
      "    sample_time_ms: 9885.825\n",
      "    update_time_ms: 2.918\n",
      "  timestamp: 1645202600\n",
      "  timesteps_since_restore: 183954\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 183954\n",
      "  training_iteration: 23\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:43:25 (running for 00:30:22.11)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         226.183</td><td style=\"text-align: right;\"> 183954</td><td style=\"text-align: right;\">  198.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 139</td><td style=\"text-align: right;\">            198.41</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 191952\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-43-30\n",
      "  done: false\n",
      "  episode_len_mean: 199.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.24\n",
      "  episode_reward_min: 175.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 1450\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4572640061378479\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008500045165419579\n",
      "          model: {}\n",
      "          policy_loss: -0.010125434026122093\n",
      "          total_loss: 209.17721557617188\n",
      "          vf_explained_var: 0.7106572389602661\n",
      "          vf_loss: 209.18350219726562\n",
      "    num_agent_steps_sampled: 191952\n",
      "    num_agent_steps_trained: 191952\n",
      "    num_steps_sampled: 191952\n",
      "    num_steps_trained: 191952\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.57857142857144\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0911428353215261\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09310089228339344\n",
      "    mean_inference_ms: 1.004804834988365\n",
      "    mean_raw_obs_processing_ms: 0.12163877683866292\n",
      "  time_since_restore: 235.7297878265381\n",
      "  time_this_iter_s: 9.54682207107544\n",
      "  time_total_s: 235.7297878265381\n",
      "  timers:\n",
      "    learn_throughput: 1287.263\n",
      "    learn_time_ms: 6213.181\n",
      "    load_throughput: 24715275.467\n",
      "    load_time_ms: 0.324\n",
      "    sample_throughput: 810.665\n",
      "    sample_time_ms: 9865.977\n",
      "    update_time_ms: 2.923\n",
      "  timestamp: 1645202610\n",
      "  timesteps_since_restore: 191952\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 191952\n",
      "  training_iteration: 24\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:43:31 (running for 00:30:27.68)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">          235.73</td><td style=\"text-align: right;\"> 191952</td><td style=\"text-align: right;\">  199.24</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 175</td><td style=\"text-align: right;\">            199.24</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:43:36 (running for 00:30:32.69)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">          235.73</td><td style=\"text-align: right;\"> 191952</td><td style=\"text-align: right;\">  199.24</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 175</td><td style=\"text-align: right;\">            199.24</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 199950\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-43-39\n",
      "  done: false\n",
      "  episode_len_mean: 198.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.96\n",
      "  episode_reward_min: 168.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 1490\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4611431956291199\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010338908061385155\n",
      "          model: {}\n",
      "          policy_loss: -0.009321963414549828\n",
      "          total_loss: 182.01214599609375\n",
      "          vf_explained_var: 0.7355068922042847\n",
      "          vf_loss: 182.01683044433594\n",
      "    num_agent_steps_sampled: 199950\n",
      "    num_agent_steps_trained: 199950\n",
      "    num_steps_sampled: 199950\n",
      "    num_steps_trained: 199950\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.36153846153846\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09107427756111779\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09305835833995374\n",
      "    mean_inference_ms: 1.0038026087587435\n",
      "    mean_raw_obs_processing_ms: 0.12147378677763954\n",
      "  time_since_restore: 245.28385281562805\n",
      "  time_this_iter_s: 9.554064989089966\n",
      "  time_total_s: 245.28385281562805\n",
      "  timers:\n",
      "    learn_throughput: 1294.176\n",
      "    learn_time_ms: 6179.993\n",
      "    load_throughput: 24116494.171\n",
      "    load_time_ms: 0.332\n",
      "    sample_throughput: 810.215\n",
      "    sample_time_ms: 9871.46\n",
      "    update_time_ms: 2.927\n",
      "  timestamp: 1645202619\n",
      "  timesteps_since_restore: 199950\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 199950\n",
      "  training_iteration: 25\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:43:41 (running for 00:30:38.30)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         245.284</td><td style=\"text-align: right;\"> 199950</td><td style=\"text-align: right;\">  198.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 168</td><td style=\"text-align: right;\">            198.96</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:43:46 (running for 00:30:43.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         245.284</td><td style=\"text-align: right;\"> 199950</td><td style=\"text-align: right;\">  198.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 168</td><td style=\"text-align: right;\">            198.96</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 207948\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-43-49\n",
      "  done: false\n",
      "  episode_len_mean: 198.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.94\n",
      "  episode_reward_min: 162.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 1532\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4653139114379883\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009129205718636513\n",
      "          model: {}\n",
      "          policy_loss: -0.01382288709282875\n",
      "          total_loss: 263.6448059082031\n",
      "          vf_explained_var: 0.6862342953681946\n",
      "          vf_loss: 263.6545104980469\n",
      "    num_agent_steps_sampled: 207948\n",
      "    num_agent_steps_trained: 207948\n",
      "    num_steps_sampled: 207948\n",
      "    num_steps_trained: 207948\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.9142857142857\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09100702533918252\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09302049370246579\n",
      "    mean_inference_ms: 1.0029530869004653\n",
      "    mean_raw_obs_processing_ms: 0.121326220407948\n",
      "  time_since_restore: 254.9038245677948\n",
      "  time_this_iter_s: 9.619971752166748\n",
      "  time_total_s: 254.9038245677948\n",
      "  timers:\n",
      "    learn_throughput: 1301.251\n",
      "    learn_time_ms: 6146.391\n",
      "    load_throughput: 24671650.652\n",
      "    load_time_ms: 0.324\n",
      "    sample_throughput: 815.012\n",
      "    sample_time_ms: 9813.354\n",
      "    update_time_ms: 2.892\n",
      "  timestamp: 1645202629\n",
      "  timesteps_since_restore: 207948\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 207948\n",
      "  training_iteration: 26\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:43:52 (running for 00:30:48.95)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         254.904</td><td style=\"text-align: right;\"> 207948</td><td style=\"text-align: right;\">  198.94</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 162</td><td style=\"text-align: right;\">            198.94</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:43:57 (running for 00:30:53.96)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         254.904</td><td style=\"text-align: right;\"> 207948</td><td style=\"text-align: right;\">  198.94</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 162</td><td style=\"text-align: right;\">            198.94</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 215946\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-43-58\n",
      "  done: false\n",
      "  episode_len_mean: 199.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.42\n",
      "  episode_reward_min: 162.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 1571\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4548414647579193\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01168255228549242\n",
      "          model: {}\n",
      "          policy_loss: -0.013673542067408562\n",
      "          total_loss: 251.23475646972656\n",
      "          vf_explained_var: 0.6811316609382629\n",
      "          vf_loss: 251.24317932128906\n",
      "    num_agent_steps_sampled: 215946\n",
      "    num_agent_steps_trained: 215946\n",
      "    num_steps_sampled: 215946\n",
      "    num_steps_trained: 215946\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.5642857142857\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09099555820240919\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09300097349037084\n",
      "    mean_inference_ms: 1.002348785295243\n",
      "    mean_raw_obs_processing_ms: 0.1212201031312234\n",
      "  time_since_restore: 264.4815330505371\n",
      "  time_this_iter_s: 9.57770848274231\n",
      "  time_total_s: 264.4815330505371\n",
      "  timers:\n",
      "    learn_throughput: 1303.738\n",
      "    learn_time_ms: 6134.669\n",
      "    load_throughput: 24956140.003\n",
      "    load_time_ms: 0.32\n",
      "    sample_throughput: 818.839\n",
      "    sample_time_ms: 9767.483\n",
      "    update_time_ms: 2.887\n",
      "  timestamp: 1645202638\n",
      "  timesteps_since_restore: 215946\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 215946\n",
      "  training_iteration: 27\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:44:03 (running for 00:30:59.55)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         264.482</td><td style=\"text-align: right;\"> 215946</td><td style=\"text-align: right;\">  199.42</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 162</td><td style=\"text-align: right;\">            199.42</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:44:08 (running for 00:31:04.57)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         264.482</td><td style=\"text-align: right;\"> 215946</td><td style=\"text-align: right;\">  199.42</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 162</td><td style=\"text-align: right;\">            199.42</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 223944\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-44-08\n",
      "  done: false\n",
      "  episode_len_mean: 199.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.18\n",
      "  episode_reward_min: 149.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 1612\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4349973201751709\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009024829603731632\n",
      "          model: {}\n",
      "          policy_loss: -0.024384530261158943\n",
      "          total_loss: 319.912353515625\n",
      "          vf_explained_var: 0.5178573131561279\n",
      "          vf_loss: 319.9327087402344\n",
      "    num_agent_steps_sampled: 223944\n",
      "    num_agent_steps_trained: 223944\n",
      "    num_steps_sampled: 223944\n",
      "    num_steps_trained: 223944\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.96428571428571\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.090947449481442\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09298211106816014\n",
      "    mean_inference_ms: 1.0015783803304503\n",
      "    mean_raw_obs_processing_ms: 0.1211118609187726\n",
      "  time_since_restore: 274.2526090145111\n",
      "  time_this_iter_s: 9.771075963973999\n",
      "  time_total_s: 274.2526090145111\n",
      "  timers:\n",
      "    learn_throughput: 1301.753\n",
      "    learn_time_ms: 6144.022\n",
      "    load_throughput: 24948715.895\n",
      "    load_time_ms: 0.321\n",
      "    sample_throughput: 819.553\n",
      "    sample_time_ms: 9758.974\n",
      "    update_time_ms: 2.862\n",
      "  timestamp: 1645202648\n",
      "  timesteps_since_restore: 223944\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 223944\n",
      "  training_iteration: 28\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:44:13 (running for 00:31:10.35)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         274.253</td><td style=\"text-align: right;\"> 223944</td><td style=\"text-align: right;\">  199.18</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 149</td><td style=\"text-align: right;\">            199.18</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 231942\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-44-18\n",
      "  done: false\n",
      "  episode_len_mean: 198.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.01\n",
      "  episode_reward_min: 146.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 1652\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.42638564109802246\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010049420408904552\n",
      "          model: {}\n",
      "          policy_loss: -0.011372438631951809\n",
      "          total_loss: 286.56439208984375\n",
      "          vf_explained_var: 0.610058069229126\n",
      "          vf_loss: 286.57122802734375\n",
      "    num_agent_steps_sampled: 231942\n",
      "    num_agent_steps_trained: 231942\n",
      "    num_steps_sampled: 231942\n",
      "    num_steps_trained: 231942\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.72307692307692\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0909061488719115\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09294724062152365\n",
      "    mean_inference_ms: 1.001045763509676\n",
      "    mean_raw_obs_processing_ms: 0.1210045435887437\n",
      "  time_since_restore: 283.9042258262634\n",
      "  time_this_iter_s: 9.65161681175232\n",
      "  time_total_s: 283.9042258262634\n",
      "  timers:\n",
      "    learn_throughput: 1304.713\n",
      "    learn_time_ms: 6130.083\n",
      "    load_throughput: 24518376.986\n",
      "    load_time_ms: 0.326\n",
      "    sample_throughput: 818.541\n",
      "    sample_time_ms: 9771.042\n",
      "    update_time_ms: 2.853\n",
      "  timestamp: 1645202658\n",
      "  timesteps_since_restore: 231942\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 231942\n",
      "  training_iteration: 29\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:44:19 (running for 00:31:15.98)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         283.904</td><td style=\"text-align: right;\"> 231942</td><td style=\"text-align: right;\">  198.01</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            198.01</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:44:24 (running for 00:31:21.03)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         283.904</td><td style=\"text-align: right;\"> 231942</td><td style=\"text-align: right;\">  198.01</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            198.01</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 239940\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-44-27\n",
      "  done: false\n",
      "  episode_len_mean: 198.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.27\n",
      "  episode_reward_min: 146.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 1693\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4148794412612915\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010393347591161728\n",
      "          model: {}\n",
      "          policy_loss: -0.01856049709022045\n",
      "          total_loss: 281.065673828125\n",
      "          vf_explained_var: 0.6280584335327148\n",
      "          vf_loss: 281.0795593261719\n",
      "    num_agent_steps_sampled: 239940\n",
      "    num_agent_steps_trained: 239940\n",
      "    num_steps_sampled: 239940\n",
      "    num_steps_trained: 239940\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.64999999999999\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09083177881698994\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09291479950707611\n",
      "    mean_inference_ms: 1.0002043982902287\n",
      "    mean_raw_obs_processing_ms: 0.12088263541476177\n",
      "  time_since_restore: 293.30463099479675\n",
      "  time_this_iter_s: 9.400405168533325\n",
      "  time_total_s: 293.30463099479675\n",
      "  timers:\n",
      "    learn_throughput: 1312.329\n",
      "    learn_time_ms: 6094.51\n",
      "    load_throughput: 24213976.752\n",
      "    load_time_ms: 0.33\n",
      "    sample_throughput: 820.827\n",
      "    sample_time_ms: 9743.827\n",
      "    update_time_ms: 2.792\n",
      "  timestamp: 1645202667\n",
      "  timesteps_since_restore: 239940\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 239940\n",
      "  training_iteration: 30\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:44:29 (running for 00:31:26.41)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         293.305</td><td style=\"text-align: right;\"> 239940</td><td style=\"text-align: right;\">  198.27</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            198.27</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:44:34 (running for 00:31:31.46)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         293.305</td><td style=\"text-align: right;\"> 239940</td><td style=\"text-align: right;\">  198.27</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            198.27</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 247938\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-44-37\n",
      "  done: false\n",
      "  episode_len_mean: 198.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.47\n",
      "  episode_reward_min: 146.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 1732\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4072360694408417\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008062144741415977\n",
      "          model: {}\n",
      "          policy_loss: -0.00820006150752306\n",
      "          total_loss: 285.82513427734375\n",
      "          vf_explained_var: 0.6022472977638245\n",
      "          vf_loss: 285.8297424316406\n",
      "    num_agent_steps_sampled: 247938\n",
      "    num_agent_steps_trained: 247938\n",
      "    num_steps_sampled: 247938\n",
      "    num_steps_trained: 247938\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.10714285714286\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09080162925386609\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09286080021833673\n",
      "    mean_inference_ms: 0.9996411506556995\n",
      "    mean_raw_obs_processing_ms: 0.12075547496720468\n",
      "  time_since_restore: 303.0208775997162\n",
      "  time_this_iter_s: 9.716246604919434\n",
      "  time_total_s: 303.0208775997162\n",
      "  timers:\n",
      "    learn_throughput: 1313.627\n",
      "    learn_time_ms: 6088.486\n",
      "    load_throughput: 24168619.159\n",
      "    load_time_ms: 0.331\n",
      "    sample_throughput: 824.972\n",
      "    sample_time_ms: 9694.876\n",
      "    update_time_ms: 2.8\n",
      "  timestamp: 1645202677\n",
      "  timesteps_since_restore: 247938\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 247938\n",
      "  training_iteration: 31\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:44:40 (running for 00:31:37.15)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         303.021</td><td style=\"text-align: right;\"> 247938</td><td style=\"text-align: right;\">  198.47</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            198.47</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:44:45 (running for 00:31:42.20)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         303.021</td><td style=\"text-align: right;\"> 247938</td><td style=\"text-align: right;\">  198.47</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            198.47</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 255936\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-44-47\n",
      "  done: false\n",
      "  episode_len_mean: 199.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.55\n",
      "  episode_reward_min: 177.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 1772\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.42091643810272217\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009615751914680004\n",
      "          model: {}\n",
      "          policy_loss: -0.010212303139269352\n",
      "          total_loss: 290.7409973144531\n",
      "          vf_explained_var: 0.6224746108055115\n",
      "          vf_loss: 290.74688720703125\n",
      "    num_agent_steps_sampled: 255936\n",
      "    num_agent_steps_trained: 255936\n",
      "    num_steps_sampled: 255936\n",
      "    num_steps_trained: 255936\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.42142857142858\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0908214294296153\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09289772875653679\n",
      "    mean_inference_ms: 0.9995802323991083\n",
      "    mean_raw_obs_processing_ms: 0.1207523331712448\n",
      "  time_since_restore: 313.0343191623688\n",
      "  time_this_iter_s: 10.013441562652588\n",
      "  time_total_s: 313.0343191623688\n",
      "  timers:\n",
      "    learn_throughput: 1308.238\n",
      "    learn_time_ms: 6113.566\n",
      "    load_throughput: 23610672.432\n",
      "    load_time_ms: 0.339\n",
      "    sample_throughput: 828.04\n",
      "    sample_time_ms: 9658.955\n",
      "    update_time_ms: 2.827\n",
      "  timestamp: 1645202687\n",
      "  timesteps_since_restore: 255936\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 255936\n",
      "  training_iteration: 32\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:44:51 (running for 00:31:48.19)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         313.034</td><td style=\"text-align: right;\"> 255936</td><td style=\"text-align: right;\">  199.55</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 177</td><td style=\"text-align: right;\">            199.55</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:44:56 (running for 00:31:53.24)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         313.034</td><td style=\"text-align: right;\"> 255936</td><td style=\"text-align: right;\">  199.55</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 177</td><td style=\"text-align: right;\">            199.55</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 263934\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-44-57\n",
      "  done: false\n",
      "  episode_len_mean: 199.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.84\n",
      "  episode_reward_min: 184.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 1813\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4183536767959595\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010461087338626385\n",
      "          model: {}\n",
      "          policy_loss: -0.02518894150853157\n",
      "          total_loss: 261.2120361328125\n",
      "          vf_explained_var: 0.6929173469543457\n",
      "          vf_loss: 261.2325134277344\n",
      "    num_agent_steps_sampled: 263934\n",
      "    num_agent_steps_trained: 263934\n",
      "    num_steps_sampled: 263934\n",
      "    num_steps_trained: 263934\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.87857142857142\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0908496454697272\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09292037924083602\n",
      "    mean_inference_ms: 0.9996928201810659\n",
      "    mean_raw_obs_processing_ms: 0.12076149133879603\n",
      "  time_since_restore: 322.7932274341583\n",
      "  time_this_iter_s: 9.75890827178955\n",
      "  time_total_s: 322.7932274341583\n",
      "  timers:\n",
      "    learn_throughput: 1304.579\n",
      "    learn_time_ms: 6130.712\n",
      "    load_throughput: 23509736.766\n",
      "    load_time_ms: 0.34\n",
      "    sample_throughput: 827.127\n",
      "    sample_time_ms: 9669.62\n",
      "    update_time_ms: 2.806\n",
      "  timestamp: 1645202697\n",
      "  timesteps_since_restore: 263934\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 263934\n",
      "  training_iteration: 33\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:45:02 (running for 00:31:58.98)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         322.793</td><td style=\"text-align: right;\"> 263934</td><td style=\"text-align: right;\">  199.84</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 184</td><td style=\"text-align: right;\">            199.84</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 271932\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-45-07\n",
      "  done: false\n",
      "  episode_len_mean: 199.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.22\n",
      "  episode_reward_min: 176.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 1852\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4349985122680664\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00792869832366705\n",
      "          model: {}\n",
      "          policy_loss: -0.009073153138160706\n",
      "          total_loss: 314.7040100097656\n",
      "          vf_explained_var: 0.6380570530891418\n",
      "          vf_loss: 314.7095031738281\n",
      "    num_agent_steps_sampled: 271932\n",
      "    num_agent_steps_trained: 271932\n",
      "    num_steps_sampled: 271932\n",
      "    num_steps_trained: 271932\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.92142857142856\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09088870781437379\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09294189712227835\n",
      "    mean_inference_ms: 0.9998075605668382\n",
      "    mean_raw_obs_processing_ms: 0.12077583870464405\n",
      "  time_since_restore: 332.68519926071167\n",
      "  time_this_iter_s: 9.891971826553345\n",
      "  time_total_s: 332.68519926071167\n",
      "  timers:\n",
      "    learn_throughput: 1299.715\n",
      "    learn_time_ms: 6153.657\n",
      "    load_throughput: 23055699.926\n",
      "    load_time_ms: 0.347\n",
      "    sample_throughput: 824.658\n",
      "    sample_time_ms: 9698.57\n",
      "    update_time_ms: 2.823\n",
      "  timestamp: 1645202707\n",
      "  timesteps_since_restore: 271932\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 271932\n",
      "  training_iteration: 34\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:45:08 (running for 00:32:04.90)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         332.685</td><td style=\"text-align: right;\"> 271932</td><td style=\"text-align: right;\">  199.22</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 176</td><td style=\"text-align: right;\">            199.22</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:45:13 (running for 00:32:09.91)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         332.685</td><td style=\"text-align: right;\"> 271932</td><td style=\"text-align: right;\">  199.22</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 176</td><td style=\"text-align: right;\">            199.22</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 279930\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-45-17\n",
      "  done: false\n",
      "  episode_len_mean: 197.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.88\n",
      "  episode_reward_min: 148.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 1894\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4209989607334137\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009986413642764091\n",
      "          model: {}\n",
      "          policy_loss: -0.018722552806138992\n",
      "          total_loss: 212.2120361328125\n",
      "          vf_explained_var: 0.7213494181632996\n",
      "          vf_loss: 212.2262420654297\n",
      "    num_agent_steps_sampled: 279930\n",
      "    num_agent_steps_trained: 279930\n",
      "    num_steps_sampled: 279930\n",
      "    num_steps_trained: 279930\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.93571428571428\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09087780423620967\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09296492951339273\n",
      "    mean_inference_ms: 0.9995850718323724\n",
      "    mean_raw_obs_processing_ms: 0.12075022756241499\n",
      "  time_since_restore: 342.36329102516174\n",
      "  time_this_iter_s: 9.678091764450073\n",
      "  time_total_s: 342.36329102516174\n",
      "  timers:\n",
      "    learn_throughput: 1298.176\n",
      "    learn_time_ms: 6160.952\n",
      "    load_throughput: 23613996.475\n",
      "    load_time_ms: 0.339\n",
      "    sample_throughput: 822.23\n",
      "    sample_time_ms: 9727.207\n",
      "    update_time_ms: 2.779\n",
      "  timestamp: 1645202717\n",
      "  timesteps_since_restore: 279930\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 279930\n",
      "  training_iteration: 35\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:45:19 (running for 00:32:15.60)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         342.363</td><td style=\"text-align: right;\"> 279930</td><td style=\"text-align: right;\">  197.88</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 148</td><td style=\"text-align: right;\">            197.88</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:45:24 (running for 00:32:20.61)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         342.363</td><td style=\"text-align: right;\"> 279930</td><td style=\"text-align: right;\">  197.88</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 148</td><td style=\"text-align: right;\">            197.88</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 287928\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-45-26\n",
      "  done: false\n",
      "  episode_len_mean: 197.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.65\n",
      "  episode_reward_min: 148.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 1934\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4204840660095215\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010086842812597752\n",
      "          model: {}\n",
      "          policy_loss: -0.013619496487081051\n",
      "          total_loss: 262.4637756347656\n",
      "          vf_explained_var: 0.6725555658340454\n",
      "          vf_loss: 262.4728698730469\n",
      "    num_agent_steps_sampled: 287928\n",
      "    num_agent_steps_trained: 287928\n",
      "    num_steps_sampled: 287928\n",
      "    num_steps_trained: 287928\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.24285714285715\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0908697780791645\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09293651238038109\n",
      "    mean_inference_ms: 0.9993894013610537\n",
      "    mean_raw_obs_processing_ms: 0.1207117956177408\n",
      "  time_since_restore: 351.83195781707764\n",
      "  time_this_iter_s: 9.468666791915894\n",
      "  time_total_s: 351.83195781707764\n",
      "  timers:\n",
      "    learn_throughput: 1300.252\n",
      "    learn_time_ms: 6151.116\n",
      "    load_throughput: 23152766.507\n",
      "    load_time_ms: 0.345\n",
      "    sample_throughput: 822.069\n",
      "    sample_time_ms: 9729.108\n",
      "    update_time_ms: 2.813\n",
      "  timestamp: 1645202726\n",
      "  timesteps_since_restore: 287928\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 287928\n",
      "  training_iteration: 36\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:45:29 (running for 00:32:26.14)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         351.832</td><td style=\"text-align: right;\"> 287928</td><td style=\"text-align: right;\">  197.65</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 148</td><td style=\"text-align: right;\">            197.65</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:45:34 (running for 00:32:31.15)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         351.832</td><td style=\"text-align: right;\"> 287928</td><td style=\"text-align: right;\">  197.65</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 148</td><td style=\"text-align: right;\">            197.65</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 295926\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-45-36\n",
      "  done: false\n",
      "  episode_len_mean: 198.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.62\n",
      "  episode_reward_min: 164.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 1974\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4036537706851959\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00964562501758337\n",
      "          model: {}\n",
      "          policy_loss: -0.01961488276720047\n",
      "          total_loss: 218.1288604736328\n",
      "          vf_explained_var: 0.6880064010620117\n",
      "          vf_loss: 218.14414978027344\n",
      "    num_agent_steps_sampled: 295926\n",
      "    num_agent_steps_trained: 295926\n",
      "    num_steps_sampled: 295926\n",
      "    num_steps_trained: 295926\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.92307692307692\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09078694589333881\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09286410331937134\n",
      "    mean_inference_ms: 0.9985808635026213\n",
      "    mean_raw_obs_processing_ms: 0.12056508834690025\n",
      "  time_since_restore: 361.3269603252411\n",
      "  time_this_iter_s: 9.495002508163452\n",
      "  time_total_s: 361.3269603252411\n",
      "  timers:\n",
      "    learn_throughput: 1300.399\n",
      "    learn_time_ms: 6150.421\n",
      "    load_throughput: 22870223.202\n",
      "    load_time_ms: 0.35\n",
      "    sample_throughput: 823.591\n",
      "    sample_time_ms: 9711.135\n",
      "    update_time_ms: 2.998\n",
      "  timestamp: 1645202736\n",
      "  timesteps_since_restore: 295926\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 295926\n",
      "  training_iteration: 37\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:45:40 (running for 00:32:36.68)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         361.327</td><td style=\"text-align: right;\"> 295926</td><td style=\"text-align: right;\">  198.62</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 164</td><td style=\"text-align: right;\">            198.62</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:45:45 (running for 00:32:41.69)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         361.327</td><td style=\"text-align: right;\"> 295926</td><td style=\"text-align: right;\">  198.62</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 164</td><td style=\"text-align: right;\">            198.62</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 303924\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-45-46\n",
      "  done: false\n",
      "  episode_len_mean: 198.23\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.23\n",
      "  episode_reward_min: 152.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 2014\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4112594723701477\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010532421991229057\n",
      "          model: {}\n",
      "          policy_loss: -0.015249524265527725\n",
      "          total_loss: 282.9184265136719\n",
      "          vf_explained_var: 0.6397879719734192\n",
      "          vf_loss: 282.92889404296875\n",
      "    num_agent_steps_sampled: 303924\n",
      "    num_agent_steps_trained: 303924\n",
      "    num_steps_sampled: 303924\n",
      "    num_steps_trained: 303924\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.5\n",
      "    ram_util_percent: 17.9\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09079277065823063\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09282086106467002\n",
      "    mean_inference_ms: 0.9984565231662579\n",
      "    mean_raw_obs_processing_ms: 0.12049097916449966\n",
      "  time_since_restore: 371.40564012527466\n",
      "  time_this_iter_s: 10.07867980003357\n",
      "  time_total_s: 371.40564012527466\n",
      "  timers:\n",
      "    learn_throughput: 1296.972\n",
      "    learn_time_ms: 6166.67\n",
      "    load_throughput: 22928059.184\n",
      "    load_time_ms: 0.349\n",
      "    sample_throughput: 822.421\n",
      "    sample_time_ms: 9724.951\n",
      "    update_time_ms: 2.997\n",
      "  timestamp: 1645202746\n",
      "  timesteps_since_restore: 303924\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 303924\n",
      "  training_iteration: 38\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:45:50 (running for 00:32:46.77)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         371.406</td><td style=\"text-align: right;\"> 303924</td><td style=\"text-align: right;\">  198.23</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 152</td><td style=\"text-align: right;\">            198.23</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:45:55 (running for 00:32:51.77)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         371.406</td><td style=\"text-align: right;\"> 303924</td><td style=\"text-align: right;\">  198.23</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 152</td><td style=\"text-align: right;\">            198.23</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 311922\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-45-56\n",
      "  done: false\n",
      "  episode_len_mean: 198.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.65\n",
      "  episode_reward_min: 152.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 2055\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.40861743688583374\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008717755787074566\n",
      "          model: {}\n",
      "          policy_loss: -0.005743047222495079\n",
      "          total_loss: 353.6675109863281\n",
      "          vf_explained_var: 0.5339203476905823\n",
      "          vf_loss: 353.6693420410156\n",
      "    num_agent_steps_sampled: 311922\n",
      "    num_agent_steps_trained: 311922\n",
      "    num_steps_sampled: 311922\n",
      "    num_steps_trained: 311922\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.74285714285715\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09081411820464963\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09289541304744944\n",
      "    mean_inference_ms: 0.998560111656094\n",
      "    mean_raw_obs_processing_ms: 0.12048691438077927\n",
      "  time_since_restore: 381.2890655994415\n",
      "  time_this_iter_s: 9.88342547416687\n",
      "  time_total_s: 381.2890655994415\n",
      "  timers:\n",
      "    learn_throughput: 1294.517\n",
      "    learn_time_ms: 6178.366\n",
      "    load_throughput: 23360754.451\n",
      "    load_time_ms: 0.342\n",
      "    sample_throughput: 820.09\n",
      "    sample_time_ms: 9752.588\n",
      "    update_time_ms: 3.009\n",
      "  timestamp: 1645202756\n",
      "  timesteps_since_restore: 311922\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 311922\n",
      "  training_iteration: 39\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:46:01 (running for 00:32:57.68)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         381.289</td><td style=\"text-align: right;\"> 311922</td><td style=\"text-align: right;\">  198.65</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 152</td><td style=\"text-align: right;\">            198.65</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 319920\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-46-05\n",
      "  done: false\n",
      "  episode_len_mean: 199.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.25\n",
      "  episode_reward_min: 152.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 2094\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4070355296134949\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009265130385756493\n",
      "          model: {}\n",
      "          policy_loss: -0.007585790939629078\n",
      "          total_loss: 435.3047180175781\n",
      "          vf_explained_var: 0.3686998784542084\n",
      "          vf_loss: 435.3081359863281\n",
      "    num_agent_steps_sampled: 319920\n",
      "    num_agent_steps_trained: 319920\n",
      "    num_steps_sampled: 319920\n",
      "    num_steps_trained: 319920\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.86428571428571\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09089490661128127\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0929580911215044\n",
      "    mean_inference_ms: 0.9991091516332957\n",
      "    mean_raw_obs_processing_ms: 0.12053634054933288\n",
      "  time_since_restore: 391.0905828475952\n",
      "  time_this_iter_s: 9.801517248153687\n",
      "  time_total_s: 391.0905828475952\n",
      "  timers:\n",
      "    learn_throughput: 1289.767\n",
      "    learn_time_ms: 6201.118\n",
      "    load_throughput: 23439102.426\n",
      "    load_time_ms: 0.341\n",
      "    sample_throughput: 817.627\n",
      "    sample_time_ms: 9781.962\n",
      "    update_time_ms: 3.085\n",
      "  timestamp: 1645202765\n",
      "  timesteps_since_restore: 319920\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 319920\n",
      "  training_iteration: 40\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:46:06 (running for 00:33:03.46)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         391.091</td><td style=\"text-align: right;\"> 319920</td><td style=\"text-align: right;\">  199.25</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 152</td><td style=\"text-align: right;\">            199.25</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:46:11 (running for 00:33:08.52)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         391.091</td><td style=\"text-align: right;\"> 319920</td><td style=\"text-align: right;\">  199.25</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 152</td><td style=\"text-align: right;\">            199.25</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 327918\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-46-15\n",
      "  done: false\n",
      "  episode_len_mean: 199.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.34\n",
      "  episode_reward_min: 164.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 2135\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3826543986797333\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00881976168602705\n",
      "          model: {}\n",
      "          policy_loss: -0.005119019187986851\n",
      "          total_loss: 342.3204650878906\n",
      "          vf_explained_var: 0.4842180907726288\n",
      "          vf_loss: 342.3216247558594\n",
      "    num_agent_steps_sampled: 327918\n",
      "    num_agent_steps_trained: 327918\n",
      "    num_steps_sampled: 327918\n",
      "    num_steps_trained: 327918\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.7642857142857\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09093523515901673\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09300043095542967\n",
      "    mean_inference_ms: 0.9993036517842966\n",
      "    mean_raw_obs_processing_ms: 0.12055806762351966\n",
      "  time_since_restore: 400.8618462085724\n",
      "  time_this_iter_s: 9.771263360977173\n",
      "  time_total_s: 400.8618462085724\n",
      "  timers:\n",
      "    learn_throughput: 1289.849\n",
      "    learn_time_ms: 6200.724\n",
      "    load_throughput: 23380292.3\n",
      "    load_time_ms: 0.342\n",
      "    sample_throughput: 815.218\n",
      "    sample_time_ms: 9810.869\n",
      "    update_time_ms: 3.057\n",
      "  timestamp: 1645202775\n",
      "  timesteps_since_restore: 327918\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 327918\n",
      "  training_iteration: 41\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:46:17 (running for 00:33:14.26)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         400.862</td><td style=\"text-align: right;\"> 327918</td><td style=\"text-align: right;\">  199.34</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 164</td><td style=\"text-align: right;\">            199.34</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:46:22 (running for 00:33:19.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         400.862</td><td style=\"text-align: right;\"> 327918</td><td style=\"text-align: right;\">  199.34</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 164</td><td style=\"text-align: right;\">            199.34</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 335916\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-46-25\n",
      "  done: false\n",
      "  episode_len_mean: 198.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.53\n",
      "  episode_reward_min: 164.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 2175\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3912767171859741\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009542951360344887\n",
      "          model: {}\n",
      "          policy_loss: -0.009422960691154003\n",
      "          total_loss: 394.7413330078125\n",
      "          vf_explained_var: 0.39061999320983887\n",
      "          vf_loss: 394.7464294433594\n",
      "    num_agent_steps_sampled: 335916\n",
      "    num_agent_steps_trained: 335916\n",
      "    num_steps_sampled: 335916\n",
      "    num_steps_trained: 335916\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.86153846153846\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09093365003406838\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09299235344761993\n",
      "    mean_inference_ms: 0.9991992659788752\n",
      "    mean_raw_obs_processing_ms: 0.12054371653209081\n",
      "  time_since_restore: 410.44216799736023\n",
      "  time_this_iter_s: 9.580321788787842\n",
      "  time_total_s: 410.44216799736023\n",
      "  timers:\n",
      "    learn_throughput: 1295.359\n",
      "    learn_time_ms: 6174.352\n",
      "    load_throughput: 23011416.787\n",
      "    load_time_ms: 0.348\n",
      "    sample_throughput: 816.684\n",
      "    sample_time_ms: 9793.263\n",
      "    update_time_ms: 3.0\n",
      "  timestamp: 1645202785\n",
      "  timesteps_since_restore: 335916\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 335916\n",
      "  training_iteration: 42\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:46:28 (running for 00:33:24.86)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         410.442</td><td style=\"text-align: right;\"> 335916</td><td style=\"text-align: right;\">  198.53</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 164</td><td style=\"text-align: right;\">            198.53</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:46:33 (running for 00:33:29.90)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         410.442</td><td style=\"text-align: right;\"> 335916</td><td style=\"text-align: right;\">  198.53</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 164</td><td style=\"text-align: right;\">            198.53</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 343914\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-46-35\n",
      "  done: false\n",
      "  episode_len_mean: 198.23\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.23\n",
      "  episode_reward_min: 146.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 2215\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3950691521167755\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009140188805758953\n",
      "          model: {}\n",
      "          policy_loss: -0.00723284250125289\n",
      "          total_loss: 394.7769470214844\n",
      "          vf_explained_var: 0.39401665329933167\n",
      "          vf_loss: 394.780029296875\n",
      "    num_agent_steps_sampled: 343914\n",
      "    num_agent_steps_trained: 343914\n",
      "    num_steps_sampled: 343914\n",
      "    num_steps_trained: 343914\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.15333333333334\n",
      "    ram_util_percent: 17.9\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09090706917501101\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09296527754031034\n",
      "    mean_inference_ms: 0.9989734704257179\n",
      "    mean_raw_obs_processing_ms: 0.1204874658372978\n",
      "  time_since_restore: 420.3655204772949\n",
      "  time_this_iter_s: 9.923352479934692\n",
      "  time_total_s: 420.3655204772949\n",
      "  timers:\n",
      "    learn_throughput: 1293.827\n",
      "    learn_time_ms: 6181.659\n",
      "    load_throughput: 22806474.534\n",
      "    load_time_ms: 0.351\n",
      "    sample_throughput: 818.115\n",
      "    sample_time_ms: 9776.137\n",
      "    update_time_ms: 2.954\n",
      "  timestamp: 1645202795\n",
      "  timesteps_since_restore: 343914\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 343914\n",
      "  training_iteration: 43\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:46:39 (running for 00:33:35.81)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         420.366</td><td style=\"text-align: right;\"> 343914</td><td style=\"text-align: right;\">  198.23</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            198.23</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:46:44 (running for 00:33:40.86)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         420.366</td><td style=\"text-align: right;\"> 343914</td><td style=\"text-align: right;\">  198.23</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            198.23</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 351912\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-46-45\n",
      "  done: false\n",
      "  episode_len_mean: 197.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.32\n",
      "  episode_reward_min: 118.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 2257\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.39501702785491943\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008528664708137512\n",
      "          model: {}\n",
      "          policy_loss: -0.014469021931290627\n",
      "          total_loss: 361.3084716796875\n",
      "          vf_explained_var: 0.4771832227706909\n",
      "          vf_loss: 361.319091796875\n",
      "    num_agent_steps_sampled: 351912\n",
      "    num_agent_steps_trained: 351912\n",
      "    num_steps_sampled: 351912\n",
      "    num_steps_trained: 351912\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.61428571428571\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09084363258574418\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09294200757862957\n",
      "    mean_inference_ms: 0.9985320258692073\n",
      "    mean_raw_obs_processing_ms: 0.12040700056040103\n",
      "  time_since_restore: 430.1392343044281\n",
      "  time_this_iter_s: 9.773713827133179\n",
      "  time_total_s: 430.1392343044281\n",
      "  timers:\n",
      "    learn_throughput: 1294.804\n",
      "    learn_time_ms: 6176.995\n",
      "    load_throughput: 22152838.534\n",
      "    load_time_ms: 0.361\n",
      "    sample_throughput: 818.144\n",
      "    sample_time_ms: 9775.786\n",
      "    update_time_ms: 2.961\n",
      "  timestamp: 1645202805\n",
      "  timesteps_since_restore: 351912\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 351912\n",
      "  training_iteration: 44\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:46:50 (running for 00:33:46.61)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         430.139</td><td style=\"text-align: right;\"> 351912</td><td style=\"text-align: right;\">  197.32</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 118</td><td style=\"text-align: right;\">            197.32</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 359910\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-46-54\n",
      "  done: false\n",
      "  episode_len_mean: 197.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.2\n",
      "  episode_reward_min: 118.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 2296\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4033048450946808\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008369803428649902\n",
      "          model: {}\n",
      "          policy_loss: -0.008879103697836399\n",
      "          total_loss: 420.0589904785156\n",
      "          vf_explained_var: 0.3222815692424774\n",
      "          vf_loss: 420.0641174316406\n",
      "    num_agent_steps_sampled: 359910\n",
      "    num_agent_steps_trained: 359910\n",
      "    num_steps_sampled: 359910\n",
      "    num_steps_trained: 359910\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.24285714285715\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09087056499917928\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09292508182884447\n",
      "    mean_inference_ms: 0.9986608295199761\n",
      "    mean_raw_obs_processing_ms: 0.12039967788603281\n",
      "  time_since_restore: 440.0027275085449\n",
      "  time_this_iter_s: 9.863493204116821\n",
      "  time_total_s: 440.0027275085449\n",
      "  timers:\n",
      "    learn_throughput: 1293.257\n",
      "    learn_time_ms: 6184.385\n",
      "    load_throughput: 21617504.441\n",
      "    load_time_ms: 0.37\n",
      "    sample_throughput: 817.636\n",
      "    sample_time_ms: 9781.863\n",
      "    update_time_ms: 2.99\n",
      "  timestamp: 1645202814\n",
      "  timesteps_since_restore: 359910\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 359910\n",
      "  training_iteration: 45\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:46:55 (running for 00:33:52.50)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         440.003</td><td style=\"text-align: right;\"> 359910</td><td style=\"text-align: right;\">  197.2 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 118</td><td style=\"text-align: right;\">            197.2 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:47:00 (running for 00:33:57.50)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         440.003</td><td style=\"text-align: right;\"> 359910</td><td style=\"text-align: right;\">  197.2 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 118</td><td style=\"text-align: right;\">            197.2 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 367908\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-47-04\n",
      "  done: false\n",
      "  episode_len_mean: 196.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.52\n",
      "  episode_reward_min: 114.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 2338\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3960992097854614\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009073448367416859\n",
      "          model: {}\n",
      "          policy_loss: -0.006315571255981922\n",
      "          total_loss: 358.41412353515625\n",
      "          vf_explained_var: 0.5220722556114197\n",
      "          vf_loss: 358.4163513183594\n",
      "    num_agent_steps_sampled: 367908\n",
      "    num_agent_steps_trained: 367908\n",
      "    num_steps_sampled: 367908\n",
      "    num_steps_trained: 367908\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.47692307692309\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09083889800615637\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09292054120114124\n",
      "    mean_inference_ms: 0.9984606986466936\n",
      "    mean_raw_obs_processing_ms: 0.12034653908244536\n",
      "  time_since_restore: 449.52052545547485\n",
      "  time_this_iter_s: 9.517797946929932\n",
      "  time_total_s: 449.52052545547485\n",
      "  timers:\n",
      "    learn_throughput: 1292.351\n",
      "    learn_time_ms: 6188.72\n",
      "    load_throughput: 21737975.241\n",
      "    load_time_ms: 0.368\n",
      "    sample_throughput: 816.902\n",
      "    sample_time_ms: 9790.652\n",
      "    update_time_ms: 2.886\n",
      "  timestamp: 1645202824\n",
      "  timesteps_since_restore: 367908\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 367908\n",
      "  training_iteration: 46\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:47:06 (running for 00:34:03.04)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         449.521</td><td style=\"text-align: right;\"> 367908</td><td style=\"text-align: right;\">  196.52</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 114</td><td style=\"text-align: right;\">            196.52</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:47:11 (running for 00:34:08.05)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         449.521</td><td style=\"text-align: right;\"> 367908</td><td style=\"text-align: right;\">  196.52</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 114</td><td style=\"text-align: right;\">            196.52</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 375906\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-47-14\n",
      "  done: false\n",
      "  episode_len_mean: 195.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.84\n",
      "  episode_reward_min: 114.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 2378\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3937840759754181\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008590025827288628\n",
      "          model: {}\n",
      "          policy_loss: -0.009620340541005135\n",
      "          total_loss: 428.9714050292969\n",
      "          vf_explained_var: 0.3090416491031647\n",
      "          vf_loss: 428.9771423339844\n",
      "    num_agent_steps_sampled: 375906\n",
      "    num_agent_steps_trained: 375906\n",
      "    num_steps_sampled: 375906\n",
      "    num_steps_trained: 375906\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.57857142857144\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09082557753196294\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09289422705821394\n",
      "    mean_inference_ms: 0.9981042670049356\n",
      "    mean_raw_obs_processing_ms: 0.12030591415787203\n",
      "  time_since_restore: 459.0847728252411\n",
      "  time_this_iter_s: 9.564247369766235\n",
      "  time_total_s: 459.0847728252411\n",
      "  timers:\n",
      "    learn_throughput: 1293.104\n",
      "    learn_time_ms: 6185.118\n",
      "    load_throughput: 21981549.959\n",
      "    load_time_ms: 0.364\n",
      "    sample_throughput: 815.659\n",
      "    sample_time_ms: 9805.567\n",
      "    update_time_ms: 2.743\n",
      "  timestamp: 1645202834\n",
      "  timesteps_since_restore: 375906\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 375906\n",
      "  training_iteration: 47\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:47:17 (running for 00:34:13.63)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         459.085</td><td style=\"text-align: right;\"> 375906</td><td style=\"text-align: right;\">  195.84</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 114</td><td style=\"text-align: right;\">            195.84</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:47:22 (running for 00:34:18.64)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         459.085</td><td style=\"text-align: right;\"> 375906</td><td style=\"text-align: right;\">  195.84</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 114</td><td style=\"text-align: right;\">            195.84</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 383904\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-47-23\n",
      "  done: false\n",
      "  episode_len_mean: 196.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.25\n",
      "  episode_reward_min: 114.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 2419\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.40540146827697754\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009268213994801044\n",
      "          model: {}\n",
      "          policy_loss: -0.0066824182868003845\n",
      "          total_loss: 370.8903503417969\n",
      "          vf_explained_var: 0.4276464283466339\n",
      "          vf_loss: 370.89288330078125\n",
      "    num_agent_steps_sampled: 383904\n",
      "    num_agent_steps_trained: 383904\n",
      "    num_steps_sampled: 383904\n",
      "    num_steps_trained: 383904\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.80000000000001\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09080178032691279\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09285905480236618\n",
      "    mean_inference_ms: 0.9975971539702264\n",
      "    mean_raw_obs_processing_ms: 0.12024691085735661\n",
      "  time_since_restore: 468.5962326526642\n",
      "  time_this_iter_s: 9.511459827423096\n",
      "  time_total_s: 468.5962326526642\n",
      "  timers:\n",
      "    learn_throughput: 1302.215\n",
      "    learn_time_ms: 6141.843\n",
      "    load_throughput: 21523189.652\n",
      "    load_time_ms: 0.372\n",
      "    sample_throughput: 817.095\n",
      "    sample_time_ms: 9788.331\n",
      "    update_time_ms: 2.758\n",
      "  timestamp: 1645202843\n",
      "  timesteps_since_restore: 383904\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 383904\n",
      "  training_iteration: 48\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:47:27 (running for 00:34:24.21)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         468.596</td><td style=\"text-align: right;\"> 383904</td><td style=\"text-align: right;\">  196.25</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 114</td><td style=\"text-align: right;\">            196.25</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:47:32 (running for 00:34:29.22)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         468.596</td><td style=\"text-align: right;\"> 383904</td><td style=\"text-align: right;\">  196.25</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 114</td><td style=\"text-align: right;\">            196.25</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 391902\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-47-33\n",
      "  done: false\n",
      "  episode_len_mean: 196.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.98\n",
      "  episode_reward_min: 121.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 2460\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4016720950603485\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009727261029183865\n",
      "          model: {}\n",
      "          policy_loss: -0.02499169111251831\n",
      "          total_loss: 398.1249084472656\n",
      "          vf_explained_var: 0.3551212251186371\n",
      "          vf_loss: 398.1455383300781\n",
      "    num_agent_steps_sampled: 391902\n",
      "    num_agent_steps_trained: 391902\n",
      "    num_steps_sampled: 391902\n",
      "    num_steps_trained: 391902\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.00769230769231\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09076196680860456\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09283316960727117\n",
      "    mean_inference_ms: 0.9970455949590934\n",
      "    mean_raw_obs_processing_ms: 0.12019266251174222\n",
      "  time_since_restore: 478.0599989891052\n",
      "  time_this_iter_s: 9.46376633644104\n",
      "  time_total_s: 478.0599989891052\n",
      "  timers:\n",
      "    learn_throughput: 1306.719\n",
      "    learn_time_ms: 6120.675\n",
      "    load_throughput: 21049158.18\n",
      "    load_time_ms: 0.38\n",
      "    sample_throughput: 822.51\n",
      "    sample_time_ms: 9723.891\n",
      "    update_time_ms: 2.785\n",
      "  timestamp: 1645202853\n",
      "  timesteps_since_restore: 391902\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 391902\n",
      "  training_iteration: 49\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:47:38 (running for 00:34:34.70)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">          478.06</td><td style=\"text-align: right;\"> 391902</td><td style=\"text-align: right;\">  196.98</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 121</td><td style=\"text-align: right;\">            196.98</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 399900\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-47-42\n",
      "  done: false\n",
      "  episode_len_mean: 198.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.91\n",
      "  episode_reward_min: 165.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 2500\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3997604548931122\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009256264194846153\n",
      "          model: {}\n",
      "          policy_loss: -0.008146396838128567\n",
      "          total_loss: 356.08734130859375\n",
      "          vf_explained_var: 0.43180710077285767\n",
      "          vf_loss: 356.09130859375\n",
      "    num_agent_steps_sampled: 399900\n",
      "    num_agent_steps_trained: 399900\n",
      "    num_steps_sampled: 399900\n",
      "    num_steps_trained: 399900\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.95\n",
      "    ram_util_percent: 17.957142857142856\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09077158324836972\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09280134055657425\n",
      "    mean_inference_ms: 0.9969425852951754\n",
      "    mean_raw_obs_processing_ms: 0.12016221445344105\n",
      "  time_since_restore: 487.7649164199829\n",
      "  time_this_iter_s: 9.704917430877686\n",
      "  time_total_s: 487.7649164199829\n",
      "  timers:\n",
      "    learn_throughput: 1308.27\n",
      "    learn_time_ms: 6113.419\n",
      "    load_throughput: 21159356.246\n",
      "    load_time_ms: 0.378\n",
      "    sample_throughput: 824.563\n",
      "    sample_time_ms: 9699.687\n",
      "    update_time_ms: 2.751\n",
      "  timestamp: 1645202862\n",
      "  timesteps_since_restore: 399900\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 399900\n",
      "  training_iteration: 50\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:47:43 (running for 00:34:40.38)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         487.765</td><td style=\"text-align: right;\"> 399900</td><td style=\"text-align: right;\">  198.91</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 165</td><td style=\"text-align: right;\">            198.91</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:47:48 (running for 00:34:45.45)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         487.765</td><td style=\"text-align: right;\"> 399900</td><td style=\"text-align: right;\">  198.91</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 165</td><td style=\"text-align: right;\">            198.91</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 407898\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-47-52\n",
      "  done: false\n",
      "  episode_len_mean: 198.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.42\n",
      "  episode_reward_min: 116.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 2540\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.40250569581985474\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010052296333014965\n",
      "          model: {}\n",
      "          policy_loss: -0.012854057364165783\n",
      "          total_loss: 329.2420654296875\n",
      "          vf_explained_var: 0.5708847045898438\n",
      "          vf_loss: 329.2503662109375\n",
      "    num_agent_steps_sampled: 407898\n",
      "    num_agent_steps_trained: 407898\n",
      "    num_steps_sampled: 407898\n",
      "    num_steps_trained: 407898\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.5\n",
      "    ram_util_percent: 18.0\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09074706829085474\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09279408199526007\n",
      "    mean_inference_ms: 0.9968275300943651\n",
      "    mean_raw_obs_processing_ms: 0.12014218527080343\n",
      "  time_since_restore: 497.6211109161377\n",
      "  time_this_iter_s: 9.856194496154785\n",
      "  time_total_s: 497.6211109161377\n",
      "  timers:\n",
      "    learn_throughput: 1305.312\n",
      "    learn_time_ms: 6127.271\n",
      "    load_throughput: 21218243.765\n",
      "    load_time_ms: 0.377\n",
      "    sample_throughput: 825.667\n",
      "    sample_time_ms: 9686.715\n",
      "    update_time_ms: 2.824\n",
      "  timestamp: 1645202872\n",
      "  timesteps_since_restore: 407898\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 407898\n",
      "  training_iteration: 51\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:47:54 (running for 00:34:51.27)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         497.621</td><td style=\"text-align: right;\"> 407898</td><td style=\"text-align: right;\">  198.42</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 116</td><td style=\"text-align: right;\">            198.42</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:47:59 (running for 00:34:56.34)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         497.621</td><td style=\"text-align: right;\"> 407898</td><td style=\"text-align: right;\">  198.42</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 116</td><td style=\"text-align: right;\">            198.42</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 415896\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-48-02\n",
      "  done: false\n",
      "  episode_len_mean: 196.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.14\n",
      "  episode_reward_min: 116.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 2582\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.40110060572624207\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009449735283851624\n",
      "          model: {}\n",
      "          policy_loss: -0.014397538267076015\n",
      "          total_loss: 278.6954650878906\n",
      "          vf_explained_var: 0.5555561184883118\n",
      "          vf_loss: 278.7055969238281\n",
      "    num_agent_steps_sampled: 415896\n",
      "    num_agent_steps_trained: 415896\n",
      "    num_steps_sampled: 415896\n",
      "    num_steps_trained: 415896\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.82142857142857\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09073380940491076\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09280045143067063\n",
      "    mean_inference_ms: 0.9968194357471719\n",
      "    mean_raw_obs_processing_ms: 0.12015082529373096\n",
      "  time_since_restore: 507.66160774230957\n",
      "  time_this_iter_s: 10.040496826171875\n",
      "  time_total_s: 507.66160774230957\n",
      "  timers:\n",
      "    learn_throughput: 1296.496\n",
      "    learn_time_ms: 6168.938\n",
      "    load_throughput: 21785974.407\n",
      "    load_time_ms: 0.367\n",
      "    sample_throughput: 824.067\n",
      "    sample_time_ms: 9705.52\n",
      "    update_time_ms: 2.845\n",
      "  timestamp: 1645202882\n",
      "  timesteps_since_restore: 415896\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 415896\n",
      "  training_iteration: 52\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:48:05 (running for 00:35:02.33)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         507.662</td><td style=\"text-align: right;\"> 415896</td><td style=\"text-align: right;\">  196.14</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 116</td><td style=\"text-align: right;\">            196.14</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:48:10 (running for 00:35:07.38)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         507.662</td><td style=\"text-align: right;\"> 415896</td><td style=\"text-align: right;\">  196.14</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 116</td><td style=\"text-align: right;\">            196.14</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 423894\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-48-12\n",
      "  done: false\n",
      "  episode_len_mean: 195.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.26\n",
      "  episode_reward_min: 116.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 2621\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4010471701622009\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009791155345737934\n",
      "          model: {}\n",
      "          policy_loss: -0.009292993694543839\n",
      "          total_loss: 324.0506591796875\n",
      "          vf_explained_var: 0.5811288356781006\n",
      "          vf_loss: 324.0555725097656\n",
      "    num_agent_steps_sampled: 423894\n",
      "    num_agent_steps_trained: 423894\n",
      "    num_steps_sampled: 423894\n",
      "    num_steps_trained: 423894\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.73333333333335\n",
      "    ram_util_percent: 17.9\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09076510819490771\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09282355713625468\n",
      "    mean_inference_ms: 0.9971028897108423\n",
      "    mean_raw_obs_processing_ms: 0.12020289703671434\n",
      "  time_since_restore: 517.5653877258301\n",
      "  time_this_iter_s: 9.903779983520508\n",
      "  time_total_s: 517.5653877258301\n",
      "  timers:\n",
      "    learn_throughput: 1300.248\n",
      "    learn_time_ms: 6151.135\n",
      "    load_throughput: 21967155.649\n",
      "    load_time_ms: 0.364\n",
      "    sample_throughput: 819.193\n",
      "    sample_time_ms: 9763.265\n",
      "    update_time_ms: 2.86\n",
      "  timestamp: 1645202892\n",
      "  timesteps_since_restore: 423894\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 423894\n",
      "  training_iteration: 53\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:48:16 (running for 00:35:13.26)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         517.565</td><td style=\"text-align: right;\"> 423894</td><td style=\"text-align: right;\">  195.26</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 116</td><td style=\"text-align: right;\">            195.26</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:48:21 (running for 00:35:18.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         517.565</td><td style=\"text-align: right;\"> 423894</td><td style=\"text-align: right;\">  195.26</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 116</td><td style=\"text-align: right;\">            195.26</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 431892\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-48-22\n",
      "  done: false\n",
      "  episode_len_mean: 196.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.13\n",
      "  episode_reward_min: 116.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 2662\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4023222327232361\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010505828075110912\n",
      "          model: {}\n",
      "          policy_loss: -0.010396131314337254\n",
      "          total_loss: 352.4104309082031\n",
      "          vf_explained_var: 0.45742928981781006\n",
      "          vf_loss: 352.41607666015625\n",
      "    num_agent_steps_sampled: 431892\n",
      "    num_agent_steps_trained: 431892\n",
      "    num_steps_sampled: 431892\n",
      "    num_steps_trained: 431892\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.6923076923077\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09079840073230354\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09282491713418857\n",
      "    mean_inference_ms: 0.9973814598340909\n",
      "    mean_raw_obs_processing_ms: 0.12022259705750592\n",
      "  time_since_restore: 527.0959937572479\n",
      "  time_this_iter_s: 9.530606031417847\n",
      "  time_total_s: 527.0959937572479\n",
      "  timers:\n",
      "    learn_throughput: 1303.943\n",
      "    learn_time_ms: 6133.702\n",
      "    load_throughput: 23046196.34\n",
      "    load_time_ms: 0.347\n",
      "    sample_throughput: 821.253\n",
      "    sample_time_ms: 9738.777\n",
      "    update_time_ms: 2.832\n",
      "  timestamp: 1645202902\n",
      "  timesteps_since_restore: 431892\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 431892\n",
      "  training_iteration: 54\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:48:27 (running for 00:35:23.82)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         527.096</td><td style=\"text-align: right;\"> 431892</td><td style=\"text-align: right;\">  196.13</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 116</td><td style=\"text-align: right;\">            196.13</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 439890\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-48-32\n",
      "  done: false\n",
      "  episode_len_mean: 198.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.54\n",
      "  episode_reward_min: 144.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 2702\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4060141146183014\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012214917689561844\n",
      "          model: {}\n",
      "          policy_loss: -0.015226250514388084\n",
      "          total_loss: 270.5655212402344\n",
      "          vf_explained_var: 0.6307154893875122\n",
      "          vf_loss: 270.57525634765625\n",
      "    num_agent_steps_sampled: 439890\n",
      "    num_agent_steps_trained: 439890\n",
      "    num_steps_sampled: 439890\n",
      "    num_steps_trained: 439890\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.39285714285714\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09078053267611001\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09280643158670046\n",
      "    mean_inference_ms: 0.9972898648715751\n",
      "    mean_raw_obs_processing_ms: 0.12018886517210946\n",
      "  time_since_restore: 536.9475588798523\n",
      "  time_this_iter_s: 9.85156512260437\n",
      "  time_total_s: 536.9475588798523\n",
      "  timers:\n",
      "    learn_throughput: 1302.312\n",
      "    learn_time_ms: 6141.387\n",
      "    load_throughput: 23496563.278\n",
      "    load_time_ms: 0.34\n",
      "    sample_throughput: 823.482\n",
      "    sample_time_ms: 9712.411\n",
      "    update_time_ms: 2.872\n",
      "  timestamp: 1645202912\n",
      "  timesteps_since_restore: 439890\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 439890\n",
      "  training_iteration: 55\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:48:33 (running for 00:35:29.70)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         536.948</td><td style=\"text-align: right;\"> 439890</td><td style=\"text-align: right;\">  198.54</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 144</td><td style=\"text-align: right;\">            198.54</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:48:38 (running for 00:35:34.71)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         536.948</td><td style=\"text-align: right;\"> 439890</td><td style=\"text-align: right;\">  198.54</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 144</td><td style=\"text-align: right;\">            198.54</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 447888\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-48-42\n",
      "  done: false\n",
      "  episode_len_mean: 199.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.46\n",
      "  episode_reward_min: 177.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 2742\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.39770981669425964\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009565268643200397\n",
      "          model: {}\n",
      "          policy_loss: -0.008416892029345036\n",
      "          total_loss: 235.7833709716797\n",
      "          vf_explained_var: 0.6805323958396912\n",
      "          vf_loss: 235.78746032714844\n",
      "    num_agent_steps_sampled: 447888\n",
      "    num_agent_steps_trained: 447888\n",
      "    num_steps_sampled: 447888\n",
      "    num_steps_trained: 447888\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.7\n",
      "    ram_util_percent: 17.9\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09077381553539\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09278784249954528\n",
      "    mean_inference_ms: 0.9972523615285124\n",
      "    mean_raw_obs_processing_ms: 0.12015304280008618\n",
      "  time_since_restore: 546.8805565834045\n",
      "  time_this_iter_s: 9.932997703552246\n",
      "  time_total_s: 546.8805565834045\n",
      "  timers:\n",
      "    learn_throughput: 1295.017\n",
      "    learn_time_ms: 6175.981\n",
      "    load_throughput: 23320155.295\n",
      "    load_time_ms: 0.343\n",
      "    sample_throughput: 822.282\n",
      "    sample_time_ms: 9726.596\n",
      "    update_time_ms: 2.921\n",
      "  timestamp: 1645202922\n",
      "  timesteps_since_restore: 447888\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 447888\n",
      "  training_iteration: 56\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:48:44 (running for 00:35:40.65)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         546.881</td><td style=\"text-align: right;\"> 447888</td><td style=\"text-align: right;\">  199.46</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 177</td><td style=\"text-align: right;\">            199.46</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:48:49 (running for 00:35:45.66)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         546.881</td><td style=\"text-align: right;\"> 447888</td><td style=\"text-align: right;\">  199.46</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 177</td><td style=\"text-align: right;\">            199.46</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 455886\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-48-51\n",
      "  done: false\n",
      "  episode_len_mean: 198.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.11\n",
      "  episode_reward_min: 110.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 2783\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.39243045449256897\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011070768348872662\n",
      "          model: {}\n",
      "          policy_loss: -0.008970968425273895\n",
      "          total_loss: 215.7382354736328\n",
      "          vf_explained_var: 0.721774697303772\n",
      "          vf_loss: 215.74220275878906\n",
      "    num_agent_steps_sampled: 455886\n",
      "    num_agent_steps_trained: 455886\n",
      "    num_steps_sampled: 455886\n",
      "    num_steps_trained: 455886\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.50714285714285\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09072467192968711\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09279239859251628\n",
      "    mean_inference_ms: 0.9969706788908251\n",
      "    mean_raw_obs_processing_ms: 0.1200977782732153\n",
      "  time_since_restore: 556.6982765197754\n",
      "  time_this_iter_s: 9.81771993637085\n",
      "  time_total_s: 556.6982765197754\n",
      "  timers:\n",
      "    learn_throughput: 1290.408\n",
      "    learn_time_ms: 6198.04\n",
      "    load_throughput: 23049363.331\n",
      "    load_time_ms: 0.347\n",
      "    sample_throughput: 819.078\n",
      "    sample_time_ms: 9764.632\n",
      "    update_time_ms: 2.916\n",
      "  timestamp: 1645202931\n",
      "  timesteps_since_restore: 455886\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 455886\n",
      "  training_iteration: 57\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:48:54 (running for 00:35:51.50)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         556.698</td><td style=\"text-align: right;\"> 455886</td><td style=\"text-align: right;\">  198.11</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 110</td><td style=\"text-align: right;\">            198.11</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:48:59 (running for 00:35:56.51)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         556.698</td><td style=\"text-align: right;\"> 455886</td><td style=\"text-align: right;\">  198.11</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 110</td><td style=\"text-align: right;\">            198.11</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 463884\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-49-01\n",
      "  done: false\n",
      "  episode_len_mean: 197.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.81\n",
      "  episode_reward_min: 110.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 2824\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.38362282514572144\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010522156022489071\n",
      "          model: {}\n",
      "          policy_loss: -0.01638997718691826\n",
      "          total_loss: 297.3782958984375\n",
      "          vf_explained_var: 0.6098262667655945\n",
      "          vf_loss: 297.38995361328125\n",
      "    num_agent_steps_sampled: 463884\n",
      "    num_agent_steps_trained: 463884\n",
      "    num_steps_sampled: 463884\n",
      "    num_steps_trained: 463884\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.12857142857143\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09071158557522735\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09278256133658327\n",
      "    mean_inference_ms: 0.9969763485324339\n",
      "    mean_raw_obs_processing_ms: 0.12005935584662489\n",
      "  time_since_restore: 566.4422807693481\n",
      "  time_this_iter_s: 9.744004249572754\n",
      "  time_total_s: 566.4422807693481\n",
      "  timers:\n",
      "    learn_throughput: 1286.065\n",
      "    learn_time_ms: 6218.969\n",
      "    load_throughput: 23860902.903\n",
      "    load_time_ms: 0.335\n",
      "    sample_throughput: 817.059\n",
      "    sample_time_ms: 9788.765\n",
      "    update_time_ms: 2.96\n",
      "  timestamp: 1645202941\n",
      "  timesteps_since_restore: 463884\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 463884\n",
      "  training_iteration: 58\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:49:05 (running for 00:36:02.27)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         566.442</td><td style=\"text-align: right;\"> 463884</td><td style=\"text-align: right;\">  197.81</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 110</td><td style=\"text-align: right;\">            197.81</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:49:10 (running for 00:36:07.28)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         566.442</td><td style=\"text-align: right;\"> 463884</td><td style=\"text-align: right;\">  197.81</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 110</td><td style=\"text-align: right;\">            197.81</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 471882\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-49-11\n",
      "  done: false\n",
      "  episode_len_mean: 198.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.47\n",
      "  episode_reward_min: 110.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 2863\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.38540220260620117\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009777720086276531\n",
      "          model: {}\n",
      "          policy_loss: -0.01016552560031414\n",
      "          total_loss: 368.60711669921875\n",
      "          vf_explained_var: 0.4770526885986328\n",
      "          vf_loss: 368.6129150390625\n",
      "    num_agent_steps_sampled: 471882\n",
      "    num_agent_steps_trained: 471882\n",
      "    num_steps_sampled: 471882\n",
      "    num_steps_trained: 471882\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.60714285714286\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09073201764257269\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09277546898491171\n",
      "    mean_inference_ms: 0.9971063049443578\n",
      "    mean_raw_obs_processing_ms: 0.12004794406381318\n",
      "  time_since_restore: 576.2121088504791\n",
      "  time_this_iter_s: 9.769828081130981\n",
      "  time_total_s: 576.2121088504791\n",
      "  timers:\n",
      "    learn_throughput: 1282.593\n",
      "    learn_time_ms: 6235.805\n",
      "    load_throughput: 24177328.571\n",
      "    load_time_ms: 0.331\n",
      "    sample_throughput: 814.111\n",
      "    sample_time_ms: 9824.216\n",
      "    update_time_ms: 2.935\n",
      "  timestamp: 1645202951\n",
      "  timesteps_since_restore: 471882\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 471882\n",
      "  training_iteration: 59\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:49:16 (running for 00:36:13.11)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         576.212</td><td style=\"text-align: right;\"> 471882</td><td style=\"text-align: right;\">  198.47</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 110</td><td style=\"text-align: right;\">            198.47</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 479880\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-49-20\n",
      "  done: false\n",
      "  episode_len_mean: 199.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.16\n",
      "  episode_reward_min: 161.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 2903\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.38158556818962097\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010627045296132565\n",
      "          model: {}\n",
      "          policy_loss: -0.011437097564339638\n",
      "          total_loss: 355.43927001953125\n",
      "          vf_explained_var: 0.4648772180080414\n",
      "          vf_loss: 355.4459228515625\n",
      "    num_agent_steps_sampled: 479880\n",
      "    num_agent_steps_trained: 479880\n",
      "    num_steps_sampled: 479880\n",
      "    num_steps_trained: 479880\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.9076923076923\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09073939802604217\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09275063656066822\n",
      "    mean_inference_ms: 0.9969819781655679\n",
      "    mean_raw_obs_processing_ms: 0.12001940599855565\n",
      "  time_since_restore: 585.6282868385315\n",
      "  time_this_iter_s: 9.416177988052368\n",
      "  time_total_s: 585.6282868385315\n",
      "  timers:\n",
      "    learn_throughput: 1284.339\n",
      "    learn_time_ms: 6227.329\n",
      "    load_throughput: 24189532.299\n",
      "    load_time_ms: 0.331\n",
      "    sample_throughput: 814.396\n",
      "    sample_time_ms: 9820.779\n",
      "    update_time_ms: 2.96\n",
      "  timestamp: 1645202960\n",
      "  timesteps_since_restore: 479880\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 479880\n",
      "  training_iteration: 60\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:49:22 (running for 00:36:18.55)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         585.628</td><td style=\"text-align: right;\"> 479880</td><td style=\"text-align: right;\">  199.16</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 161</td><td style=\"text-align: right;\">            199.16</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:49:27 (running for 00:36:23.56)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         585.628</td><td style=\"text-align: right;\"> 479880</td><td style=\"text-align: right;\">  199.16</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 161</td><td style=\"text-align: right;\">            199.16</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 487878\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-49-30\n",
      "  done: false\n",
      "  episode_len_mean: 199.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.64\n",
      "  episode_reward_min: 182.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 2944\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3803004026412964\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008560869842767715\n",
      "          model: {}\n",
      "          policy_loss: -0.010565552860498428\n",
      "          total_loss: 403.15167236328125\n",
      "          vf_explained_var: 0.4041843116283417\n",
      "          vf_loss: 403.1583251953125\n",
      "    num_agent_steps_sampled: 487878\n",
      "    num_agent_steps_trained: 487878\n",
      "    num_steps_sampled: 487878\n",
      "    num_steps_trained: 487878\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.81428571428572\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09071751915563618\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09271930713521416\n",
      "    mean_inference_ms: 0.9966614328001936\n",
      "    mean_raw_obs_processing_ms: 0.11996224722068742\n",
      "  time_since_restore: 595.1910619735718\n",
      "  time_this_iter_s: 9.562775135040283\n",
      "  time_total_s: 595.1910619735718\n",
      "  timers:\n",
      "    learn_throughput: 1290.405\n",
      "    learn_time_ms: 6198.056\n",
      "    load_throughput: 24391800.62\n",
      "    load_time_ms: 0.328\n",
      "    sample_throughput: 815.119\n",
      "    sample_time_ms: 9812.068\n",
      "    update_time_ms: 2.92\n",
      "  timestamp: 1645202970\n",
      "  timesteps_since_restore: 487878\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 487878\n",
      "  training_iteration: 61\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:49:32 (running for 00:36:29.15)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         595.191</td><td style=\"text-align: right;\"> 487878</td><td style=\"text-align: right;\">  199.64</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 182</td><td style=\"text-align: right;\">            199.64</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:49:37 (running for 00:36:34.16)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         595.191</td><td style=\"text-align: right;\"> 487878</td><td style=\"text-align: right;\">  199.64</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 182</td><td style=\"text-align: right;\">            199.64</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 495876\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-49-40\n",
      "  done: false\n",
      "  episode_len_mean: 199.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.82\n",
      "  episode_reward_min: 188.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 2983\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3818698227405548\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010172146372497082\n",
      "          model: {}\n",
      "          policy_loss: -0.00918940082192421\n",
      "          total_loss: 329.4671936035156\n",
      "          vf_explained_var: 0.5603471398353577\n",
      "          vf_loss: 329.4718017578125\n",
      "    num_agent_steps_sampled: 495876\n",
      "    num_agent_steps_trained: 495876\n",
      "    num_steps_sampled: 495876\n",
      "    num_steps_trained: 495876\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.74285714285715\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09072435893563856\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09269696871113048\n",
      "    mean_inference_ms: 0.9965742035901054\n",
      "    mean_raw_obs_processing_ms: 0.11994136788999515\n",
      "  time_since_restore: 605.1310551166534\n",
      "  time_this_iter_s: 9.939993143081665\n",
      "  time_total_s: 605.1310551166534\n",
      "  timers:\n",
      "    learn_throughput: 1292.948\n",
      "    learn_time_ms: 6185.866\n",
      "    load_throughput: 24637223.408\n",
      "    load_time_ms: 0.325\n",
      "    sample_throughput: 817.416\n",
      "    sample_time_ms: 9784.494\n",
      "    update_time_ms: 2.979\n",
      "  timestamp: 1645202980\n",
      "  timesteps_since_restore: 495876\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 495876\n",
      "  training_iteration: 62\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:49:43 (running for 00:36:40.10)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         605.131</td><td style=\"text-align: right;\"> 495876</td><td style=\"text-align: right;\">  199.82</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 188</td><td style=\"text-align: right;\">            199.82</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:49:48 (running for 00:36:45.11)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         605.131</td><td style=\"text-align: right;\"> 495876</td><td style=\"text-align: right;\">  199.82</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 188</td><td style=\"text-align: right;\">            199.82</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 503874\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-49-50\n",
      "  done: false\n",
      "  episode_len_mean: 199.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.56\n",
      "  episode_reward_min: 162.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 3023\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3885672986507416\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010529653169214725\n",
      "          model: {}\n",
      "          policy_loss: -0.007157111074775457\n",
      "          total_loss: 361.7606201171875\n",
      "          vf_explained_var: 0.4720599353313446\n",
      "          vf_loss: 361.7630310058594\n",
      "    num_agent_steps_sampled: 503874\n",
      "    num_agent_steps_trained: 503874\n",
      "    num_steps_sampled: 503874\n",
      "    num_steps_trained: 503874\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.1\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09075041111977881\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0927279030615616\n",
      "    mean_inference_ms: 0.9967008072020627\n",
      "    mean_raw_obs_processing_ms: 0.11996641392868375\n",
      "  time_since_restore: 615.2744405269623\n",
      "  time_this_iter_s: 10.143385410308838\n",
      "  time_total_s: 615.2744405269623\n",
      "  timers:\n",
      "    learn_throughput: 1287.289\n",
      "    learn_time_ms: 6213.059\n",
      "    load_throughput: 24365226.171\n",
      "    load_time_ms: 0.328\n",
      "    sample_throughput: 818.719\n",
      "    sample_time_ms: 9768.914\n",
      "    update_time_ms: 3.051\n",
      "  timestamp: 1645202990\n",
      "  timesteps_since_restore: 503874\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 503874\n",
      "  training_iteration: 63\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:49:53 (running for 00:36:50.27)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         615.274</td><td style=\"text-align: right;\"> 503874</td><td style=\"text-align: right;\">  199.56</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 162</td><td style=\"text-align: right;\">            199.56</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:49:58 (running for 00:36:55.28)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         615.274</td><td style=\"text-align: right;\"> 503874</td><td style=\"text-align: right;\">  199.56</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 162</td><td style=\"text-align: right;\">            199.56</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 511872\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-50-00\n",
      "  done: false\n",
      "  episode_len_mean: 199.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.05\n",
      "  episode_reward_min: 162.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 3065\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3835265040397644\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010220147669315338\n",
      "          model: {}\n",
      "          policy_loss: -0.019480407238006592\n",
      "          total_loss: 351.0576477050781\n",
      "          vf_explained_var: 0.42500099539756775\n",
      "          vf_loss: 351.072509765625\n",
      "    num_agent_steps_sampled: 511872\n",
      "    num_agent_steps_trained: 511872\n",
      "    num_steps_sampled: 511872\n",
      "    num_steps_trained: 511872\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.73571428571428\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09077908409816227\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09275838028311476\n",
      "    mean_inference_ms: 0.9968915026425645\n",
      "    mean_raw_obs_processing_ms: 0.11999939864103075\n",
      "  time_since_restore: 624.8666877746582\n",
      "  time_this_iter_s: 9.592247247695923\n",
      "  time_total_s: 624.8666877746582\n",
      "  timers:\n",
      "    learn_throughput: 1288.617\n",
      "    learn_time_ms: 6206.652\n",
      "    load_throughput: 24166878.029\n",
      "    load_time_ms: 0.331\n",
      "    sample_throughput: 815.412\n",
      "    sample_time_ms: 9808.541\n",
      "    update_time_ms: 3.169\n",
      "  timestamp: 1645203000\n",
      "  timesteps_since_restore: 511872\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 511872\n",
      "  training_iteration: 64\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:50:04 (running for 00:37:00.88)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         624.867</td><td style=\"text-align: right;\"> 511872</td><td style=\"text-align: right;\">  199.05</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 162</td><td style=\"text-align: right;\">            199.05</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:50:09 (running for 00:37:05.90)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         624.867</td><td style=\"text-align: right;\"> 511872</td><td style=\"text-align: right;\">  199.05</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 162</td><td style=\"text-align: right;\">            199.05</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 519870\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-50-09\n",
      "  done: false\n",
      "  episode_len_mean: 199.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.39\n",
      "  episode_reward_min: 167.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 3104\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.38757357001304626\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010205812752246857\n",
      "          model: {}\n",
      "          policy_loss: -0.007826604880392551\n",
      "          total_loss: 338.7289123535156\n",
      "          vf_explained_var: 0.5282449126243591\n",
      "          vf_loss: 338.73211669921875\n",
      "    num_agent_steps_sampled: 519870\n",
      "    num_agent_steps_trained: 519870\n",
      "    num_steps_sampled: 519870\n",
      "    num_steps_trained: 519870\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.67142857142856\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0907890889201727\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09273855063592482\n",
      "    mean_inference_ms: 0.9968830900213601\n",
      "    mean_raw_obs_processing_ms: 0.11998250390237741\n",
      "  time_since_restore: 634.4060752391815\n",
      "  time_this_iter_s: 9.539387464523315\n",
      "  time_total_s: 634.4060752391815\n",
      "  timers:\n",
      "    learn_throughput: 1292.359\n",
      "    learn_time_ms: 6188.681\n",
      "    load_throughput: 24026674.826\n",
      "    load_time_ms: 0.333\n",
      "    sample_throughput: 817.042\n",
      "    sample_time_ms: 9788.969\n",
      "    update_time_ms: 3.123\n",
      "  timestamp: 1645203009\n",
      "  timesteps_since_restore: 519870\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 519870\n",
      "  training_iteration: 65\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:50:14 (running for 00:37:11.46)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         634.406</td><td style=\"text-align: right;\"> 519870</td><td style=\"text-align: right;\">  199.39</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 167</td><td style=\"text-align: right;\">            199.39</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 527868\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-50-19\n",
      "  done: false\n",
      "  episode_len_mean: 199.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.45\n",
      "  episode_reward_min: 173.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 3144\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3835834860801697\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00996049027889967\n",
      "          model: {}\n",
      "          policy_loss: -0.019745545461773872\n",
      "          total_loss: 358.8041687011719\n",
      "          vf_explained_var: 0.472183495759964\n",
      "          vf_loss: 358.8194580078125\n",
      "    num_agent_steps_sampled: 527868\n",
      "    num_agent_steps_trained: 527868\n",
      "    num_steps_sampled: 527868\n",
      "    num_steps_trained: 527868\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.4076923076923\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09075513410592183\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09270849983029712\n",
      "    mean_inference_ms: 0.9965540924543282\n",
      "    mean_raw_obs_processing_ms: 0.11992870136008477\n",
      "  time_since_restore: 643.9462687969208\n",
      "  time_this_iter_s: 9.540193557739258\n",
      "  time_total_s: 643.9462687969208\n",
      "  timers:\n",
      "    learn_throughput: 1300.098\n",
      "    learn_time_ms: 6151.845\n",
      "    load_throughput: 24314012.751\n",
      "    load_time_ms: 0.329\n",
      "    sample_throughput: 818.75\n",
      "    sample_time_ms: 9768.554\n",
      "    update_time_ms: 3.082\n",
      "  timestamp: 1645203019\n",
      "  timesteps_since_restore: 527868\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 527868\n",
      "  training_iteration: 66\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:50:20 (running for 00:37:16.97)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         643.946</td><td style=\"text-align: right;\"> 527868</td><td style=\"text-align: right;\">  199.45</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 173</td><td style=\"text-align: right;\">            199.45</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:50:25 (running for 00:37:22.02)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         643.946</td><td style=\"text-align: right;\"> 527868</td><td style=\"text-align: right;\">  199.45</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 173</td><td style=\"text-align: right;\">            199.45</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 535866\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-50-28\n",
      "  done: false\n",
      "  episode_len_mean: 198.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.78\n",
      "  episode_reward_min: 138.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 3185\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3679240345954895\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010719754733145237\n",
      "          model: {}\n",
      "          policy_loss: -0.009218634106218815\n",
      "          total_loss: 339.96490478515625\n",
      "          vf_explained_var: 0.5307085514068604\n",
      "          vf_loss: 339.96929931640625\n",
      "    num_agent_steps_sampled: 535866\n",
      "    num_agent_steps_trained: 535866\n",
      "    num_steps_sampled: 535866\n",
      "    num_steps_trained: 535866\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.32857142857144\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09074475283038057\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09268731548852426\n",
      "    mean_inference_ms: 0.996333479866625\n",
      "    mean_raw_obs_processing_ms: 0.11990096408529052\n",
      "  time_since_restore: 653.3157567977905\n",
      "  time_this_iter_s: 9.369488000869751\n",
      "  time_total_s: 653.3157567977905\n",
      "  timers:\n",
      "    learn_throughput: 1308.337\n",
      "    learn_time_ms: 6113.105\n",
      "    load_throughput: 24777342.043\n",
      "    load_time_ms: 0.323\n",
      "    sample_throughput: 822.359\n",
      "    sample_time_ms: 9725.685\n",
      "    update_time_ms: 3.057\n",
      "  timestamp: 1645203028\n",
      "  timesteps_since_restore: 535866\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 535866\n",
      "  training_iteration: 67\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:50:30 (running for 00:37:27.37)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         653.316</td><td style=\"text-align: right;\"> 535866</td><td style=\"text-align: right;\">  198.78</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 138</td><td style=\"text-align: right;\">            198.78</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:50:35 (running for 00:37:32.41)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         653.316</td><td style=\"text-align: right;\"> 535866</td><td style=\"text-align: right;\">  198.78</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 138</td><td style=\"text-align: right;\">            198.78</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 543864\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-50-38\n",
      "  done: false\n",
      "  episode_len_mean: 197.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.11\n",
      "  episode_reward_min: 127.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 3226\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.38050323724746704\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01053943857550621\n",
      "          model: {}\n",
      "          policy_loss: -0.0263834111392498\n",
      "          total_loss: 310.336669921875\n",
      "          vf_explained_var: 0.5395929217338562\n",
      "          vf_loss: 310.3582763671875\n",
      "    num_agent_steps_sampled: 543864\n",
      "    num_agent_steps_trained: 543864\n",
      "    num_steps_sampled: 543864\n",
      "    num_steps_trained: 543864\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.59230769230768\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09069730896827917\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09266137141928248\n",
      "    mean_inference_ms: 0.9958134594446768\n",
      "    mean_raw_obs_processing_ms: 0.11982480583696986\n",
      "  time_since_restore: 662.7217681407928\n",
      "  time_this_iter_s: 9.40601134300232\n",
      "  time_total_s: 662.7217681407928\n",
      "  timers:\n",
      "    learn_throughput: 1313.811\n",
      "    learn_time_ms: 6087.635\n",
      "    load_throughput: 24215724.675\n",
      "    load_time_ms: 0.33\n",
      "    sample_throughput: 826.327\n",
      "    sample_time_ms: 9678.982\n",
      "    update_time_ms: 3.258\n",
      "  timestamp: 1645203038\n",
      "  timesteps_since_restore: 543864\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 543864\n",
      "  training_iteration: 68\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:50:41 (running for 00:37:37.80)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         662.722</td><td style=\"text-align: right;\"> 543864</td><td style=\"text-align: right;\">  197.11</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 127</td><td style=\"text-align: right;\">            197.11</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:50:46 (running for 00:37:42.84)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         662.722</td><td style=\"text-align: right;\"> 543864</td><td style=\"text-align: right;\">  197.11</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 127</td><td style=\"text-align: right;\">            197.11</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 551862\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-50-47\n",
      "  done: false\n",
      "  episode_len_mean: 195.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.85\n",
      "  episode_reward_min: 127.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 3266\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3643244802951813\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011296600103378296\n",
      "          model: {}\n",
      "          policy_loss: -0.008937235921621323\n",
      "          total_loss: 320.15301513671875\n",
      "          vf_explained_var: 0.5057014226913452\n",
      "          vf_loss: 320.1568603515625\n",
      "    num_agent_steps_sampled: 551862\n",
      "    num_agent_steps_trained: 551862\n",
      "    num_steps_sampled: 551862\n",
      "    num_steps_trained: 551862\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.86153846153846\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0906902815063936\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09262601782563873\n",
      "    mean_inference_ms: 0.99561621835463\n",
      "    mean_raw_obs_processing_ms: 0.11977645637032733\n",
      "  time_since_restore: 672.0079612731934\n",
      "  time_this_iter_s: 9.286193132400513\n",
      "  time_total_s: 672.0079612731934\n",
      "  timers:\n",
      "    learn_throughput: 1320.869\n",
      "    learn_time_ms: 6055.103\n",
      "    load_throughput: 24637223.408\n",
      "    load_time_ms: 0.325\n",
      "    sample_throughput: 829.887\n",
      "    sample_time_ms: 9637.455\n",
      "    update_time_ms: 3.234\n",
      "  timestamp: 1645203047\n",
      "  timesteps_since_restore: 551862\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 551862\n",
      "  training_iteration: 69\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:50:51 (running for 00:37:48.11)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         672.008</td><td style=\"text-align: right;\"> 551862</td><td style=\"text-align: right;\">  195.85</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 127</td><td style=\"text-align: right;\">            195.85</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:50:56 (running for 00:37:53.15)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         672.008</td><td style=\"text-align: right;\"> 551862</td><td style=\"text-align: right;\">  195.85</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 127</td><td style=\"text-align: right;\">            195.85</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 559860\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-50-56\n",
      "  done: false\n",
      "  episode_len_mean: 196.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.35\n",
      "  episode_reward_min: 136.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 3308\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.37484607100486755\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009864427149295807\n",
      "          model: {}\n",
      "          policy_loss: -0.011451595462858677\n",
      "          total_loss: 344.4450988769531\n",
      "          vf_explained_var: 0.49481070041656494\n",
      "          vf_loss: 344.45208740234375\n",
      "    num_agent_steps_sampled: 559860\n",
      "    num_agent_steps_trained: 559860\n",
      "    num_steps_sampled: 559860\n",
      "    num_steps_trained: 559860\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.58571428571427\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09061605307573606\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09259113981056945\n",
      "    mean_inference_ms: 0.9949150596061012\n",
      "    mean_raw_obs_processing_ms: 0.1196679317583133\n",
      "  time_since_restore: 681.3507087230682\n",
      "  time_this_iter_s: 9.342747449874878\n",
      "  time_total_s: 681.3507087230682\n",
      "  timers:\n",
      "    learn_throughput: 1324.798\n",
      "    learn_time_ms: 6037.148\n",
      "    load_throughput: 24243725.802\n",
      "    load_time_ms: 0.33\n",
      "    sample_throughput: 831.775\n",
      "    sample_time_ms: 9615.579\n",
      "    update_time_ms: 3.147\n",
      "  timestamp: 1645203056\n",
      "  timesteps_since_restore: 559860\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 559860\n",
      "  training_iteration: 70\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:51:01 (running for 00:37:58.48)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         681.351</td><td style=\"text-align: right;\"> 559860</td><td style=\"text-align: right;\">  196.35</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 136</td><td style=\"text-align: right;\">            196.35</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 567858\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-51-06\n",
      "  done: false\n",
      "  episode_len_mean: 198.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.63\n",
      "  episode_reward_min: 151.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 3347\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3622053265571594\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009593604132533073\n",
      "          model: {}\n",
      "          policy_loss: -0.007284824270755053\n",
      "          total_loss: 370.952880859375\n",
      "          vf_explained_var: 0.4100838005542755\n",
      "          vf_loss: 370.9558410644531\n",
      "    num_agent_steps_sampled: 567858\n",
      "    num_agent_steps_trained: 567858\n",
      "    num_steps_sampled: 567858\n",
      "    num_steps_trained: 567858\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.62307692307691\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09059539057791981\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09251438493773824\n",
      "    mean_inference_ms: 0.9945272898599699\n",
      "    mean_raw_obs_processing_ms: 0.11956530573690034\n",
      "  time_since_restore: 690.6359596252441\n",
      "  time_this_iter_s: 9.285250902175903\n",
      "  time_total_s: 690.6359596252441\n",
      "  timers:\n",
      "    learn_throughput: 1325.372\n",
      "    learn_time_ms: 6034.531\n",
      "    load_throughput: 24372307.027\n",
      "    load_time_ms: 0.328\n",
      "    sample_throughput: 835.531\n",
      "    sample_time_ms: 9572.352\n",
      "    update_time_ms: 3.608\n",
      "  timestamp: 1645203066\n",
      "  timesteps_since_restore: 567858\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 567858\n",
      "  training_iteration: 71\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:51:07 (running for 00:38:03.83)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         690.636</td><td style=\"text-align: right;\"> 567858</td><td style=\"text-align: right;\">  198.63</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 151</td><td style=\"text-align: right;\">            198.63</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:51:12 (running for 00:38:08.84)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         690.636</td><td style=\"text-align: right;\"> 567858</td><td style=\"text-align: right;\">  198.63</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 151</td><td style=\"text-align: right;\">            198.63</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 575856\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-51-15\n",
      "  done: false\n",
      "  episode_len_mean: 198.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.71\n",
      "  episode_reward_min: 147.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 3387\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3528115749359131\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009588275104761124\n",
      "          model: {}\n",
      "          policy_loss: -0.0070663015358150005\n",
      "          total_loss: 430.8557434082031\n",
      "          vf_explained_var: 0.31161558628082275\n",
      "          vf_loss: 430.85845947265625\n",
      "    num_agent_steps_sampled: 575856\n",
      "    num_agent_steps_trained: 575856\n",
      "    num_steps_sampled: 575856\n",
      "    num_steps_trained: 575856\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.76153846153846\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09053651300063606\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09243229887849098\n",
      "    mean_inference_ms: 0.9938250912634851\n",
      "    mean_raw_obs_processing_ms: 0.11943768662620625\n",
      "  time_since_restore: 699.9314877986908\n",
      "  time_this_iter_s: 9.295528173446655\n",
      "  time_total_s: 699.9314877986908\n",
      "  timers:\n",
      "    learn_throughput: 1334.093\n",
      "    learn_time_ms: 5995.084\n",
      "    load_throughput: 24146004.025\n",
      "    load_time_ms: 0.331\n",
      "    sample_throughput: 837.952\n",
      "    sample_time_ms: 9544.705\n",
      "    update_time_ms: 3.526\n",
      "  timestamp: 1645203075\n",
      "  timesteps_since_restore: 575856\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 575856\n",
      "  training_iteration: 72\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:51:17 (running for 00:38:14.14)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         699.931</td><td style=\"text-align: right;\"> 575856</td><td style=\"text-align: right;\">  198.71</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 147</td><td style=\"text-align: right;\">            198.71</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:51:22 (running for 00:38:19.16)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         699.931</td><td style=\"text-align: right;\"> 575856</td><td style=\"text-align: right;\">  198.71</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 147</td><td style=\"text-align: right;\">            198.71</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 583854\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-51-24\n",
      "  done: false\n",
      "  episode_len_mean: 198.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.29\n",
      "  episode_reward_min: 147.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 3428\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3532226085662842\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010960656218230724\n",
      "          model: {}\n",
      "          policy_loss: -0.007889878936111927\n",
      "          total_loss: 366.3346862792969\n",
      "          vf_explained_var: 0.45399579405784607\n",
      "          vf_loss: 366.337646484375\n",
      "    num_agent_steps_sampled: 583854\n",
      "    num_agent_steps_trained: 583854\n",
      "    num_steps_sampled: 583854\n",
      "    num_steps_trained: 583854\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.3076923076923\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09045008377832142\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09236338611752179\n",
      "    mean_inference_ms: 0.9928919596026372\n",
      "    mean_raw_obs_processing_ms: 0.11930449471203901\n",
      "  time_since_restore: 709.0846564769745\n",
      "  time_this_iter_s: 9.153168678283691\n",
      "  time_total_s: 709.0846564769745\n",
      "  timers:\n",
      "    learn_throughput: 1348.177\n",
      "    learn_time_ms: 5932.453\n",
      "    load_throughput: 24536310.263\n",
      "    load_time_ms: 0.326\n",
      "    sample_throughput: 844.667\n",
      "    sample_time_ms: 9468.825\n",
      "    update_time_ms: 3.445\n",
      "  timestamp: 1645203084\n",
      "  timesteps_since_restore: 583854\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 583854\n",
      "  training_iteration: 73\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:51:27 (running for 00:38:24.34)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         709.085</td><td style=\"text-align: right;\"> 583854</td><td style=\"text-align: right;\">  198.29</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 147</td><td style=\"text-align: right;\">            198.29</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:51:32 (running for 00:38:29.35)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         709.085</td><td style=\"text-align: right;\"> 583854</td><td style=\"text-align: right;\">  198.29</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 147</td><td style=\"text-align: right;\">            198.29</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 591852\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-51-33\n",
      "  done: false\n",
      "  episode_len_mean: 196.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.45\n",
      "  episode_reward_min: 147.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 3468\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3546917140483856\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010772391222417355\n",
      "          model: {}\n",
      "          policy_loss: -0.010792271234095097\n",
      "          total_loss: 278.5528259277344\n",
      "          vf_explained_var: 0.5707975029945374\n",
      "          vf_loss: 278.55877685546875\n",
      "    num_agent_steps_sampled: 591852\n",
      "    num_agent_steps_trained: 591852\n",
      "    num_steps_sampled: 591852\n",
      "    num_steps_trained: 591852\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.85714285714286\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09037512488226751\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09228908146189099\n",
      "    mean_inference_ms: 0.9920901029077922\n",
      "    mean_raw_obs_processing_ms: 0.11917855803928618\n",
      "  time_since_restore: 718.2992956638336\n",
      "  time_this_iter_s: 9.21463918685913\n",
      "  time_total_s: 718.2992956638336\n",
      "  timers:\n",
      "    learn_throughput: 1351.711\n",
      "    learn_time_ms: 5916.946\n",
      "    load_throughput: 24713454.687\n",
      "    load_time_ms: 0.324\n",
      "    sample_throughput: 852.29\n",
      "    sample_time_ms: 9384.134\n",
      "    update_time_ms: 3.353\n",
      "  timestamp: 1645203093\n",
      "  timesteps_since_restore: 591852\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 591852\n",
      "  training_iteration: 74\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:51:38 (running for 00:38:34.57)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         718.299</td><td style=\"text-align: right;\"> 591852</td><td style=\"text-align: right;\">  196.45</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 147</td><td style=\"text-align: right;\">            196.45</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:51:43 (running for 00:38:39.58)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         718.299</td><td style=\"text-align: right;\"> 591852</td><td style=\"text-align: right;\">  196.45</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 147</td><td style=\"text-align: right;\">            196.45</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 599850\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-51-43\n",
      "  done: false\n",
      "  episode_len_mean: 197.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.59\n",
      "  episode_reward_min: 152.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 3509\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3381582498550415\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01221699733287096\n",
      "          model: {}\n",
      "          policy_loss: -0.018090514466166496\n",
      "          total_loss: 355.4157409667969\n",
      "          vf_explained_var: 0.4697217047214508\n",
      "          vf_loss: 355.4283752441406\n",
      "    num_agent_steps_sampled: 599850\n",
      "    num_agent_steps_trained: 599850\n",
      "    num_steps_sampled: 599850\n",
      "    num_steps_trained: 599850\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.76923076923076\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0902802718188283\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09222459243568437\n",
      "    mean_inference_ms: 0.9912339895911018\n",
      "    mean_raw_obs_processing_ms: 0.1190493180830008\n",
      "  time_since_restore: 727.5125706195831\n",
      "  time_this_iter_s: 9.213274955749512\n",
      "  time_total_s: 727.5125706195831\n",
      "  timers:\n",
      "    learn_throughput: 1358.341\n",
      "    learn_time_ms: 5888.065\n",
      "    load_throughput: 24969142.83\n",
      "    load_time_ms: 0.32\n",
      "    sample_throughput: 854.011\n",
      "    sample_time_ms: 9365.217\n",
      "    update_time_ms: 3.331\n",
      "  timestamp: 1645203103\n",
      "  timesteps_since_restore: 599850\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 599850\n",
      "  training_iteration: 75\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:51:48 (running for 00:38:44.80)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         727.513</td><td style=\"text-align: right;\"> 599850</td><td style=\"text-align: right;\">  197.59</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 152</td><td style=\"text-align: right;\">            197.59</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 607848\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-51-52\n",
      "  done: false\n",
      "  episode_len_mean: 196.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.8\n",
      "  episode_reward_min: 129.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 3550\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.35329025983810425\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010004614479839802\n",
      "          model: {}\n",
      "          policy_loss: -0.010441180318593979\n",
      "          total_loss: 323.4312744140625\n",
      "          vf_explained_var: 0.5408644080162048\n",
      "          vf_loss: 323.4372253417969\n",
      "    num_agent_steps_sampled: 607848\n",
      "    num_agent_steps_trained: 607848\n",
      "    num_steps_sampled: 607848\n",
      "    num_steps_trained: 607848\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.46923076923078\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09022234094754261\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09216144499049843\n",
      "    mean_inference_ms: 0.9906933047377376\n",
      "    mean_raw_obs_processing_ms: 0.1189541979557035\n",
      "  time_since_restore: 736.6442267894745\n",
      "  time_this_iter_s: 9.131656169891357\n",
      "  time_total_s: 736.6442267894745\n",
      "  timers:\n",
      "    learn_throughput: 1363.605\n",
      "    learn_time_ms: 5865.336\n",
      "    load_throughput: 25258672.835\n",
      "    load_time_ms: 0.317\n",
      "    sample_throughput: 858.353\n",
      "    sample_time_ms: 9317.845\n",
      "    update_time_ms: 3.346\n",
      "  timestamp: 1645203112\n",
      "  timesteps_since_restore: 607848\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 607848\n",
      "  training_iteration: 76\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:51:53 (running for 00:38:49.92)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         736.644</td><td style=\"text-align: right;\"> 607848</td><td style=\"text-align: right;\">  196.8 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 129</td><td style=\"text-align: right;\">            196.8 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:51:58 (running for 00:38:54.96)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         736.644</td><td style=\"text-align: right;\"> 607848</td><td style=\"text-align: right;\">  196.8 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 129</td><td style=\"text-align: right;\">            196.8 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 615846\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-52-01\n",
      "  done: false\n",
      "  episode_len_mean: 196.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.97\n",
      "  episode_reward_min: 129.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 3590\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3449995517730713\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01069426815956831\n",
      "          model: {}\n",
      "          policy_loss: -0.008046012371778488\n",
      "          total_loss: 346.3447265625\n",
      "          vf_explained_var: 0.4650283753871918\n",
      "          vf_loss: 346.34796142578125\n",
      "    num_agent_steps_sampled: 615846\n",
      "    num_agent_steps_trained: 615846\n",
      "    num_steps_sampled: 615846\n",
      "    num_steps_trained: 615846\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.47692307692307\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09014570648282405\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09209545891406139\n",
      "    mean_inference_ms: 0.9900384479509722\n",
      "    mean_raw_obs_processing_ms: 0.1188269074685865\n",
      "  time_since_restore: 745.9601466655731\n",
      "  time_this_iter_s: 9.315919876098633\n",
      "  time_total_s: 745.9601466655731\n",
      "  timers:\n",
      "    learn_throughput: 1365.471\n",
      "    learn_time_ms: 5857.32\n",
      "    load_throughput: 25273896.928\n",
      "    load_time_ms: 0.316\n",
      "    sample_throughput: 860.202\n",
      "    sample_time_ms: 9297.813\n",
      "    update_time_ms: 3.333\n",
      "  timestamp: 1645203121\n",
      "  timesteps_since_restore: 615846\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 615846\n",
      "  training_iteration: 77\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:52:03 (running for 00:39:00.26)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">          745.96</td><td style=\"text-align: right;\"> 615846</td><td style=\"text-align: right;\">  196.97</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 129</td><td style=\"text-align: right;\">            196.97</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:52:08 (running for 00:39:05.30)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">          745.96</td><td style=\"text-align: right;\"> 615846</td><td style=\"text-align: right;\">  196.97</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 129</td><td style=\"text-align: right;\">            196.97</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 623844\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-52-10\n",
      "  done: false\n",
      "  episode_len_mean: 196.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.16\n",
      "  episode_reward_min: 143.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 3631\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.36167746782302856\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011563449166715145\n",
      "          model: {}\n",
      "          policy_loss: -0.010396947152912617\n",
      "          total_loss: 298.3840026855469\n",
      "          vf_explained_var: 0.5421978831291199\n",
      "          vf_loss: 298.3891906738281\n",
      "    num_agent_steps_sampled: 623844\n",
      "    num_agent_steps_trained: 623844\n",
      "    num_steps_sampled: 623844\n",
      "    num_steps_trained: 623844\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.53076923076922\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09012235710835415\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09204862035498365\n",
      "    mean_inference_ms: 0.9898353427843734\n",
      "    mean_raw_obs_processing_ms: 0.11875876006603547\n",
      "  time_since_restore: 755.2253634929657\n",
      "  time_this_iter_s: 9.265216827392578\n",
      "  time_total_s: 755.2253634929657\n",
      "  timers:\n",
      "    learn_throughput: 1369.376\n",
      "    learn_time_ms: 5840.617\n",
      "    load_throughput: 25674302.305\n",
      "    load_time_ms: 0.312\n",
      "    sample_throughput: 860.733\n",
      "    sample_time_ms: 9292.079\n",
      "    update_time_ms: 3.059\n",
      "  timestamp: 1645203130\n",
      "  timesteps_since_restore: 623844\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 623844\n",
      "  training_iteration: 78\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:52:14 (running for 00:39:10.55)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         755.225</td><td style=\"text-align: right;\"> 623844</td><td style=\"text-align: right;\">  196.16</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 143</td><td style=\"text-align: right;\">            196.16</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:52:19 (running for 00:39:15.61)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         755.225</td><td style=\"text-align: right;\"> 623844</td><td style=\"text-align: right;\">  196.16</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 143</td><td style=\"text-align: right;\">            196.16</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 631842\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-52-20\n",
      "  done: false\n",
      "  episode_len_mean: 197.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.74\n",
      "  episode_reward_min: 144.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 3671\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.36024582386016846\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010280344635248184\n",
      "          model: {}\n",
      "          policy_loss: -0.016823388636112213\n",
      "          total_loss: 321.07366943359375\n",
      "          vf_explained_var: 0.49418359994888306\n",
      "          vf_loss: 321.08587646484375\n",
      "    num_agent_steps_sampled: 631842\n",
      "    num_agent_steps_trained: 631842\n",
      "    num_steps_sampled: 631842\n",
      "    num_steps_trained: 631842\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.27692307692308\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09004671856941908\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0920064114365013\n",
      "    mean_inference_ms: 0.9891886598329068\n",
      "    mean_raw_obs_processing_ms: 0.11864528994983843\n",
      "  time_since_restore: 764.2884061336517\n",
      "  time_this_iter_s: 9.063042640686035\n",
      "  time_total_s: 764.2884061336517\n",
      "  timers:\n",
      "    learn_throughput: 1371.689\n",
      "    learn_time_ms: 5830.768\n",
      "    load_throughput: 25315857.967\n",
      "    load_time_ms: 0.316\n",
      "    sample_throughput: 863.497\n",
      "    sample_time_ms: 9262.333\n",
      "    update_time_ms: 3.077\n",
      "  timestamp: 1645203140\n",
      "  timesteps_since_restore: 631842\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 631842\n",
      "  training_iteration: 79\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:52:24 (running for 00:39:20.64)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         764.288</td><td style=\"text-align: right;\"> 631842</td><td style=\"text-align: right;\">  197.74</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 144</td><td style=\"text-align: right;\">            197.74</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:52:29 (running for 00:39:25.67)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         764.288</td><td style=\"text-align: right;\"> 631842</td><td style=\"text-align: right;\">  197.74</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 144</td><td style=\"text-align: right;\">            197.74</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 639840\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-52-29\n",
      "  done: false\n",
      "  episode_len_mean: 198.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.03\n",
      "  episode_reward_min: 127.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 3712\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.357941597700119\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011165638454258442\n",
      "          model: {}\n",
      "          policy_loss: -0.009708043187856674\n",
      "          total_loss: 342.77001953125\n",
      "          vf_explained_var: 0.47778159379959106\n",
      "          vf_loss: 342.77471923828125\n",
      "    num_agent_steps_sampled: 639840\n",
      "    num_agent_steps_trained: 639840\n",
      "    num_steps_sampled: 639840\n",
      "    num_steps_trained: 639840\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.25714285714287\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09001665004509782\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09194907852493303\n",
      "    mean_inference_ms: 0.9888505728870669\n",
      "    mean_raw_obs_processing_ms: 0.11856716604968984\n",
      "  time_since_restore: 773.472048997879\n",
      "  time_this_iter_s: 9.183642864227295\n",
      "  time_total_s: 773.472048997879\n",
      "  timers:\n",
      "    learn_throughput: 1373.756\n",
      "    learn_time_ms: 5821.994\n",
      "    load_throughput: 26034958.007\n",
      "    load_time_ms: 0.307\n",
      "    sample_throughput: 865.101\n",
      "    sample_time_ms: 9245.158\n",
      "    update_time_ms: 3.098\n",
      "  timestamp: 1645203149\n",
      "  timesteps_since_restore: 639840\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 639840\n",
      "  training_iteration: 80\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:52:34 (running for 00:39:30.85)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         773.472</td><td style=\"text-align: right;\"> 639840</td><td style=\"text-align: right;\">  198.03</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 127</td><td style=\"text-align: right;\">            198.03</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 647838\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-52-38\n",
      "  done: false\n",
      "  episode_len_mean: 197.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.98\n",
      "  episode_reward_min: 127.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 3752\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3538495600223541\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010233706794679165\n",
      "          model: {}\n",
      "          policy_loss: -0.008962842635810375\n",
      "          total_loss: 376.7077331542969\n",
      "          vf_explained_var: 0.40183815360069275\n",
      "          vf_loss: 376.71209716796875\n",
      "    num_agent_steps_sampled: 647838\n",
      "    num_agent_steps_trained: 647838\n",
      "    num_steps_sampled: 647838\n",
      "    num_steps_trained: 647838\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.73076923076923\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08996557750269478\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09189105487791728\n",
      "    mean_inference_ms: 0.9883043237672534\n",
      "    mean_raw_obs_processing_ms: 0.11845967356400611\n",
      "  time_since_restore: 782.5846099853516\n",
      "  time_this_iter_s: 9.112560987472534\n",
      "  time_total_s: 782.5846099853516\n",
      "  timers:\n",
      "    learn_throughput: 1378.714\n",
      "    learn_time_ms: 5801.056\n",
      "    load_throughput: 26111966.523\n",
      "    load_time_ms: 0.306\n",
      "    sample_throughput: 865.522\n",
      "    sample_time_ms: 9240.67\n",
      "    update_time_ms: 2.626\n",
      "  timestamp: 1645203158\n",
      "  timesteps_since_restore: 647838\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 647838\n",
      "  training_iteration: 81\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:52:39 (running for 00:39:36.05)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         782.585</td><td style=\"text-align: right;\"> 647838</td><td style=\"text-align: right;\">  197.98</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 127</td><td style=\"text-align: right;\">            197.98</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:52:44 (running for 00:39:41.07)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         782.585</td><td style=\"text-align: right;\"> 647838</td><td style=\"text-align: right;\">  197.98</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 127</td><td style=\"text-align: right;\">            197.98</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 655836\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-52-47\n",
      "  done: false\n",
      "  episode_len_mean: 197.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.7\n",
      "  episode_reward_min: 136.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 3793\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3515387177467346\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01031146477907896\n",
      "          model: {}\n",
      "          policy_loss: -0.008003088645637035\n",
      "          total_loss: 342.9076232910156\n",
      "          vf_explained_var: 0.49861469864845276\n",
      "          vf_loss: 342.9110107421875\n",
      "    num_agent_steps_sampled: 655836\n",
      "    num_agent_steps_trained: 655836\n",
      "    num_steps_sampled: 655836\n",
      "    num_steps_trained: 655836\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.39999999999999\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08993287912946361\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09184547025352507\n",
      "    mean_inference_ms: 0.9879488668524438\n",
      "    mean_raw_obs_processing_ms: 0.11837725083375839\n",
      "  time_since_restore: 791.8196325302124\n",
      "  time_this_iter_s: 9.23502254486084\n",
      "  time_total_s: 791.8196325302124\n",
      "  timers:\n",
      "    learn_throughput: 1384.554\n",
      "    learn_time_ms: 5776.591\n",
      "    load_throughput: 26335408.535\n",
      "    load_time_ms: 0.304\n",
      "    sample_throughput: 865.746\n",
      "    sample_time_ms: 9238.277\n",
      "    update_time_ms: 2.627\n",
      "  timestamp: 1645203167\n",
      "  timesteps_since_restore: 655836\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 655836\n",
      "  training_iteration: 82\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:52:49 (running for 00:39:46.30)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">          791.82</td><td style=\"text-align: right;\"> 655836</td><td style=\"text-align: right;\">  197.7 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 136</td><td style=\"text-align: right;\">            197.7 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:52:54 (running for 00:39:51.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">          791.82</td><td style=\"text-align: right;\"> 655836</td><td style=\"text-align: right;\">  197.7 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 136</td><td style=\"text-align: right;\">            197.7 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 663834\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-52-56\n",
      "  done: false\n",
      "  episode_len_mean: 198.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.09\n",
      "  episode_reward_min: 139.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 3832\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.34304508566856384\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009645976126194\n",
      "          model: {}\n",
      "          policy_loss: -0.00732424994930625\n",
      "          total_loss: 385.5621032714844\n",
      "          vf_explained_var: 0.4012542963027954\n",
      "          vf_loss: 385.5650634765625\n",
      "    num_agent_steps_sampled: 663834\n",
      "    num_agent_steps_trained: 663834\n",
      "    num_steps_sampled: 663834\n",
      "    num_steps_trained: 663834\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.4923076923077\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08989952866792318\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09180620025493581\n",
      "    mean_inference_ms: 0.9876452892663045\n",
      "    mean_raw_obs_processing_ms: 0.11830368397388977\n",
      "  time_since_restore: 800.889594078064\n",
      "  time_this_iter_s: 9.069961547851562\n",
      "  time_total_s: 800.889594078064\n",
      "  timers:\n",
      "    learn_throughput: 1387.279\n",
      "    learn_time_ms: 5765.241\n",
      "    load_throughput: 26393425.171\n",
      "    load_time_ms: 0.303\n",
      "    sample_throughput: 867.785\n",
      "    sample_time_ms: 9216.567\n",
      "    update_time_ms: 2.614\n",
      "  timestamp: 1645203176\n",
      "  timesteps_since_restore: 663834\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 663834\n",
      "  training_iteration: 83\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:52:59 (running for 00:39:56.38)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">          800.89</td><td style=\"text-align: right;\"> 663834</td><td style=\"text-align: right;\">  198.09</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 139</td><td style=\"text-align: right;\">            198.09</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:53:05 (running for 00:40:01.58)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">          800.89</td><td style=\"text-align: right;\"> 663834</td><td style=\"text-align: right;\">  198.09</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 139</td><td style=\"text-align: right;\">            198.09</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 671832\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-53-06\n",
      "  done: false\n",
      "  episode_len_mean: 198.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.55\n",
      "  episode_reward_min: 139.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 3874\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.36237832903862\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011315174400806427\n",
      "          model: {}\n",
      "          policy_loss: -0.020493283867836\n",
      "          total_loss: 337.1374206542969\n",
      "          vf_explained_var: 0.4622632563114166\n",
      "          vf_loss: 337.15283203125\n",
      "    num_agent_steps_sampled: 671832\n",
      "    num_agent_steps_trained: 671832\n",
      "    num_steps_sampled: 671832\n",
      "    num_steps_trained: 671832\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.81538461538462\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08983426624195336\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09177206692164797\n",
      "    mean_inference_ms: 0.9870840836903665\n",
      "    mean_raw_obs_processing_ms: 0.11820602756943113\n",
      "  time_since_restore: 810.2864089012146\n",
      "  time_this_iter_s: 9.396814823150635\n",
      "  time_total_s: 810.2864089012146\n",
      "  timers:\n",
      "    learn_throughput: 1382.935\n",
      "    learn_time_ms: 5783.351\n",
      "    load_throughput: 26325075.251\n",
      "    load_time_ms: 0.304\n",
      "    sample_throughput: 868.839\n",
      "    sample_time_ms: 9205.391\n",
      "    update_time_ms: 2.62\n",
      "  timestamp: 1645203186\n",
      "  timesteps_since_restore: 671832\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 671832\n",
      "  training_iteration: 84\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:53:10 (running for 00:40:06.79)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         810.286</td><td style=\"text-align: right;\"> 671832</td><td style=\"text-align: right;\">  198.55</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 139</td><td style=\"text-align: right;\">            198.55</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:53:15 (running for 00:40:11.80)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         810.286</td><td style=\"text-align: right;\"> 671832</td><td style=\"text-align: right;\">  198.55</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 139</td><td style=\"text-align: right;\">            198.55</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 679830\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-53-15\n",
      "  done: false\n",
      "  episode_len_mean: 198.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.45\n",
      "  episode_reward_min: 153.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 3914\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.34628796577453613\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0109259570017457\n",
      "          model: {}\n",
      "          policy_loss: -0.011146673001348972\n",
      "          total_loss: 275.6906433105469\n",
      "          vf_explained_var: 0.5636376142501831\n",
      "          vf_loss: 275.6968688964844\n",
      "    num_agent_steps_sampled: 679830\n",
      "    num_agent_steps_trained: 679830\n",
      "    num_steps_sampled: 679830\n",
      "    num_steps_trained: 679830\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.6076923076923\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08979926279613978\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09172777472612773\n",
      "    mean_inference_ms: 0.986635396057807\n",
      "    mean_raw_obs_processing_ms: 0.1181298307368887\n",
      "  time_since_restore: 819.3337235450745\n",
      "  time_this_iter_s: 9.047314643859863\n",
      "  time_total_s: 819.3337235450745\n",
      "  timers:\n",
      "    learn_throughput: 1386.325\n",
      "    learn_time_ms: 5769.209\n",
      "    load_throughput: 26564811.048\n",
      "    load_time_ms: 0.301\n",
      "    sample_throughput: 867.403\n",
      "    sample_time_ms: 9220.63\n",
      "    update_time_ms: 2.61\n",
      "  timestamp: 1645203195\n",
      "  timesteps_since_restore: 679830\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 679830\n",
      "  training_iteration: 85\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:53:20 (running for 00:40:16.88)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         819.334</td><td style=\"text-align: right;\"> 679830</td><td style=\"text-align: right;\">  198.45</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">            198.45</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 687828\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-53-24\n",
      "  done: false\n",
      "  episode_len_mean: 197.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.66\n",
      "  episode_reward_min: 151.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 3955\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3524080812931061\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011205198243260384\n",
      "          model: {}\n",
      "          policy_loss: -0.011886613443493843\n",
      "          total_loss: 344.63690185546875\n",
      "          vf_explained_var: 0.5253838896751404\n",
      "          vf_loss: 344.64373779296875\n",
      "    num_agent_steps_sampled: 687828\n",
      "    num_agent_steps_trained: 687828\n",
      "    num_steps_sampled: 687828\n",
      "    num_steps_trained: 687828\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.99999999999999\n",
      "    ram_util_percent: 17.915384615384617\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08973928081012011\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09166648742820087\n",
      "    mean_inference_ms: 0.9860669602817286\n",
      "    mean_raw_obs_processing_ms: 0.1180148580089189\n",
      "  time_since_restore: 828.4383144378662\n",
      "  time_this_iter_s: 9.104590892791748\n",
      "  time_total_s: 828.4383144378662\n",
      "  timers:\n",
      "    learn_throughput: 1388.505\n",
      "    learn_time_ms: 5760.152\n",
      "    load_throughput: 25934320.365\n",
      "    load_time_ms: 0.308\n",
      "    sample_throughput: 868.085\n",
      "    sample_time_ms: 9213.383\n",
      "    update_time_ms: 2.59\n",
      "  timestamp: 1645203204\n",
      "  timesteps_since_restore: 687828\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 687828\n",
      "  training_iteration: 86\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:53:25 (running for 00:40:21.96)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         828.438</td><td style=\"text-align: right;\"> 687828</td><td style=\"text-align: right;\">  197.66</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 151</td><td style=\"text-align: right;\">            197.66</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:53:30 (running for 00:40:27.01)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         828.438</td><td style=\"text-align: right;\"> 687828</td><td style=\"text-align: right;\">  197.66</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 151</td><td style=\"text-align: right;\">            197.66</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 695826\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-53-33\n",
      "  done: false\n",
      "  episode_len_mean: 198.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.42\n",
      "  episode_reward_min: 151.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 3994\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.34845852851867676\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009653058834373951\n",
      "          model: {}\n",
      "          policy_loss: -0.011471248231828213\n",
      "          total_loss: 338.583740234375\n",
      "          vf_explained_var: 0.4943660497665405\n",
      "          vf_loss: 338.5908508300781\n",
      "    num_agent_steps_sampled: 695826\n",
      "    num_agent_steps_trained: 695826\n",
      "    num_steps_sampled: 695826\n",
      "    num_steps_trained: 695826\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.16923076923077\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08972259259830885\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09159335886494442\n",
      "    mean_inference_ms: 0.9858171279491753\n",
      "    mean_raw_obs_processing_ms: 0.11793899671139033\n",
      "  time_since_restore: 837.5115501880646\n",
      "  time_this_iter_s: 9.073235750198364\n",
      "  time_total_s: 837.5115501880646\n",
      "  timers:\n",
      "    learn_throughput: 1390.371\n",
      "    learn_time_ms: 5752.423\n",
      "    load_throughput: 25902280.435\n",
      "    load_time_ms: 0.309\n",
      "    sample_throughput: 870.501\n",
      "    sample_time_ms: 9187.808\n",
      "    update_time_ms: 2.57\n",
      "  timestamp: 1645203213\n",
      "  timesteps_since_restore: 695826\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 695826\n",
      "  training_iteration: 87\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:53:35 (running for 00:40:32.06)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         837.512</td><td style=\"text-align: right;\"> 695826</td><td style=\"text-align: right;\">  198.42</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 151</td><td style=\"text-align: right;\">            198.42</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:53:40 (running for 00:40:37.10)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         837.512</td><td style=\"text-align: right;\"> 695826</td><td style=\"text-align: right;\">  198.42</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 151</td><td style=\"text-align: right;\">            198.42</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 703824\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-53-42\n",
      "  done: false\n",
      "  episode_len_mean: 198.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.19\n",
      "  episode_reward_min: 151.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 4034\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.34967249631881714\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01022928673774004\n",
      "          model: {}\n",
      "          policy_loss: -0.005661319941282272\n",
      "          total_loss: 305.9718322753906\n",
      "          vf_explained_var: 0.5213763117790222\n",
      "          vf_loss: 305.9729309082031\n",
      "    num_agent_steps_sampled: 703824\n",
      "    num_agent_steps_trained: 703824\n",
      "    num_steps_sampled: 703824\n",
      "    num_steps_trained: 703824\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.44615384615385\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08966046894639243\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09154445318915722\n",
      "    mean_inference_ms: 0.9852540078381011\n",
      "    mean_raw_obs_processing_ms: 0.1178486713901081\n",
      "  time_since_restore: 846.6029009819031\n",
      "  time_this_iter_s: 9.091350793838501\n",
      "  time_total_s: 846.6029009819031\n",
      "  timers:\n",
      "    learn_throughput: 1391.808\n",
      "    learn_time_ms: 5746.483\n",
      "    load_throughput: 26045064.745\n",
      "    load_time_ms: 0.307\n",
      "    sample_throughput: 872.349\n",
      "    sample_time_ms: 9168.353\n",
      "    update_time_ms: 2.535\n",
      "  timestamp: 1645203222\n",
      "  timesteps_since_restore: 703824\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 703824\n",
      "  training_iteration: 88\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:53:45 (running for 00:40:42.17)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         846.603</td><td style=\"text-align: right;\"> 703824</td><td style=\"text-align: right;\">  198.19</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 151</td><td style=\"text-align: right;\">            198.19</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:53:50 (running for 00:40:47.22)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         846.603</td><td style=\"text-align: right;\"> 703824</td><td style=\"text-align: right;\">  198.19</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 151</td><td style=\"text-align: right;\">            198.19</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 711822\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-53-51\n",
      "  done: false\n",
      "  episode_len_mean: 197.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.68\n",
      "  episode_reward_min: 126.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 4076\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3386455774307251\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008942140266299248\n",
      "          model: {}\n",
      "          policy_loss: -0.009029286913573742\n",
      "          total_loss: 286.36138916015625\n",
      "          vf_explained_var: 0.542341411113739\n",
      "          vf_loss: 286.36639404296875\n",
      "    num_agent_steps_sampled: 711822\n",
      "    num_agent_steps_trained: 711822\n",
      "    num_steps_sampled: 711822\n",
      "    num_steps_trained: 711822\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.53076923076922\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08960444116877708\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09149694506574932\n",
      "    mean_inference_ms: 0.9846820658802793\n",
      "    mean_raw_obs_processing_ms: 0.11776078638928056\n",
      "  time_since_restore: 855.5883550643921\n",
      "  time_this_iter_s: 8.985454082489014\n",
      "  time_total_s: 855.5883550643921\n",
      "  timers:\n",
      "    learn_throughput: 1394.078\n",
      "    learn_time_ms: 5737.124\n",
      "    load_throughput: 26120099.192\n",
      "    load_time_ms: 0.306\n",
      "    sample_throughput: 872.758\n",
      "    sample_time_ms: 9164.049\n",
      "    update_time_ms: 2.532\n",
      "  timestamp: 1645203231\n",
      "  timesteps_since_restore: 711822\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 711822\n",
      "  training_iteration: 89\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:53:56 (running for 00:40:53.19)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         855.588</td><td style=\"text-align: right;\"> 711822</td><td style=\"text-align: right;\">  197.68</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 126</td><td style=\"text-align: right;\">            197.68</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 719820\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-54-00\n",
      "  done: false\n",
      "  episode_len_mean: 196.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.01\n",
      "  episode_reward_min: 126.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 4117\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.36286258697509766\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010711991228163242\n",
      "          model: {}\n",
      "          policy_loss: -0.019677262753248215\n",
      "          total_loss: 314.2777099609375\n",
      "          vf_explained_var: 0.5772092342376709\n",
      "          vf_loss: 314.29254150390625\n",
      "    num_agent_steps_sampled: 719820\n",
      "    num_agent_steps_trained: 719820\n",
      "    num_steps_sampled: 719820\n",
      "    num_steps_trained: 719820\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.43076923076924\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08954326540575039\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09143549520554899\n",
      "    mean_inference_ms: 0.9840245317249898\n",
      "    mean_raw_obs_processing_ms: 0.11764990180100472\n",
      "  time_since_restore: 864.6553344726562\n",
      "  time_this_iter_s: 9.06697940826416\n",
      "  time_total_s: 864.6553344726562\n",
      "  timers:\n",
      "    learn_throughput: 1395.217\n",
      "    learn_time_ms: 5732.443\n",
      "    load_throughput: 25938330.93\n",
      "    load_time_ms: 0.308\n",
      "    sample_throughput: 874.309\n",
      "    sample_time_ms: 9147.795\n",
      "    update_time_ms: 2.559\n",
      "  timestamp: 1645203240\n",
      "  timesteps_since_restore: 719820\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 719820\n",
      "  training_iteration: 90\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:54:01 (running for 00:40:58.32)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         864.655</td><td style=\"text-align: right;\"> 719820</td><td style=\"text-align: right;\">  196.01</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 126</td><td style=\"text-align: right;\">            196.01</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:54:06 (running for 00:41:03.33)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         864.655</td><td style=\"text-align: right;\"> 719820</td><td style=\"text-align: right;\">  196.01</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 126</td><td style=\"text-align: right;\">            196.01</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 727818\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-54-09\n",
      "  done: false\n",
      "  episode_len_mean: 195.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.94\n",
      "  episode_reward_min: 129.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 4158\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.35374176502227783\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012285466305911541\n",
      "          model: {}\n",
      "          policy_loss: -0.008566195145249367\n",
      "          total_loss: 308.6598205566406\n",
      "          vf_explained_var: 0.5593597888946533\n",
      "          vf_loss: 308.6628723144531\n",
      "    num_agent_steps_sampled: 727818\n",
      "    num_agent_steps_trained: 727818\n",
      "    num_steps_sampled: 727818\n",
      "    num_steps_trained: 727818\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.7\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08949498470807914\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0913826201783558\n",
      "    mean_inference_ms: 0.983508702380634\n",
      "    mean_raw_obs_processing_ms: 0.11756490218642453\n",
      "  time_since_restore: 873.6642951965332\n",
      "  time_this_iter_s: 9.008960723876953\n",
      "  time_total_s: 873.6642951965332\n",
      "  timers:\n",
      "    learn_throughput: 1398.128\n",
      "    learn_time_ms: 5720.507\n",
      "    load_throughput: 25560837.696\n",
      "    load_time_ms: 0.313\n",
      "    sample_throughput: 874.621\n",
      "    sample_time_ms: 9144.537\n",
      "    update_time_ms: 2.509\n",
      "  timestamp: 1645203249\n",
      "  timesteps_since_restore: 727818\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 727818\n",
      "  training_iteration: 91\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:54:11 (running for 00:41:08.35)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         873.664</td><td style=\"text-align: right;\"> 727818</td><td style=\"text-align: right;\">  195.94</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 129</td><td style=\"text-align: right;\">            195.94</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:54:16 (running for 00:41:13.36)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         873.664</td><td style=\"text-align: right;\"> 727818</td><td style=\"text-align: right;\">  195.94</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 129</td><td style=\"text-align: right;\">            195.94</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 735816\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-54-20\n",
      "  done: false\n",
      "  episode_len_mean: 197.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.22\n",
      "  episode_reward_min: 129.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 4197\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3542223572731018\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009478755295276642\n",
      "          model: {}\n",
      "          policy_loss: -0.011684877797961235\n",
      "          total_loss: 312.9032897949219\n",
      "          vf_explained_var: 0.5454016327857971\n",
      "          vf_loss: 312.91070556640625\n",
      "    num_agent_steps_sampled: 735816\n",
      "    num_agent_steps_trained: 735816\n",
      "    num_steps_sampled: 735816\n",
      "    num_steps_trained: 735816\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.72666666666666\n",
      "    ram_util_percent: 17.9\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08946376233908294\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09132311051340469\n",
      "    mean_inference_ms: 0.9831342984805161\n",
      "    mean_raw_obs_processing_ms: 0.11749191993554486\n",
      "  time_since_restore: 884.0947420597076\n",
      "  time_this_iter_s: 10.430446863174438\n",
      "  time_total_s: 884.0947420597076\n",
      "  timers:\n",
      "    learn_throughput: 1366.31\n",
      "    learn_time_ms: 5853.722\n",
      "    load_throughput: 25768968.653\n",
      "    load_time_ms: 0.31\n",
      "    sample_throughput: 877.11\n",
      "    sample_time_ms: 9118.582\n",
      "    update_time_ms: 2.504\n",
      "  timestamp: 1645203260\n",
      "  timesteps_since_restore: 735816\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 735816\n",
      "  training_iteration: 92\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:54:22 (running for 00:41:18.79)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         884.095</td><td style=\"text-align: right;\"> 735816</td><td style=\"text-align: right;\">  197.22</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 129</td><td style=\"text-align: right;\">            197.22</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:54:27 (running for 00:41:23.80)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         884.095</td><td style=\"text-align: right;\"> 735816</td><td style=\"text-align: right;\">  197.22</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 129</td><td style=\"text-align: right;\">            197.22</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 743814\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-54-29\n",
      "  done: false\n",
      "  episode_len_mean: 199.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.3\n",
      "  episode_reward_min: 160.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 4237\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3508811891078949\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01032670121639967\n",
      "          model: {}\n",
      "          policy_loss: -0.0137944296002388\n",
      "          total_loss: 221.9215087890625\n",
      "          vf_explained_var: 0.6926341652870178\n",
      "          vf_loss: 221.93064880371094\n",
      "    num_agent_steps_sampled: 743814\n",
      "    num_agent_steps_trained: 743814\n",
      "    num_steps_sampled: 743814\n",
      "    num_steps_trained: 743814\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.74615384615385\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08941875134409609\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0912573051346514\n",
      "    mean_inference_ms: 0.9826975446236849\n",
      "    mean_raw_obs_processing_ms: 0.11739843571286603\n",
      "  time_since_restore: 893.1141939163208\n",
      "  time_this_iter_s: 9.01945185661316\n",
      "  time_total_s: 893.1141939163208\n",
      "  timers:\n",
      "    learn_throughput: 1366.188\n",
      "    learn_time_ms: 5854.248\n",
      "    load_throughput: 25804648.763\n",
      "    load_time_ms: 0.31\n",
      "    sample_throughput: 864.986\n",
      "    sample_time_ms: 9246.391\n",
      "    update_time_ms: 2.55\n",
      "  timestamp: 1645203269\n",
      "  timesteps_since_restore: 743814\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 743814\n",
      "  training_iteration: 93\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:54:32 (running for 00:41:28.86)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         893.114</td><td style=\"text-align: right;\"> 743814</td><td style=\"text-align: right;\">  199.3 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 160</td><td style=\"text-align: right;\">            199.3 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:54:37 (running for 00:41:33.87)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         893.114</td><td style=\"text-align: right;\"> 743814</td><td style=\"text-align: right;\">  199.3 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 160</td><td style=\"text-align: right;\">            199.3 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 751812\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-54-38\n",
      "  done: false\n",
      "  episode_len_mean: 199.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.7\n",
      "  episode_reward_min: 170.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 4278\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3304542899131775\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00982721894979477\n",
      "          model: {}\n",
      "          policy_loss: -0.00519370473921299\n",
      "          total_loss: 321.76788330078125\n",
      "          vf_explained_var: 0.5744379758834839\n",
      "          vf_loss: 321.7686767578125\n",
      "    num_agent_steps_sampled: 751812\n",
      "    num_agent_steps_trained: 751812\n",
      "    num_steps_sampled: 751812\n",
      "    num_steps_trained: 751812\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.53076923076922\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08935214735165492\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09120858784688092\n",
      "    mean_inference_ms: 0.9821458377976423\n",
      "    mean_raw_obs_processing_ms: 0.11730248463124733\n",
      "  time_since_restore: 902.2758905887604\n",
      "  time_this_iter_s: 9.161696672439575\n",
      "  time_total_s: 902.2758905887604\n",
      "  timers:\n",
      "    learn_throughput: 1372.525\n",
      "    learn_time_ms: 5827.217\n",
      "    load_throughput: 24617335.725\n",
      "    load_time_ms: 0.325\n",
      "    sample_throughput: 864.62\n",
      "    sample_time_ms: 9250.312\n",
      "    update_time_ms: 2.62\n",
      "  timestamp: 1645203278\n",
      "  timesteps_since_restore: 751812\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 751812\n",
      "  training_iteration: 94\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:54:42 (running for 00:41:39.04)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         902.276</td><td style=\"text-align: right;\"> 751812</td><td style=\"text-align: right;\">  199.7 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 170</td><td style=\"text-align: right;\">            199.7 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:54:47 (running for 00:41:44.05)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         902.276</td><td style=\"text-align: right;\"> 751812</td><td style=\"text-align: right;\">  199.7 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 170</td><td style=\"text-align: right;\">            199.7 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 759810\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-54-47\n",
      "  done: false\n",
      "  episode_len_mean: 199.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.35\n",
      "  episode_reward_min: 166.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 4317\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.347526490688324\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010845339857041836\n",
      "          model: {}\n",
      "          policy_loss: -0.010364596731960773\n",
      "          total_loss: 244.12879943847656\n",
      "          vf_explained_var: 0.6407372951507568\n",
      "          vf_loss: 244.13427734375\n",
      "    num_agent_steps_sampled: 759810\n",
      "    num_agent_steps_trained: 759810\n",
      "    num_steps_sampled: 759810\n",
      "    num_steps_trained: 759810\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.52307692307691\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08931813857460556\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0911709683607985\n",
      "    mean_inference_ms: 0.9819541825340851\n",
      "    mean_raw_obs_processing_ms: 0.11724646795182465\n",
      "  time_since_restore: 911.5175819396973\n",
      "  time_this_iter_s: 9.24169135093689\n",
      "  time_total_s: 911.5175819396973\n",
      "  timers:\n",
      "    learn_throughput: 1370.947\n",
      "    learn_time_ms: 5833.924\n",
      "    load_throughput: 24611917.382\n",
      "    load_time_ms: 0.325\n",
      "    sample_throughput: 865.906\n",
      "    sample_time_ms: 9236.566\n",
      "    update_time_ms: 2.628\n",
      "  timestamp: 1645203287\n",
      "  timesteps_since_restore: 759810\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 759810\n",
      "  training_iteration: 95\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:54:52 (running for 00:41:49.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         911.518</td><td style=\"text-align: right;\"> 759810</td><td style=\"text-align: right;\">  199.35</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 166</td><td style=\"text-align: right;\">            199.35</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 767808\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-54-56\n",
      "  done: false\n",
      "  episode_len_mean: 198.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.36\n",
      "  episode_reward_min: 137.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 4359\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.33640214800834656\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009343769401311874\n",
      "          model: {}\n",
      "          policy_loss: -0.010426959954202175\n",
      "          total_loss: 304.3421325683594\n",
      "          vf_explained_var: 0.5676742792129517\n",
      "          vf_loss: 304.34832763671875\n",
      "    num_agent_steps_sampled: 767808\n",
      "    num_agent_steps_trained: 767808\n",
      "    num_steps_sampled: 767808\n",
      "    num_steps_trained: 767808\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.70769230769233\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08929171922030064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09114419992245612\n",
      "    mean_inference_ms: 0.9818225092147483\n",
      "    mean_raw_obs_processing_ms: 0.11719966691411264\n",
      "  time_since_restore: 920.5555441379547\n",
      "  time_this_iter_s: 9.037962198257446\n",
      "  time_total_s: 920.5555441379547\n",
      "  timers:\n",
      "    learn_throughput: 1372.629\n",
      "    learn_time_ms: 5826.776\n",
      "    load_throughput: 24880251.718\n",
      "    load_time_ms: 0.321\n",
      "    sample_throughput: 865.305\n",
      "    sample_time_ms: 9242.986\n",
      "    update_time_ms: 2.614\n",
      "  timestamp: 1645203296\n",
      "  timesteps_since_restore: 767808\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 767808\n",
      "  training_iteration: 96\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:54:57 (running for 00:41:54.32)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         920.556</td><td style=\"text-align: right;\"> 767808</td><td style=\"text-align: right;\">  198.36</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 137</td><td style=\"text-align: right;\">            198.36</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:55:02 (running for 00:41:59.36)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         920.556</td><td style=\"text-align: right;\"> 767808</td><td style=\"text-align: right;\">  198.36</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 137</td><td style=\"text-align: right;\">            198.36</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 775806\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-55-05\n",
      "  done: false\n",
      "  episode_len_mean: 198.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.5\n",
      "  episode_reward_min: 137.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 4398\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.34248703718185425\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010466307401657104\n",
      "          model: {}\n",
      "          policy_loss: -0.0030489193741232157\n",
      "          total_loss: 327.8896484375\n",
      "          vf_explained_var: 0.5718517899513245\n",
      "          vf_loss: 327.8879699707031\n",
      "    num_agent_steps_sampled: 775806\n",
      "    num_agent_steps_trained: 775806\n",
      "    num_steps_sampled: 775806\n",
      "    num_steps_trained: 775806\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.16923076923077\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08926327949476713\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09111688471184784\n",
      "    mean_inference_ms: 0.9816053637327241\n",
      "    mean_raw_obs_processing_ms: 0.11715264418690274\n",
      "  time_since_restore: 929.7713778018951\n",
      "  time_this_iter_s: 9.21583366394043\n",
      "  time_total_s: 929.7713778018951\n",
      "  timers:\n",
      "    learn_throughput: 1371.014\n",
      "    learn_time_ms: 5833.638\n",
      "    load_throughput: 24677095.33\n",
      "    load_time_ms: 0.324\n",
      "    sample_throughput: 865.293\n",
      "    sample_time_ms: 9243.108\n",
      "    update_time_ms: 2.613\n",
      "  timestamp: 1645203305\n",
      "  timesteps_since_restore: 775806\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 775806\n",
      "  training_iteration: 97\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:55:08 (running for 00:42:04.56)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         929.771</td><td style=\"text-align: right;\"> 775806</td><td style=\"text-align: right;\">  198.5 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 137</td><td style=\"text-align: right;\">            198.5 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:55:13 (running for 00:42:09.61)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         929.771</td><td style=\"text-align: right;\"> 775806</td><td style=\"text-align: right;\">  198.5 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 137</td><td style=\"text-align: right;\">            198.5 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 783804\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-55-15\n",
      "  done: false\n",
      "  episode_len_mean: 198.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.46\n",
      "  episode_reward_min: 150.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 4439\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.34122028946876526\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011409066617488861\n",
      "          model: {}\n",
      "          policy_loss: -0.013735794462263584\n",
      "          total_loss: 298.6332702636719\n",
      "          vf_explained_var: 0.589198112487793\n",
      "          vf_loss: 298.6418762207031\n",
      "    num_agent_steps_sampled: 783804\n",
      "    num_agent_steps_trained: 783804\n",
      "    num_steps_sampled: 783804\n",
      "    num_steps_trained: 783804\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.73846153846154\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08919814408087064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09108144666456369\n",
      "    mean_inference_ms: 0.9810962076213673\n",
      "    mean_raw_obs_processing_ms: 0.11706122076544472\n",
      "  time_since_restore: 938.9226253032684\n",
      "  time_this_iter_s: 9.151247501373291\n",
      "  time_total_s: 938.9226253032684\n",
      "  timers:\n",
      "    learn_throughput: 1368.647\n",
      "    learn_time_ms: 5843.727\n",
      "    load_throughput: 24095707.077\n",
      "    load_time_ms: 0.332\n",
      "    sample_throughput: 865.035\n",
      "    sample_time_ms: 9245.873\n",
      "    update_time_ms: 2.625\n",
      "  timestamp: 1645203315\n",
      "  timesteps_since_restore: 783804\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 783804\n",
      "  training_iteration: 98\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:55:18 (running for 00:42:14.74)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         938.923</td><td style=\"text-align: right;\"> 783804</td><td style=\"text-align: right;\">  198.46</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 150</td><td style=\"text-align: right;\">            198.46</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:55:23 (running for 00:42:19.78)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         938.923</td><td style=\"text-align: right;\"> 783804</td><td style=\"text-align: right;\">  198.46</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 150</td><td style=\"text-align: right;\">            198.46</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 791802\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-55-24\n",
      "  done: false\n",
      "  episode_len_mean: 199.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.21\n",
      "  episode_reward_min: 174.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 4479\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3325255811214447\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010590647347271442\n",
      "          model: {}\n",
      "          policy_loss: -0.00835624523460865\n",
      "          total_loss: 345.34747314453125\n",
      "          vf_explained_var: 0.5030254125595093\n",
      "          vf_loss: 345.35107421875\n",
      "    num_agent_steps_sampled: 791802\n",
      "    num_agent_steps_trained: 791802\n",
      "    num_steps_sampled: 791802\n",
      "    num_steps_trained: 791802\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.40769230769232\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08917441088503264\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0910333345466968\n",
      "    mean_inference_ms: 0.9808203531684835\n",
      "    mean_raw_obs_processing_ms: 0.11699574756113482\n",
      "  time_since_restore: 947.911463022232\n",
      "  time_this_iter_s: 8.988837718963623\n",
      "  time_total_s: 947.911463022232\n",
      "  timers:\n",
      "    learn_throughput: 1367.177\n",
      "    learn_time_ms: 5850.009\n",
      "    load_throughput: 24233217.794\n",
      "    load_time_ms: 0.33\n",
      "    sample_throughput: 864.634\n",
      "    sample_time_ms: 9250.158\n",
      "    update_time_ms: 2.622\n",
      "  timestamp: 1645203324\n",
      "  timesteps_since_restore: 791802\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 791802\n",
      "  training_iteration: 99\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:55:29 (running for 00:42:25.75)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         947.911</td><td style=\"text-align: right;\"> 791802</td><td style=\"text-align: right;\">  199.21</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 174</td><td style=\"text-align: right;\">            199.21</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 799800\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-55-33\n",
      "  done: false\n",
      "  episode_len_mean: 198.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.87\n",
      "  episode_reward_min: 164.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 4519\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.338824063539505\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012393264099955559\n",
      "          model: {}\n",
      "          policy_loss: -0.009841375052928925\n",
      "          total_loss: 332.0562744140625\n",
      "          vf_explained_var: 0.5504248738288879\n",
      "          vf_loss: 332.060546875\n",
      "    num_agent_steps_sampled: 799800\n",
      "    num_agent_steps_trained: 799800\n",
      "    num_steps_sampled: 799800\n",
      "    num_steps_trained: 799800\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.57692307692308\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08913566789291316\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09099828976658414\n",
      "    mean_inference_ms: 0.9804243003555234\n",
      "    mean_raw_obs_processing_ms: 0.11692114105001909\n",
      "  time_since_restore: 957.0876672267914\n",
      "  time_this_iter_s: 9.176204204559326\n",
      "  time_total_s: 957.0876672267914\n",
      "  timers:\n",
      "    learn_throughput: 1365.648\n",
      "    learn_time_ms: 5856.56\n",
      "    load_throughput: 23903408.431\n",
      "    load_time_ms: 0.335\n",
      "    sample_throughput: 863.64\n",
      "    sample_time_ms: 9260.801\n",
      "    update_time_ms: 2.621\n",
      "  timestamp: 1645203333\n",
      "  timesteps_since_restore: 799800\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 799800\n",
      "  training_iteration: 100\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:55:34 (running for 00:42:30.99)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         957.088</td><td style=\"text-align: right;\"> 799800</td><td style=\"text-align: right;\">  198.87</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 164</td><td style=\"text-align: right;\">            198.87</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:55:39 (running for 00:42:36.00)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         957.088</td><td style=\"text-align: right;\"> 799800</td><td style=\"text-align: right;\">  198.87</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 164</td><td style=\"text-align: right;\">            198.87</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 807798\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-55-42\n",
      "  done: false\n",
      "  episode_len_mean: 199.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.41\n",
      "  episode_reward_min: 164.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 4559\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.33646246790885925\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009749915450811386\n",
      "          model: {}\n",
      "          policy_loss: -0.015194345265626907\n",
      "          total_loss: 305.00244140625\n",
      "          vf_explained_var: 0.5401930809020996\n",
      "          vf_loss: 305.0132751464844\n",
      "    num_agent_steps_sampled: 807798\n",
      "    num_agent_steps_trained: 807798\n",
      "    num_steps_sampled: 807798\n",
      "    num_steps_trained: 807798\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.03076923076924\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08910898283161899\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09097297632884806\n",
      "    mean_inference_ms: 0.9801485950346008\n",
      "    mean_raw_obs_processing_ms: 0.11686107287574536\n",
      "  time_since_restore: 966.2648100852966\n",
      "  time_this_iter_s: 9.177142858505249\n",
      "  time_total_s: 966.2648100852966\n",
      "  timers:\n",
      "    learn_throughput: 1363.232\n",
      "    learn_time_ms: 5866.938\n",
      "    load_throughput: 23555960.531\n",
      "    load_time_ms: 0.34\n",
      "    sample_throughput: 862.461\n",
      "    sample_time_ms: 9273.462\n",
      "    update_time_ms: 2.669\n",
      "  timestamp: 1645203342\n",
      "  timesteps_since_restore: 807798\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 807798\n",
      "  training_iteration: 101\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:55:44 (running for 00:42:41.20)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         966.265</td><td style=\"text-align: right;\"> 807798</td><td style=\"text-align: right;\">  199.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 164</td><td style=\"text-align: right;\">            199.41</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:55:49 (running for 00:42:46.21)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         966.265</td><td style=\"text-align: right;\"> 807798</td><td style=\"text-align: right;\">  199.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 164</td><td style=\"text-align: right;\">            199.41</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 815796\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-55-51\n",
      "  done: false\n",
      "  episode_len_mean: 199.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.33\n",
      "  episode_reward_min: 167.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 4600\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3183438777923584\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009942413307726383\n",
      "          model: {}\n",
      "          policy_loss: -0.003884491976350546\n",
      "          total_loss: 389.38311767578125\n",
      "          vf_explained_var: 0.43346741795539856\n",
      "          vf_loss: 389.3825378417969\n",
      "    num_agent_steps_sampled: 815796\n",
      "    num_agent_steps_trained: 815796\n",
      "    num_steps_sampled: 815796\n",
      "    num_steps_trained: 815796\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.77692307692305\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08907850880183535\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09094532533010408\n",
      "    mean_inference_ms: 0.9799317254841986\n",
      "    mean_raw_obs_processing_ms: 0.11680084929944017\n",
      "  time_since_restore: 975.3509213924408\n",
      "  time_this_iter_s: 9.086111307144165\n",
      "  time_total_s: 975.3509213924408\n",
      "  timers:\n",
      "    learn_throughput: 1394.56\n",
      "    learn_time_ms: 5735.141\n",
      "    load_throughput: 23383551.786\n",
      "    load_time_ms: 0.342\n",
      "    sample_throughput: 861.718\n",
      "    sample_time_ms: 9281.457\n",
      "    update_time_ms: 2.724\n",
      "  timestamp: 1645203351\n",
      "  timesteps_since_restore: 815796\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 815796\n",
      "  training_iteration: 102\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:55:54 (running for 00:42:51.31)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         975.351</td><td style=\"text-align: right;\"> 815796</td><td style=\"text-align: right;\">  199.33</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 167</td><td style=\"text-align: right;\">            199.33</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:55:59 (running for 00:42:56.32)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         975.351</td><td style=\"text-align: right;\"> 815796</td><td style=\"text-align: right;\">  199.33</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 167</td><td style=\"text-align: right;\">            199.33</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 823794\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-56-00\n",
      "  done: false\n",
      "  episode_len_mean: 198.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.55\n",
      "  episode_reward_min: 157.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 4639\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.32820868492126465\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009901481680572033\n",
      "          model: {}\n",
      "          policy_loss: -0.00830301083624363\n",
      "          total_loss: 352.283203125\n",
      "          vf_explained_var: 0.4904192388057709\n",
      "          vf_loss: 352.2870178222656\n",
      "    num_agent_steps_sampled: 823794\n",
      "    num_agent_steps_trained: 823794\n",
      "    num_steps_sampled: 823794\n",
      "    num_steps_trained: 823794\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.45714285714287\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08905376650686671\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09092462042013834\n",
      "    mean_inference_ms: 0.9797734052996089\n",
      "    mean_raw_obs_processing_ms: 0.11675133120132224\n",
      "  time_since_restore: 984.630450963974\n",
      "  time_this_iter_s: 9.279529571533203\n",
      "  time_total_s: 984.630450963974\n",
      "  timers:\n",
      "    learn_throughput: 1392.868\n",
      "    learn_time_ms: 5742.109\n",
      "    load_throughput: 23289394.191\n",
      "    load_time_ms: 0.343\n",
      "    sample_throughput: 872.304\n",
      "    sample_time_ms: 9168.821\n",
      "    update_time_ms: 2.665\n",
      "  timestamp: 1645203360\n",
      "  timesteps_since_restore: 823794\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 823794\n",
      "  training_iteration: 103\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:56:05 (running for 00:43:01.60)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">          984.63</td><td style=\"text-align: right;\"> 823794</td><td style=\"text-align: right;\">  198.55</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 157</td><td style=\"text-align: right;\">            198.55</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:56:10 (running for 00:43:06.61)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">          984.63</td><td style=\"text-align: right;\"> 823794</td><td style=\"text-align: right;\">  198.55</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 157</td><td style=\"text-align: right;\">            198.55</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 831792\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-56-10\n",
      "  done: false\n",
      "  episode_len_mean: 199.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.2\n",
      "  episode_reward_min: 157.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 4680\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3210287094116211\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010844457894563675\n",
      "          model: {}\n",
      "          policy_loss: -0.00916116964071989\n",
      "          total_loss: 274.6167907714844\n",
      "          vf_explained_var: 0.5844730734825134\n",
      "          vf_loss: 274.6210632324219\n",
      "    num_agent_steps_sampled: 831792\n",
      "    num_agent_steps_trained: 831792\n",
      "    num_steps_sampled: 831792\n",
      "    num_steps_trained: 831792\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.75833333333331\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08903748298471244\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09088643959893876\n",
      "    mean_inference_ms: 0.9795483846784723\n",
      "    mean_raw_obs_processing_ms: 0.11669777037098344\n",
      "  time_since_restore: 993.6942360401154\n",
      "  time_this_iter_s: 9.063785076141357\n",
      "  time_total_s: 993.6942360401154\n",
      "  timers:\n",
      "    learn_throughput: 1393.554\n",
      "    learn_time_ms: 5739.283\n",
      "    load_throughput: 24305204.602\n",
      "    load_time_ms: 0.329\n",
      "    sample_throughput: 872.318\n",
      "    sample_time_ms: 9168.678\n",
      "    update_time_ms: 2.661\n",
      "  timestamp: 1645203370\n",
      "  timesteps_since_restore: 831792\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 831792\n",
      "  training_iteration: 104\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:56:15 (running for 00:43:11.70)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         993.694</td><td style=\"text-align: right;\"> 831792</td><td style=\"text-align: right;\">  199.2 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 157</td><td style=\"text-align: right;\">            199.2 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">        1560.41 </td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 839790\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-56-19\n",
      "  done: false\n",
      "  episode_len_mean: 198.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.39\n",
      "  episode_reward_min: 117.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 4721\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3255094587802887\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009321936406195164\n",
      "          model: {}\n",
      "          policy_loss: -0.018428968265652657\n",
      "          total_loss: 277.0880432128906\n",
      "          vf_explained_var: 0.5866591334342957\n",
      "          vf_loss: 277.102294921875\n",
      "    num_agent_steps_sampled: 839790\n",
      "    num_agent_steps_trained: 839790\n",
      "    num_steps_sampled: 839790\n",
      "    num_steps_trained: 839790\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.8\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08897493552565786\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0908661987102396\n",
      "    mean_inference_ms: 0.9789624600550811\n",
      "    mean_raw_obs_processing_ms: 0.11662885132569947\n",
      "  time_since_restore: 1003.0561485290527\n",
      "  time_this_iter_s: 9.361912488937378\n",
      "  time_total_s: 1003.0561485290527\n",
      "  timers:\n",
      "    learn_throughput: 1388.735\n",
      "    learn_time_ms: 5759.198\n",
      "    load_throughput: 24023233.595\n",
      "    load_time_ms: 0.333\n",
      "    sample_throughput: 873.386\n",
      "    sample_time_ms: 9157.466\n",
      "    update_time_ms: 2.682\n",
      "  timestamp: 1645203379\n",
      "  timesteps_since_restore: 839790\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 839790\n",
      "  training_iteration: 105\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:56:20 (running for 00:43:17.04)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1003.06</td><td style=\"text-align: right;\"> 839790</td><td style=\"text-align: right;\">  198.39</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 117</td><td style=\"text-align: right;\">            198.39</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:56:25 (running for 00:43:22.08)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1003.06</td><td style=\"text-align: right;\"> 839790</td><td style=\"text-align: right;\">  198.39</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 117</td><td style=\"text-align: right;\">            198.39</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 847788\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-56-29\n",
      "  done: false\n",
      "  episode_len_mean: 198.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.82\n",
      "  episode_reward_min: 117.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 4760\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3315170407295227\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011272352188825607\n",
      "          model: {}\n",
      "          policy_loss: -0.010619197972118855\n",
      "          total_loss: 330.65863037109375\n",
      "          vf_explained_var: 0.5469344854354858\n",
      "          vf_loss: 330.6641845703125\n",
      "    num_agent_steps_sampled: 847788\n",
      "    num_agent_steps_trained: 847788\n",
      "    num_steps_sampled: 847788\n",
      "    num_steps_trained: 847788\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.32142857142857\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08895278076707339\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09084587934000338\n",
      "    mean_inference_ms: 0.97871839323854\n",
      "    mean_raw_obs_processing_ms: 0.11659369978056418\n",
      "  time_since_restore: 1012.710239648819\n",
      "  time_this_iter_s: 9.654091119766235\n",
      "  time_total_s: 1012.710239648819\n",
      "  timers:\n",
      "    learn_throughput: 1375.912\n",
      "    learn_time_ms: 5812.874\n",
      "    load_throughput: 24224468.076\n",
      "    load_time_ms: 0.33\n",
      "    sample_throughput: 870.692\n",
      "    sample_time_ms: 9185.799\n",
      "    update_time_ms: 2.67\n",
      "  timestamp: 1645203389\n",
      "  timesteps_since_restore: 847788\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 847788\n",
      "  training_iteration: 106\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:56:31 (running for 00:43:27.72)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1012.71</td><td style=\"text-align: right;\"> 847788</td><td style=\"text-align: right;\">  198.82</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 117</td><td style=\"text-align: right;\">            198.82</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:56:36 (running for 00:43:32.77)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1012.71</td><td style=\"text-align: right;\"> 847788</td><td style=\"text-align: right;\">  198.82</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 117</td><td style=\"text-align: right;\">            198.82</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 855786\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-56-38\n",
      "  done: false\n",
      "  episode_len_mean: 198.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.09\n",
      "  episode_reward_min: 117.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 4801\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.33151721954345703\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01077968068420887\n",
      "          model: {}\n",
      "          policy_loss: -0.020140651613473892\n",
      "          total_loss: 305.4609680175781\n",
      "          vf_explained_var: 0.6274467706680298\n",
      "          vf_loss: 305.4762878417969\n",
      "    num_agent_steps_sampled: 855786\n",
      "    num_agent_steps_trained: 855786\n",
      "    num_steps_sampled: 855786\n",
      "    num_steps_trained: 855786\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.57692307692308\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08893687034804776\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09081349351776734\n",
      "    mean_inference_ms: 0.9784954550957782\n",
      "    mean_raw_obs_processing_ms: 0.11655381206152182\n",
      "  time_since_restore: 1021.8661165237427\n",
      "  time_this_iter_s: 9.155876874923706\n",
      "  time_total_s: 1021.8661165237427\n",
      "  timers:\n",
      "    learn_throughput: 1375.839\n",
      "    learn_time_ms: 5813.181\n",
      "    load_throughput: 24097437.966\n",
      "    load_time_ms: 0.332\n",
      "    sample_throughput: 866.242\n",
      "    sample_time_ms: 9232.989\n",
      "    update_time_ms: 2.721\n",
      "  timestamp: 1645203398\n",
      "  timesteps_since_restore: 855786\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 855786\n",
      "  training_iteration: 107\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:56:41 (running for 00:43:37.90)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1021.87</td><td style=\"text-align: right;\"> 855786</td><td style=\"text-align: right;\">  198.09</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 117</td><td style=\"text-align: right;\">            198.09</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:56:46 (running for 00:43:42.94)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1021.87</td><td style=\"text-align: right;\"> 855786</td><td style=\"text-align: right;\">  198.09</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 117</td><td style=\"text-align: right;\">            198.09</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 863784\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-56-47\n",
      "  done: false\n",
      "  episode_len_mean: 198.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.92\n",
      "  episode_reward_min: 150.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 4841\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.33235591650009155\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009107773192226887\n",
      "          model: {}\n",
      "          policy_loss: -0.011149249970912933\n",
      "          total_loss: 345.4774169921875\n",
      "          vf_explained_var: 0.4855503439903259\n",
      "          vf_loss: 345.48443603515625\n",
      "    num_agent_steps_sampled: 863784\n",
      "    num_agent_steps_trained: 863784\n",
      "    num_steps_sampled: 863784\n",
      "    num_steps_trained: 863784\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.34615384615384\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08892897408844856\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09079534576414776\n",
      "    mean_inference_ms: 0.9783831363321422\n",
      "    mean_raw_obs_processing_ms: 0.11653884519054189\n",
      "  time_since_restore: 1031.1134252548218\n",
      "  time_this_iter_s: 9.247308731079102\n",
      "  time_total_s: 1031.1134252548218\n",
      "  timers:\n",
      "    learn_throughput: 1376.205\n",
      "    learn_time_ms: 5811.632\n",
      "    load_throughput: 24511211.013\n",
      "    load_time_ms: 0.326\n",
      "    sample_throughput: 865.146\n",
      "    sample_time_ms: 9244.682\n",
      "    update_time_ms: 2.715\n",
      "  timestamp: 1645203407\n",
      "  timesteps_since_restore: 863784\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 863784\n",
      "  training_iteration: 108\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:56:51 (running for 00:43:48.17)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1031.11</td><td style=\"text-align: right;\"> 863784</td><td style=\"text-align: right;\">  198.92</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 150</td><td style=\"text-align: right;\">            198.92</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:56:56 (running for 00:43:53.21)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1031.11</td><td style=\"text-align: right;\"> 863784</td><td style=\"text-align: right;\">  198.92</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 150</td><td style=\"text-align: right;\">            198.92</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 871782\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-56-56\n",
      "  done: false\n",
      "  episode_len_mean: 199.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.29\n",
      "  episode_reward_min: 150.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 4880\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3253342807292938\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01099294051527977\n",
      "          model: {}\n",
      "          policy_loss: -0.009260464459657669\n",
      "          total_loss: 344.2003479003906\n",
      "          vf_explained_var: 0.5126233100891113\n",
      "          vf_loss: 344.2046813964844\n",
      "    num_agent_steps_sampled: 871782\n",
      "    num_agent_steps_trained: 871782\n",
      "    num_steps_sampled: 871782\n",
      "    num_steps_trained: 871782\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.86153846153846\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08890279491350694\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0907689685771872\n",
      "    mean_inference_ms: 0.9782147144506488\n",
      "    mean_raw_obs_processing_ms: 0.11649881200610078\n",
      "  time_since_restore: 1040.4037392139435\n",
      "  time_this_iter_s: 9.290313959121704\n",
      "  time_total_s: 1040.4037392139435\n",
      "  timers:\n",
      "    learn_throughput: 1372.676\n",
      "    learn_time_ms: 5826.577\n",
      "    load_throughput: 23871090.438\n",
      "    load_time_ms: 0.335\n",
      "    sample_throughput: 863.846\n",
      "    sample_time_ms: 9258.595\n",
      "    update_time_ms: 2.693\n",
      "  timestamp: 1645203416\n",
      "  timesteps_since_restore: 871782\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 871782\n",
      "  training_iteration: 109\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:57:01 (running for 00:43:58.49)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1040.4 </td><td style=\"text-align: right;\"> 871782</td><td style=\"text-align: right;\">  199.29</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 150</td><td style=\"text-align: right;\">            199.29</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 879780\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-57-06\n",
      "  done: false\n",
      "  episode_len_mean: 199.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.38\n",
      "  episode_reward_min: 165.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 4921\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3343837857246399\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011104825884103775\n",
      "          model: {}\n",
      "          policy_loss: -0.014181317761540413\n",
      "          total_loss: 311.4211120605469\n",
      "          vf_explained_var: 0.6071791052818298\n",
      "          vf_loss: 311.4302978515625\n",
      "    num_agent_steps_sampled: 879780\n",
      "    num_agent_steps_trained: 879780\n",
      "    num_steps_sampled: 879780\n",
      "    num_steps_trained: 879780\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.04285714285716\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08888743041266112\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09073305921946957\n",
      "    mean_inference_ms: 0.9781020805347487\n",
      "    mean_raw_obs_processing_ms: 0.11645377578828603\n",
      "  time_since_restore: 1049.7002367973328\n",
      "  time_this_iter_s: 9.296497583389282\n",
      "  time_total_s: 1049.7002367973328\n",
      "  timers:\n",
      "    learn_throughput: 1370.88\n",
      "    learn_time_ms: 5834.207\n",
      "    load_throughput: 24414878.742\n",
      "    load_time_ms: 0.328\n",
      "    sample_throughput: 862.033\n",
      "    sample_time_ms: 9278.068\n",
      "    update_time_ms: 2.673\n",
      "  timestamp: 1645203426\n",
      "  timesteps_since_restore: 879780\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 879780\n",
      "  training_iteration: 110\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:57:07 (running for 00:44:03.80)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1049.7 </td><td style=\"text-align: right;\"> 879780</td><td style=\"text-align: right;\">  199.38</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 165</td><td style=\"text-align: right;\">            199.38</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:57:12 (running for 00:44:08.81)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1049.7 </td><td style=\"text-align: right;\"> 879780</td><td style=\"text-align: right;\">  199.38</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 165</td><td style=\"text-align: right;\">            199.38</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 887778\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-57-15\n",
      "  done: false\n",
      "  episode_len_mean: 199.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.38\n",
      "  episode_reward_min: 165.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 4961\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3297017514705658\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010451189242303371\n",
      "          model: {}\n",
      "          policy_loss: -0.008390042930841446\n",
      "          total_loss: 329.5356140136719\n",
      "          vf_explained_var: 0.5495477914810181\n",
      "          vf_loss: 329.539306640625\n",
      "    num_agent_steps_sampled: 887778\n",
      "    num_agent_steps_trained: 887778\n",
      "    num_steps_sampled: 887778\n",
      "    num_steps_trained: 887778\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.11538461538461\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08885188395881251\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09071564830340524\n",
      "    mean_inference_ms: 0.9778796810909094\n",
      "    mean_raw_obs_processing_ms: 0.11640446241381046\n",
      "  time_since_restore: 1058.9997799396515\n",
      "  time_this_iter_s: 9.299543142318726\n",
      "  time_total_s: 1058.9997799396515\n",
      "  timers:\n",
      "    learn_throughput: 1368.734\n",
      "    learn_time_ms: 5843.354\n",
      "    load_throughput: 25249167.087\n",
      "    load_time_ms: 0.317\n",
      "    sample_throughput: 861.032\n",
      "    sample_time_ms: 9288.857\n",
      "    update_time_ms: 2.66\n",
      "  timestamp: 1645203435\n",
      "  timesteps_since_restore: 887778\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 887778\n",
      "  training_iteration: 111\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:57:17 (running for 00:44:14.17)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1059   </td><td style=\"text-align: right;\"> 887778</td><td style=\"text-align: right;\">  199.38</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 165</td><td style=\"text-align: right;\">            199.38</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:57:22 (running for 00:44:19.18)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1059   </td><td style=\"text-align: right;\"> 887778</td><td style=\"text-align: right;\">  199.38</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 165</td><td style=\"text-align: right;\">            199.38</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 895776\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-57-24\n",
      "  done: false\n",
      "  episode_len_mean: 199.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.65\n",
      "  episode_reward_min: 165.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 5000\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3293739855289459\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011505285277962685\n",
      "          model: {}\n",
      "          policy_loss: -0.01249368954449892\n",
      "          total_loss: 245.51828002929688\n",
      "          vf_explained_var: 0.6014585494995117\n",
      "          vf_loss: 245.5255889892578\n",
      "    num_agent_steps_sampled: 895776\n",
      "    num_agent_steps_trained: 895776\n",
      "    num_steps_sampled: 895776\n",
      "    num_steps_trained: 895776\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.53846153846153\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08883014781279588\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09069423188059965\n",
      "    mean_inference_ms: 0.9777614515714942\n",
      "    mean_raw_obs_processing_ms: 0.11635957481910772\n",
      "  time_since_restore: 1068.1682889461517\n",
      "  time_this_iter_s: 9.168509006500244\n",
      "  time_total_s: 1068.1682889461517\n",
      "  timers:\n",
      "    learn_throughput: 1369.271\n",
      "    learn_time_ms: 5841.063\n",
      "    load_throughput: 25357958.57\n",
      "    load_time_ms: 0.315\n",
      "    sample_throughput: 859.197\n",
      "    sample_time_ms: 9308.696\n",
      "    update_time_ms: 2.607\n",
      "  timestamp: 1645203444\n",
      "  timesteps_since_restore: 895776\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 895776\n",
      "  training_iteration: 112\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:57:27 (running for 00:44:24.37)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1068.17</td><td style=\"text-align: right;\"> 895776</td><td style=\"text-align: right;\">  199.65</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 165</td><td style=\"text-align: right;\">            199.65</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:57:32 (running for 00:44:29.38)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>RUNNING </td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1068.17</td><td style=\"text-align: right;\"> 895776</td><td style=\"text-align: right;\">  199.65</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 165</td><td style=\"text-align: right;\">            199.65</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR   </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_a6500_00001:\n",
      "  agent_timesteps_total: 903774\n",
      "  custom_metrics: {}\n",
      "  date: 2022-02-18_16-57-33\n",
      "  done: true\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 200.0\n",
      "  episode_reward_min: 200.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 5041\n",
      "  experiment_id: b8ffccc5477e499eb5d3cd9be55bbf25\n",
      "  hostname: instance-1\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.31411027908325195\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00998739618808031\n",
      "          model: {}\n",
      "          policy_loss: -0.011039817705750465\n",
      "          total_loss: 258.9283752441406\n",
      "          vf_explained_var: 0.6693900227546692\n",
      "          vf_loss: 258.9349060058594\n",
      "    num_agent_steps_sampled: 903774\n",
      "    num_agent_steps_trained: 903774\n",
      "    num_steps_sampled: 903774\n",
      "    num_steps_trained: 903774\n",
      "    num_steps_trained_this_iter: 7998\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 10.182.0.2\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.06923076923077\n",
      "    ram_util_percent: 17.900000000000002\n",
      "  pid: 26960\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08880543978599556\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0906510472886357\n",
      "    mean_inference_ms: 0.9775257463980915\n",
      "    mean_raw_obs_processing_ms: 0.11629925752485377\n",
      "  time_since_restore: 1077.2804141044617\n",
      "  time_this_iter_s: 9.112125158309937\n",
      "  time_total_s: 1077.2804141044617\n",
      "  timers:\n",
      "    learn_throughput: 1368.16\n",
      "    learn_time_ms: 5845.808\n",
      "    load_throughput: 25588133.785\n",
      "    load_time_ms: 0.313\n",
      "    sample_throughput: 861.379\n",
      "    sample_time_ms: 9285.11\n",
      "    update_time_ms: 2.636\n",
      "  timestamp: 1645203453\n",
      "  timesteps_since_restore: 903774\n",
      "  timesteps_this_iter: 7998\n",
      "  timesteps_total: 903774\n",
      "  training_iteration: 113\n",
      "  trial_id: a6500_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-18 16:57:33 (running for 00:44:30.48)<br>Memory usage on this node: 2.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/8.8 GiB heap, 0.0/4.4 GiB objects<br>Result logdir: /home/dojm.ex5/ray_results/PPO<br>Number of trials: 2/2 (1 ERROR, 1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00001</td><td>TERMINATED</td><td>10.182.0.2:26960</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1077.28</td><td style=\"text-align: right;\"> 903774</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td>ERROR     </td><td>10.182.0.2:25294</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1560.41</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\">  175.96</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  78</td><td style=\"text-align: right;\">            175.96</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_a6500_00000</td><td style=\"text-align: right;\">           1</td><td>/home/dojm.ex5/ray_results/PPO/PPO_CartPole-v0_a6500_00000_0_lr=0.01_2022-02-18_16-13-03/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m 2022-02-18 16:57:34,268\tERROR worker.py:432 -- SystemExit was raised from the worker.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"python/ray/_raylet.pyx\", line 636, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"python/ray/_raylet.pyx\", line 640, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"python/ray/_raylet.pyx\", line 589, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/actor.py\", line 1156, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/actor.py\", line 1235, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     raise exit\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m SystemExit: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"python/ray/_raylet.pyx\", line 770, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"python/ray/_raylet.pyx\", line 591, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"python/ray/_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 33, in ray._raylet.ProfileEvent.__exit__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/usr/lib/python3.8/traceback.py\", line 167, in format_exc\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     return \"\".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/usr/lib/python3.8/traceback.py\", line 120, in format_exception\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     return list(TracebackException(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/usr/lib/python3.8/traceback.py\", line 508, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     self.stack = StackSummary.extract(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/usr/lib/python3.8/traceback.py\", line 366, in extract\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     f.line\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/usr/lib/python3.8/traceback.py\", line 288, in line\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/linecache.py\", line 16, in getline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     lines = getlines(filename, module_globals)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     return updatecache(filename, module_globals)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/linecache.py\", line 136, in updatecache\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     with tokenize.open(fullname) as fp:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/tokenize.py\", line 394, in open\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     encoding, lines = detect_encoding(buffer.readline)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/tokenize.py\", line 363, in detect_encoding\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     first = read_or_stop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/tokenize.py\", line 321, in read_or_stop\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     return readline()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 429, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26989)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m 2022-02-18 16:57:34,270\tERROR worker.py:432 -- SystemExit was raised from the worker.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"python/ray/_raylet.pyx\", line 636, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"python/ray/_raylet.pyx\", line 640, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"python/ray/_raylet.pyx\", line 589, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/actor.py\", line 1156, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/actor.py\", line 1235, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     raise exit\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m SystemExit: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"python/ray/_raylet.pyx\", line 770, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"python/ray/_raylet.pyx\", line 591, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"python/ray/_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 33, in ray._raylet.ProfileEvent.__exit__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/usr/lib/python3.8/traceback.py\", line 167, in format_exc\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     return \"\".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/usr/lib/python3.8/traceback.py\", line 120, in format_exception\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     return list(TracebackException(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/usr/lib/python3.8/traceback.py\", line 508, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     self.stack = StackSummary.extract(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/usr/lib/python3.8/traceback.py\", line 366, in extract\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     f.line\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/usr/lib/python3.8/traceback.py\", line 288, in line\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/linecache.py\", line 16, in getline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     lines = getlines(filename, module_globals)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     return updatecache(filename, module_globals)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/linecache.py\", line 95, in updatecache\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     stat = os.stat(fullname)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m   File \"/home/dojm.ex5/rl/venv/lib/python3.8/site-packages/ray/worker.py\", line 429, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=26991)\u001b[0m SystemExit: 1\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [PPO_CartPole-v0_a6500_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPPO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepisode_reward_mean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCartPole-v0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_gpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl/venv/lib/python3.8/site-packages/ray/tune/tune.py:630\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m incomplete_trials:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failed_trial \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state[signal\u001b[38;5;241m.\u001b[39mSIGINT]:\n\u001b[0;32m--> 630\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete\u001b[39m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [PPO_CartPole-v0_a6500_00000])"
     ]
    }
   ],
   "source": [
    "tune.run(\n",
    "    \"PPO\",\n",
    "    stop={\"episode_reward_mean\": 200},\n",
    "    config={\n",
    "        \"env\": \"CartPole-v0\",\n",
    "        \"num_gpus\": 0,\n",
    "        \"num_workers\": 3,\n",
    "        \"lr\": tune.grid_search([0.01, 0.001])\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43281b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune   \n",
    "\n",
    "# agent = ppo.PPOTrainer(config=config, env=env_class)\n",
    "# agent.restore(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d4237",
   "metadata": {},
   "source": [
    "## custom  + Tune DQN + Trainer compute_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.agents import ppo\n",
    "from ray import tune\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    \n",
    "\n",
    "# from my_env import MyEnv\n",
    "# register_env(\"my_env\", lambda config: MyEnv(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a5236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    DQN    ->  custom env \n",
    "\n",
    "# tune.run(\n",
    "#     \"DQN\",\n",
    "#     stop={\"training_iteration\": 100},\n",
    "#     config={\n",
    "#         \"env\": \"my_env\",\n",
    "#         \"timesteps_per_iteration\": 100,\n",
    "#         \"buffer_size\": 10000,\n",
    "#         \"train_batch_size\": 64,\n",
    "#         \"lr\": 1e-4\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76bbd59",
   "metadata": {},
   "source": [
    "#### Trainer compute_action()\n",
    "\n",
    " 4  train, save, restore, compute_action compute_action \n",
    "\n",
    "compute_action      action         \n",
    "\n",
    "  \n",
    "1. observation \n",
    "2. policy2action\n",
    "3. obs, reward, done, info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ppo.PPOTrainer(env=\"my_env\")\n",
    "env = MyEnv()\n",
    "\n",
    "#    \n",
    "obs = env.reset()\n",
    "done = False\n",
    "episode_reward = 0\n",
    "\n",
    "while not done:\n",
    "    #     action \n",
    "    action = agent.compute_action(obs) \n",
    "    # \n",
    "    obs, reward, done, info = env.step(action)  \n",
    "    episode_reward += reward\n",
    "    print(episode_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a520a9f2",
   "metadata": {},
   "source": [
    "## trainer policy(NN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a94af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import numpy as np\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee200d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(env=\"CartPole-v0\")\n",
    "policy = trainer.get_policy()\n",
    "\n",
    "logits, _ = policy.model.from_batch(\n",
    "    {\"obs\": np.array([[0.1, 0.2, 0.3, 0.4]])}\n",
    ")\n",
    "dist = policy.dist_class(logits, policy.model)\n",
    "\n",
    "print(type(policy.model))  # <class 'ray.rllib.models.tf.fcnet.FullyConnectedNetwork'>\n",
    "print(dist.sample())       # Tensor(\"Squeeze:0\", shape=(1,), dtype=int64)\n",
    "print(dist.logp)           # bound method Categorical.logp \n",
    "print(policy.model.value_function())     # Tensor(\"Reshape:0\", shape=(1,), dtype=float32)\n",
    "print(policy.model.base_model.summary()) # Model: \"functional_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cde086",
   "metadata": {},
   "source": [
    "## Trainer q-value(NN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf21952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.rllib.agents.dqn import DQNTrainer\n",
    "import numpy as np \n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DQNTrainer(env=\"CartPole-v0\")\n",
    "model = trainer.get_policy().model\n",
    "\n",
    "model_out = model.from_batch(\n",
    "    {\"obs\": np.array([[0.1, 0.2, 0.3, 0.4]])}\n",
    ")\n",
    "model_out_dist = model.get_q_value_distributions(model_out)\n",
    "\n",
    "# (<tf.Tensor 'functional_1/fc_out/Tanh:0' shape=(1, 256) dtype=float32>, [])\n",
    "print(model_out) \n",
    "\n",
    "# [<tf.Tensor 'BiasAdd_1:0' shape=(1, 2) dtype=float32>, \n",
    "# <tf.Tensor 'default_policy/ExpandDims_10:0' shape=(1, 2, 1) dtype=float32>, \n",
    "# <tf.Tensor 'default_policy/ExpandDims_1_1:0' shape=(1, 2, 1) dtype=float32>]\n",
    "print(model_out_dist)\n",
    "\n",
    "# Tensor(\"BiasAdd_3:0\", shape=(1, 1), dtype=float32)\n",
    "print(model.get_state_value(model_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91cc007",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec4230a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32db6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a226250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3053b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9153523e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33304983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
